---
apiVersion: v1
items:
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:52Z"
  involvedObject:
    apiVersion: v1
    kind: Endpoints
    name: apiserver
    namespace: openshift-kube-apiserver
    resourceVersion: "23618"
    uid: c12c3853-d7cc-41db-989e-e0bb2b2d3586
  kind: Event
  lastTimestamp: "2023-12-06T09:32:52Z"
  message: 'Failed to update endpoint openshift-kube-apiserver/apiserver: Operation
    cannot be fulfilled on endpoints "apiserver": the object has been modified; please
    apply your changes to the latest version and try again'
  metadata:
    creationTimestamp: "2023-12-06T09:32:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2023-12-06T09:32:52Z"
    name: apiserver.179e34431fdbafb9
    namespace: openshift-kube-apiserver
    resourceVersion: "25757"
    uid: c571904e-3caf-4ff1-91e7-fce0c209ce9e
  reason: FailedToUpdateEndpoint
  reportingComponent: endpoint-controller
  reportingInstance: ""
  source:
    component: endpoint-controller
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    kind: Endpoints
    name: apiserver
    namespace: openshift-kube-apiserver
    resourceVersion: "37354"
    uid: c12c3853-d7cc-41db-989e-e0bb2b2d3586
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: 'Failed to update endpoint openshift-kube-apiserver/apiserver: Operation
    cannot be fulfilled on endpoints "apiserver": the object has been modified; please
    apply your changes to the latest version and try again'
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: apiserver.179e34ee4148edaf
    namespace: openshift-kube-apiserver
    resourceVersion: "41465"
    uid: a430260e-1332-4ca9-a138-a3de9ff38aa2
  reason: FailedToUpdateEndpoint
  reportingComponent: endpoint-controller
  reportingInstance: ""
  source:
    component: endpoint-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:12Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "16929"
    uid: ff041803-d1d0-49e5-a1fc-0635ac6d4fb7
  kind: Event
  lastTimestamp: "2023-12-06T09:25:12Z"
  message: ip-10-0-106-212_149d7b2d-e96d-4e3d-90cf-64ccb0f0b7d2 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:25:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:12Z"
    name: cert-regeneration-controller-lock.179e33d8335f254f
    namespace: openshift-kube-apiserver
    resourceVersion: "16931"
    uid: 97f4dcfb-3ed3-4981-b9c1-0f8bb98dd4bb
  reason: LeaderElection
  reportingComponent: cert-regeneration-controller
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:30:51Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "24359"
    uid: ff041803-d1d0-49e5-a1fc-0635ac6d4fb7
  kind: Event
  lastTimestamp: "2023-12-06T09:30:51Z"
  message: ip-10-0-21-63_2fa5d813-0b96-43d8-b5f4-eb234534f768 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:30:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:30:51Z"
    name: cert-regeneration-controller-lock.179e3427281cdd55
    namespace: openshift-kube-apiserver
    resourceVersion: "24360"
    uid: 4c43ca95-a601-46b2-a5a4-70f5d34250a6
  reason: LeaderElection
  reportingComponent: cert-regeneration-controller
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:47:09Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "40412"
    uid: ff041803-d1d0-49e5-a1fc-0635ac6d4fb7
  kind: Event
  lastTimestamp: "2023-12-06T09:47:09Z"
  message: ip-10-0-94-160_c9821252-a039-4fe7-8cd0-52efdcb6190b became leader
  metadata:
    creationTimestamp: "2023-12-06T09:47:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:47:09Z"
    name: cert-regeneration-controller-lock.179e350ad0d537f0
    namespace: openshift-kube-apiserver
    resourceVersion: "40413"
    uid: 00df7638-01ed-400d-b164-48d5e342dda8
  reason: LeaderElection
  reportingComponent: cert-regeneration-controller
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:46Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "42503"
    uid: ff041803-d1d0-49e5-a1fc-0635ac6d4fb7
  kind: Event
  lastTimestamp: "2023-12-06T09:50:46Z"
  message: ip-10-0-106-212_6edd6144-04f7-4981-9a66-cc0c12d749ea became leader
  metadata:
    creationTimestamp: "2023-12-06T09:50:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:50:46Z"
    name: cert-regeneration-controller-lock.179e353d3ba4a2cb
    namespace: openshift-kube-apiserver
    resourceVersion: "42504"
    uid: d661164c-9c1c-4c34-92af-e488d3943967
  reason: LeaderElection
  reportingComponent: cert-regeneration-controller
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:36Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "14328"
    uid: 1aa08822-5d9b-4f90-847b-c99e3214cd40
  kind: Event
  lastTimestamp: "2023-12-06T09:23:36Z"
  message: Add eth0 [10.128.0.23/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:23:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:23:36Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33c1c752cc2d
    namespace: openshift-kube-apiserver
    resourceVersion: "14358"
    uid: 9423675c-6aef-4b97-bbfe-e14937ea4a39
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:36Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "14325"
    uid: 1aa08822-5d9b-4f90-847b-c99e3214cd40
  kind: Event
  lastTimestamp: "2023-12-06T09:23:36Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:23:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:36Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33c1c8cc15fc
    namespace: openshift-kube-apiserver
    resourceVersion: "14362"
    uid: bd537999-c601-41d9-9d1e-e1f6681bc494
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:36Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "14325"
    uid: 1aa08822-5d9b-4f90-847b-c99e3214cd40
  kind: Event
  lastTimestamp: "2023-12-06T09:23:36Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:23:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:36Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33c1cfd231d3
    namespace: openshift-kube-apiserver
    resourceVersion: "14381"
    uid: a43f2d24-40d1-42f3-a03a-4c8e7c7990c5
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:36Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "14325"
    uid: 1aa08822-5d9b-4f90-847b-c99e3214cd40
  kind: Event
  lastTimestamp: "2023-12-06T09:23:36Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:23:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:36Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33c1d08b389e
    namespace: openshift-kube-apiserver
    resourceVersion: "14384"
    uid: 92e10e1d-e8d6-4111-8960-192b5c597e44
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "14325"
    uid: 1aa08822-5d9b-4f90-847b-c99e3214cd40
  kind: Event
  lastTimestamp: "2023-12-06T09:24:05Z"
  message: Stopping container installer
  metadata:
    creationTimestamp: "2023-12-06T09:24:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:05Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33c87cfd1ba5
    namespace: openshift-kube-apiserver
    resourceVersion: "15706"
    uid: 18cb0a18-9221-4802-92fd-f18b3e0f4244
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:15Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "15883"
    uid: 91a86050-bf24-4f65-be3f-3df275b3dbe0
  kind: Event
  lastTimestamp: "2023-12-06T09:24:15Z"
  message: Add eth0 [10.128.0.25/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:24:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:24:15Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e33caf3ae6675
    namespace: openshift-kube-apiserver
    resourceVersion: "15895"
    uid: e2338608-2f3f-4c16-b24e-ae91bfb77009
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "15879"
    uid: 91a86050-bf24-4f65-be3f-3df275b3dbe0
  kind: Event
  lastTimestamp: "2023-12-06T09:24:15Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:24:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:15Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e33caf52ccd0c
    namespace: openshift-kube-apiserver
    resourceVersion: "15899"
    uid: dbdc142a-e02e-4678-b66f-08e671e3b921
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:16Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "15879"
    uid: 91a86050-bf24-4f65-be3f-3df275b3dbe0
  kind: Event
  lastTimestamp: "2023-12-06T09:24:16Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:24:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:16Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e33cafc3ae3a6
    namespace: openshift-kube-apiserver
    resourceVersion: "15906"
    uid: de278149-7e34-4d3b-8099-8d69603efbfd
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:16Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "15879"
    uid: 91a86050-bf24-4f65-be3f-3df275b3dbe0
  kind: Event
  lastTimestamp: "2023-12-06T09:24:16Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:24:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:16Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e33cafce76586
    namespace: openshift-kube-apiserver
    resourceVersion: "15907"
    uid: b5b3247b-45c4-4d5b-90a6-bca90e1b5283
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:53Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 91a86050-bf24-4f65-be3f-3df275b3dbe0
  kind: Event
  lastTimestamp: "2023-12-06T09:24:53Z"
  message: Successfully installed revision 3
  metadata:
    creationTimestamp: "2023-12-06T09:24:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:53Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e33d3b1e43767
    namespace: openshift-kube-apiserver
    resourceVersion: "16392"
    uid: efd85a9e-cbc4-438c-95e7-b60929d93803
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:58Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "18713"
    uid: 796b16db-a3a5-4719-9c4e-c6f09316123c
  kind: Event
  lastTimestamp: "2023-12-06T09:25:58Z"
  message: Add eth0 [10.129.0.72/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:25:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:25:58Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e33e2c8ddf63f
    namespace: openshift-kube-apiserver
    resourceVersion: "18729"
    uid: 94e8a49c-65cf-40b9-86be-7e194deb8082
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "18709"
    uid: 796b16db-a3a5-4719-9c4e-c6f09316123c
  kind: Event
  lastTimestamp: "2023-12-06T09:25:58Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:58Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e33e2caf4b152
    namespace: openshift-kube-apiserver
    resourceVersion: "18731"
    uid: fea7761e-01bf-4de6-828f-1b97e97109d1
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "18709"
    uid: 796b16db-a3a5-4719-9c4e-c6f09316123c
  kind: Event
  lastTimestamp: "2023-12-06T09:25:58Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:25:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:58Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e33e2de35b01b
    namespace: openshift-kube-apiserver
    resourceVersion: "18741"
    uid: 51673d3f-541c-40b5-9f95-3530f9929b7f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "18709"
    uid: 796b16db-a3a5-4719-9c4e-c6f09316123c
  kind: Event
  lastTimestamp: "2023-12-06T09:25:58Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:25:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:58Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e33e2e04a220d
    namespace: openshift-kube-apiserver
    resourceVersion: "18742"
    uid: 5e13f336-db06-42f7-8ec3-2c769a2c0e91
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "18709"
    uid: 796b16db-a3a5-4719-9c4e-c6f09316123c
  kind: Event
  lastTimestamp: "2023-12-06T09:26:34Z"
  message: Stopping container installer
  metadata:
    creationTimestamp: "2023-12-06T09:26:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:26:34Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e33eb228219f4
    namespace: openshift-kube-apiserver
    resourceVersion: "20098"
    uid: d2c48254-e564-403e-83aa-3391d0390505
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:34Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 796b16db-a3a5-4719-9c4e-c6f09316123c
  kind: Event
  lastTimestamp: "2023-12-06T09:26:34Z"
  message: 'Installing revision 4: client rate limiter Wait returned an error: context
    canceled'
  metadata:
    creationTimestamp: "2023-12-06T09:26:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:34Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e33eb23c0ae48
    namespace: openshift-kube-apiserver
    resourceVersion: "20100"
    uid: 54f8308f-7fa6-4f1a-8122-f0243d5af03d
  reason: StaticPodInstallerFailed
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:52Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "23572"
    uid: 291fb707-7c27-4e0c-b976-12c22c263ad3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:52Z"
  message: Add eth0 [10.128.0.34/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:29:52Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e3419629bbcf2
    namespace: openshift-kube-apiserver
    resourceVersion: "23586"
    uid: 70c8bab7-ac40-43b7-a978-7536b0369458
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "23568"
    uid: 291fb707-7c27-4e0c-b976-12c22c263ad3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:52Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:52Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e341963fb405b
    namespace: openshift-kube-apiserver
    resourceVersion: "23589"
    uid: 7726b702-1d51-467c-a6cf-c21e2da55c64
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "23568"
    uid: 291fb707-7c27-4e0c-b976-12c22c263ad3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:53Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:29:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:53Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34196d4e174b
    namespace: openshift-kube-apiserver
    resourceVersion: "23590"
    uid: 1ad815b6-7f57-4510-832e-a50a011d2df8
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "23568"
    uid: 291fb707-7c27-4e0c-b976-12c22c263ad3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:53Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:29:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:53Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34196e09c63d
    namespace: openshift-kube-apiserver
    resourceVersion: "23591"
    uid: 87b25f45-b7f4-4170-a064-f929bf6287c8
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:30:30Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 291fb707-7c27-4e0c-b976-12c22c263ad3
  kind: Event
  lastTimestamp: "2023-12-06T09:30:30Z"
  message: Successfully installed revision 5
  metadata:
    creationTimestamp: "2023-12-06T09:30:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:30:30Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34222352bf19
    namespace: openshift-kube-apiserver
    resourceVersion: "24110"
    uid: 651460b5-e80e-4fd1-a3b0-90405845d2ba
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:46Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "20342"
    uid: 5736b8f6-0f15-4180-b2ee-46fde06fd08f
  kind: Event
  lastTimestamp: "2023-12-06T09:26:46Z"
  message: Add eth0 [10.129.0.74/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:26:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:26:46Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e33ee1e4f975a
    namespace: openshift-kube-apiserver
    resourceVersion: "20349"
    uid: 13873135-9df3-45fb-9c6a-6309f5433afc
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "20339"
    uid: 5736b8f6-0f15-4180-b2ee-46fde06fd08f
  kind: Event
  lastTimestamp: "2023-12-06T09:26:47Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:26:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:26:47Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e33ee1fcbfa34
    namespace: openshift-kube-apiserver
    resourceVersion: "20351"
    uid: 6ae6ff25-4b74-4a51-8227-c543c912ef6e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "20339"
    uid: 5736b8f6-0f15-4180-b2ee-46fde06fd08f
  kind: Event
  lastTimestamp: "2023-12-06T09:26:47Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:26:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:26:47Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e33ee2e042ca0
    namespace: openshift-kube-apiserver
    resourceVersion: "20355"
    uid: ae652881-72bc-4f72-b01b-0bc06906ecd8
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "20339"
    uid: 5736b8f6-0f15-4180-b2ee-46fde06fd08f
  kind: Event
  lastTimestamp: "2023-12-06T09:26:47Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:26:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:26:47Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e33ee2eda8204
    namespace: openshift-kube-apiserver
    resourceVersion: "20356"
    uid: 718852a0-bf27-4660-833f-a823b1cca0a8
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5736b8f6-0f15-4180-b2ee-46fde06fd08f
  kind: Event
  lastTimestamp: "2023-12-06T09:27:24Z"
  message: Successfully installed revision 5
  metadata:
    creationTimestamp: "2023-12-06T09:27:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:24Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e33f6e3f670b5
    namespace: openshift-kube-apiserver
    resourceVersion: "21019"
    uid: 35f2f729-a2c9-499b-a00f-05b81c6b19b3
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:20Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22243"
    uid: 001d9f0a-67c1-4aca-a294-ab2e745d37a5
  kind: Event
  lastTimestamp: "2023-12-06T09:28:20Z"
  message: Add eth0 [10.130.0.34/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:28:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:28:20Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e3403eda55f75
    namespace: openshift-kube-apiserver
    resourceVersion: "22250"
    uid: ea79d4cb-6703-4d36-9540-3e5e16c7ec2f
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:20Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22240"
    uid: 001d9f0a-67c1-4aca-a294-ab2e745d37a5
  kind: Event
  lastTimestamp: "2023-12-06T09:28:20Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:28:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:20Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e3403ef3fa595
    namespace: openshift-kube-apiserver
    resourceVersion: "22252"
    uid: 26abf780-6c07-40e9-9365-17b2806afb02
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:20Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22240"
    uid: 001d9f0a-67c1-4aca-a294-ab2e745d37a5
  kind: Event
  lastTimestamp: "2023-12-06T09:28:20Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:28:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:20Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e3403f7c7da64
    namespace: openshift-kube-apiserver
    resourceVersion: "22253"
    uid: 7b087b8b-c24d-4074-9368-9b8427bab719
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:20Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22240"
    uid: 001d9f0a-67c1-4aca-a294-ab2e745d37a5
  kind: Event
  lastTimestamp: "2023-12-06T09:28:20Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:28:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:20Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e3403f87de9e7
    namespace: openshift-kube-apiserver
    resourceVersion: "22255"
    uid: c5bfa5e3-c606-489d-b848-2af8b0250ab1
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:58Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 001d9f0a-67c1-4aca-a294-ab2e745d37a5
  kind: Event
  lastTimestamp: "2023-12-06T09:28:58Z"
  message: Successfully installed revision 5
  metadata:
    creationTimestamp: "2023-12-06T09:28:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:28:58Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e340cad855e3c
    namespace: openshift-kube-apiserver
    resourceVersion: "22723"
    uid: 52276aab-ee9c-4aa7-82ed-7f58ee6428f6
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:34Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "27856"
    uid: e8bbe8ee-0882-4224-b439-7bf2633ec640
  kind: Event
  lastTimestamp: "2023-12-06T09:35:34Z"
  message: Add eth0 [10.128.0.42/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:35:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:35:34Z"
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal.179e3468fe9b531b
    namespace: openshift-kube-apiserver
    resourceVersion: "27865"
    uid: fe9f293a-ca0c-4f51-a2c5-e72f73c03b60
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "27852"
    uid: e8bbe8ee-0882-4224-b439-7bf2633ec640
  kind: Event
  lastTimestamp: "2023-12-06T09:35:34Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:35:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:35:34Z"
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal.179e34690009aa7f
    namespace: openshift-kube-apiserver
    resourceVersion: "27867"
    uid: 5ccba72d-3762-4793-8d19-b43a46e6f4f4
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "27852"
    uid: e8bbe8ee-0882-4224-b439-7bf2633ec640
  kind: Event
  lastTimestamp: "2023-12-06T09:35:34Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:35:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:35:34Z"
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal.179e346907dbd7ba
    namespace: openshift-kube-apiserver
    resourceVersion: "27869"
    uid: d8ff0d24-231a-413d-b0c3-eb9a10f1572a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "27852"
    uid: e8bbe8ee-0882-4224-b439-7bf2633ec640
  kind: Event
  lastTimestamp: "2023-12-06T09:35:34Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:35:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:35:34Z"
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal.179e3469089c3dac
    namespace: openshift-kube-apiserver
    resourceVersion: "27870"
    uid: 65e07217-c3c3-4877-a046-9b41bc751576
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:36:12Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e8bbe8ee-0882-4224-b439-7bf2633ec640
  kind: Event
  lastTimestamp: "2023-12-06T09:36:12Z"
  message: Successfully installed revision 6
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:36:12Z"
    name: installer-6-ip-10-0-106-212.us-west-1.compute.internal.179e3471bddaf913
    namespace: openshift-kube-apiserver
    resourceVersion: "28340"
    uid: 83075ec5-cff5-4ceb-95cf-b4c7e3340a6d
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:47Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "29843"
    uid: 31d34af0-06c9-4f69-a572-1d7286679200
  kind: Event
  lastTimestamp: "2023-12-06T09:37:47Z"
  message: Add eth0 [10.128.0.43/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:37:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:37:47Z"
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal.179e3487db502b18
    namespace: openshift-kube-apiserver
    resourceVersion: "29844"
    uid: 75583f7c-ae23-43d3-9c3d-fae482ed968d
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "29840"
    uid: 31d34af0-06c9-4f69-a572-1d7286679200
  kind: Event
  lastTimestamp: "2023-12-06T09:37:47Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:37:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:37:47Z"
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal.179e3487dcfe8561
    namespace: openshift-kube-apiserver
    resourceVersion: "29846"
    uid: 16844425-41e3-4df0-83b0-4b8770e4bab4
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "29840"
    uid: 31d34af0-06c9-4f69-a572-1d7286679200
  kind: Event
  lastTimestamp: "2023-12-06T09:37:47Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:37:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:37:47Z"
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal.179e3487e77c0c7f
    namespace: openshift-kube-apiserver
    resourceVersion: "29847"
    uid: 3e67a5e9-36f8-4234-ba78-d41c3a419341
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "29840"
    uid: 31d34af0-06c9-4f69-a572-1d7286679200
  kind: Event
  lastTimestamp: "2023-12-06T09:37:47Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:37:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:37:47Z"
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal.179e3487e8438171
    namespace: openshift-kube-apiserver
    resourceVersion: "29848"
    uid: ff3c11ad-c573-4a45-bcc0-e92c252eeedf
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 31d34af0-06c9-4f69-a572-1d7286679200
  kind: Event
  lastTimestamp: "2023-12-06T09:38:24Z"
  message: Successfully installed revision 7
  metadata:
    creationTimestamp: "2023-12-06T09:38:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:25Z"
    name: installer-7-ip-10-0-106-212.us-west-1.compute.internal.179e34909dd99bdb
    namespace: openshift-kube-apiserver
    resourceVersion: "30485"
    uid: d394c895-9a16-46fa-afa4-8c8ced66d80a
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:23Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "33268"
    uid: 30f2fdd1-a8a0-44df-b430-c2d7ea958c76
  kind: Event
  lastTimestamp: "2023-12-06T09:39:23Z"
  message: Add eth0 [10.128.0.49/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:39:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:39:23Z"
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal.179e349e4a446e01
    namespace: openshift-kube-apiserver
    resourceVersion: "33286"
    uid: 4d014c2f-727a-4087-a9bc-96edf723b0a9
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "33266"
    uid: 30f2fdd1-a8a0-44df-b430-c2d7ea958c76
  kind: Event
  lastTimestamp: "2023-12-06T09:39:24Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:39:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:24Z"
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal.179e349e6c7f4141
    namespace: openshift-kube-apiserver
    resourceVersion: "33301"
    uid: 1487ec26-37eb-40c4-93cf-03779df0d70f
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "33266"
    uid: 30f2fdd1-a8a0-44df-b430-c2d7ea958c76
  kind: Event
  lastTimestamp: "2023-12-06T09:39:24Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:39:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:24Z"
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal.179e349e7c695ce8
    namespace: openshift-kube-apiserver
    resourceVersion: "33341"
    uid: 7d308ac9-e03d-42fb-95de-b1326fbbbabb
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "33266"
    uid: 30f2fdd1-a8a0-44df-b430-c2d7ea958c76
  kind: Event
  lastTimestamp: "2023-12-06T09:39:24Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:39:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:24Z"
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal.179e349e7d2bfc86
    namespace: openshift-kube-apiserver
    resourceVersion: "33343"
    uid: 2fa1f5e6-9d21-4d1b-8a18-c4dcc031ac92
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:01Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 30f2fdd1-a8a0-44df-b430-c2d7ea958c76
  kind: Event
  lastTimestamp: "2023-12-06T09:40:01Z"
  message: Successfully installed revision 8
  metadata:
    creationTimestamp: "2023-12-06T09:40:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:40:02Z"
    name: installer-8-ip-10-0-106-212.us-west-1.compute.internal.179e34a72d541480
    namespace: openshift-kube-apiserver
    resourceVersion: "34307"
    uid: 78e6f21c-5e55-4b0b-a9e9-e051fa4188d1
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:13Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "36909"
    uid: ca5af518-4242-435a-b673-6e0aca0a7283
  kind: Event
  lastTimestamp: "2023-12-06T09:42:13Z"
  message: Add eth0 [10.128.0.55/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:42:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:42:13Z"
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal.179e34c5bb1b58b6
    namespace: openshift-kube-apiserver
    resourceVersion: "36913"
    uid: 0e65d2b9-3deb-449a-b671-c5581a5ee31d
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "36906"
    uid: ca5af518-4242-435a-b673-6e0aca0a7283
  kind: Event
  lastTimestamp: "2023-12-06T09:42:13Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:13Z"
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal.179e34c5bcf55aa2
    namespace: openshift-kube-apiserver
    resourceVersion: "36915"
    uid: 031fc73e-4c88-40e2-a96f-8487688aef59
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "36906"
    uid: ca5af518-4242-435a-b673-6e0aca0a7283
  kind: Event
  lastTimestamp: "2023-12-06T09:42:13Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:42:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:13Z"
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal.179e34c5c475a7fd
    namespace: openshift-kube-apiserver
    resourceVersion: "36917"
    uid: c40f77d1-2cd7-4615-a9f8-ca1257fddb72
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "36906"
    uid: ca5af518-4242-435a-b673-6e0aca0a7283
  kind: Event
  lastTimestamp: "2023-12-06T09:42:13Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:42:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:13Z"
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal.179e34c5c52c8eb2
    namespace: openshift-kube-apiserver
    resourceVersion: "36918"
    uid: c318115e-4f87-4629-8aab-1c8cbe762a0a
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:50Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ca5af518-4242-435a-b673-6e0aca0a7283
  kind: Event
  lastTimestamp: "2023-12-06T09:42:50Z"
  message: Successfully installed revision 9
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:50Z"
    name: installer-9-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7a268306
    namespace: openshift-kube-apiserver
    resourceVersion: "37460"
    uid: c922f549-4bc7-44e4-82e5-c8423ebda589
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:10Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "39782"
    uid: f2829eb7-0259-4295-b850-f6877ecc29f6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:10Z"
  message: Add eth0 [10.129.0.89/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:46:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:46:10Z"
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal.179e34fd17965689
    namespace: openshift-kube-apiserver
    resourceVersion: "39794"
    uid: 39ddf382-06b0-49cf-8c1e-dfdf61f06c25
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:10Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "39778"
    uid: f2829eb7-0259-4295-b850-f6877ecc29f6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:10Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:46:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:10Z"
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal.179e34fd1954820c
    namespace: openshift-kube-apiserver
    resourceVersion: "39796"
    uid: 9253db19-4564-44e1-b9ce-6fb7c9e7c003
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:11Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "39778"
    uid: f2829eb7-0259-4295-b850-f6877ecc29f6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:11Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:46:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:11Z"
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal.179e34fd26a01734
    namespace: openshift-kube-apiserver
    resourceVersion: "39799"
    uid: 4cec41c2-a247-4fd2-8899-2b7632fa9fca
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:11Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "39778"
    uid: f2829eb7-0259-4295-b850-f6877ecc29f6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:11Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:46:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:11Z"
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal.179e34fd277c6828
    namespace: openshift-kube-apiserver
    resourceVersion: "39800"
    uid: ad5e3c1d-4b22-4ce7-982b-11ffdcdd36d1
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:48Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: f2829eb7-0259-4295-b850-f6877ecc29f6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:48Z"
  message: Successfully installed revision 9
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:46:48Z"
    name: installer-9-ip-10-0-21-63.us-west-1.compute.internal.179e3505e1830853
    namespace: openshift-kube-apiserver
    resourceVersion: "40184"
    uid: ae06f70a-395d-4573-a622-6fa3f3c43424
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:06Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "42076"
    uid: 4026a9aa-cba8-4361-9e70-b7e61a7263bf
  kind: Event
  lastTimestamp: "2023-12-06T09:50:06Z"
  message: Add eth0 [10.130.0.49/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:50:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:50:06Z"
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal.179e3533e8c4bf2d
    namespace: openshift-kube-apiserver
    resourceVersion: "42078"
    uid: 37e813f7-a76b-4fbc-b21a-6b5769a1bcd2
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "42073"
    uid: 4026a9aa-cba8-4361-9e70-b7e61a7263bf
  kind: Event
  lastTimestamp: "2023-12-06T09:50:06Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:50:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:06Z"
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal.179e3533eab1261f
    namespace: openshift-kube-apiserver
    resourceVersion: "42080"
    uid: b32e4def-d52c-4f23-a916-8b71b4e4a7df
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "42073"
    uid: 4026a9aa-cba8-4361-9e70-b7e61a7263bf
  kind: Event
  lastTimestamp: "2023-12-06T09:50:06Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:50:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:06Z"
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal.179e3533f3a09c7b
    namespace: openshift-kube-apiserver
    resourceVersion: "42082"
    uid: 7b6090a5-de56-4e80-8331-2872ea40ce05
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "42073"
    uid: 4026a9aa-cba8-4361-9e70-b7e61a7263bf
  kind: Event
  lastTimestamp: "2023-12-06T09:50:06Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:50:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:06Z"
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal.179e3533f45fea7b
    namespace: openshift-kube-apiserver
    resourceVersion: "42083"
    uid: bc62b546-faaf-4987-997b-3f272f640075
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:43Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 4026a9aa-cba8-4361-9e70-b7e61a7263bf
  kind: Event
  lastTimestamp: "2023-12-06T09:50:43Z"
  message: Successfully installed revision 9
  metadata:
    creationTimestamp: "2023-12-06T09:50:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:50:44Z"
    name: installer-9-ip-10-0-94-160.us-west-1.compute.internal.179e353ca8ea9187
    namespace: openshift-kube-apiserver
    resourceVersion: "42474"
    uid: e66ebd5c-3d9c-4076-b966-854a94b04352
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:00Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16610"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:25:00Z"
  message: Add eth0 [10.128.0.27/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:25:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:25:00Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d568c82b65
    namespace: openshift-kube-apiserver
    resourceVersion: "16650"
    uid: 1f62041d-2196-4a53-84e7-9e0889b379fb
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:25:00Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:00Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d56a8555c9
    namespace: openshift-kube-apiserver
    resourceVersion: "16652"
    uid: c56760eb-e7d1-48eb-a404-ac40695e6f7e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:25:01Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2023-12-06T09:25:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:01Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d572b118f9
    namespace: openshift-kube-apiserver
    resourceVersion: "16655"
    uid: 36fc3d58-f204-44ca-a5fc-ae998f830214
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:25:01Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2023-12-06T09:25:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:01Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d5736724ce
    namespace: openshift-kube-apiserver
    resourceVersion: "16656"
    uid: c41bd14e-8508-449c-b97c-16df097d1599
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 10
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:45:05Z"
  message: "Readiness probe error: Get \"https://10.0.106.212:6443/readyz\": dial
    tcp 10.0.106.212:6443: connect: connection refused\nbody: \n"
  metadata:
    creationTimestamp: "2023-12-06T09:25:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:05Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d5a171314e
    namespace: openshift-kube-apiserver
    resourceVersion: "38993"
    uid: 03e928ae-3674-4bb1-817b-8ed0607e5ef8
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: 'Readiness probe failed: Get "https://10.0.106.212:6443/readyz": dial tcp
    10.0.106.212:6443: connect: connection refused'
  metadata:
    creationTimestamp: "2023-12-06T09:25:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d5a171a84b
    namespace: openshift-kube-apiserver
    resourceVersion: "16727"
    uid: 8433be6a-e80c-47d6-ac09-2e29d1c3f8e3
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:25:07Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 403
    body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/readyz\"","reason":"Forbidden","details":{},"code":403}

  metadata:
    creationTimestamp: "2023-12-06T09:25:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:07Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d6fe1bea1e
    namespace: openshift-kube-apiserver
    resourceVersion: "16801"
    uid: 49e23b6c-67ab-47dd-9710-88c0356c1114
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:25:07Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 403'
  metadata:
    creationTimestamp: "2023-12-06T09:25:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:07Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33d6fe1c76d2
    namespace: openshift-kube-apiserver
    resourceVersion: "16802"
    uid: f1393991-afd4-41d1-bb5c-a21b1833c584
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 5
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:27:30Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [-]etcd-readiness failed: reason withheld
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [+]shutdown ok
    readyz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:27:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:30Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33f4ba5ca1e7
    namespace: openshift-kube-apiserver
    resourceVersion: "21166"
    uid: 1fb69cc6-b763-46fe-af5f-aaa2e647ca4e
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 7
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:27:40Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2023-12-06T09:27:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:40Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33f4ba5d2833
    namespace: openshift-kube-apiserver
    resourceVersion: "21343"
    uid: f74ff037-b0db-4c7e-907c-31d3c3d36f6e
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:27:40Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [-]etcd-readiness failed: reason withheld
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:27:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:40Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33f9627e429b
    namespace: openshift-kube-apiserver
    resourceVersion: "21341"
    uid: f5cd6c96-9549-40ec-932a-4c69d240dddc
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:30:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:30:35Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:30:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:30:35Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e34234b51abc7
    namespace: openshift-kube-apiserver
    resourceVersion: "24178"
    uid: 7061554d-da70-47fd-a42f-31da2a5f9d3c
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "16605"
    uid: 8cee0506-4ba3-4dc7-82f3-2a5acdda6d91
  kind: Event
  lastTimestamp: "2023-12-06T09:40:05Z"
  message: |+
    (combined from similar events): Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:36:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:05Z"
    name: kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal.179e347274eaa122
    namespace: openshift-kube-apiserver
    resourceVersion: "34357"
    uid: cce0e96a-8126-496b-8895-e2ca0a4a21fe
  reason: ProbeError
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:35Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "21220"
    uid: 7df6aea3-12fd-47a9-b8f5-ab2ed256c672
  kind: Event
  lastTimestamp: "2023-12-06T09:27:35Z"
  message: Add eth0 [10.129.0.75/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:27:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:27:35Z"
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33f961fea563
    namespace: openshift-kube-apiserver
    resourceVersion: "21234"
    uid: 437e16b5-a961-4c64-baec-e657633000b2
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "21214"
    uid: 7df6aea3-12fd-47a9-b8f5-ab2ed256c672
  kind: Event
  lastTimestamp: "2023-12-06T09:27:35Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:27:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:35Z"
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33f9636e8735
    namespace: openshift-kube-apiserver
    resourceVersion: "21238"
    uid: f64aefb5-ab42-41a6-839b-1ff57224b58a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "21214"
    uid: 7df6aea3-12fd-47a9-b8f5-ab2ed256c672
  kind: Event
  lastTimestamp: "2023-12-06T09:27:35Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2023-12-06T09:27:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:35Z"
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33f96a592986
    namespace: openshift-kube-apiserver
    resourceVersion: "21239"
    uid: e028fc47-ec9d-4a51-9398-389031160fe1
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "21214"
    uid: 7df6aea3-12fd-47a9-b8f5-ab2ed256c672
  kind: Event
  lastTimestamp: "2023-12-06T09:27:35Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2023-12-06T09:27:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:35Z"
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33f96b28ed59
    namespace: openshift-kube-apiserver
    resourceVersion: "21240"
    uid: 61ea5dd0-0da5-4f4c-b08e-da3001a98880
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 13
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "21214"
    uid: 7df6aea3-12fd-47a9-b8f5-ab2ed256c672
  kind: Event
  lastTimestamp: "2023-12-06T09:47:45Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:46:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:47:45Z"
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal.179e3506487fe41d
    namespace: openshift-kube-apiserver
    resourceVersion: "40754"
    uid: ea5fbfc5-10ae-49c3-83d9-a310491d8521
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 12
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "21214"
    uid: 7df6aea3-12fd-47a9-b8f5-ab2ed256c672
  kind: Event
  lastTimestamp: "2023-12-06T09:47:40Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2023-12-06T09:46:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:47:40Z"
    name: kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal.179e35064880d8ce
    namespace: openshift-kube-apiserver
    resourceVersion: "40707"
    uid: 7c7d5172-547b-4154-9eb9-7e29a3b8b810
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:07Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22883"
    uid: e906dcc9-7b05-4261-a4c0-267976f406a3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:07Z"
  message: Add eth0 [10.130.0.35/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:29:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:29:07Z"
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal.179e340eee7c1d0f
    namespace: openshift-kube-apiserver
    resourceVersion: "22887"
    uid: 5070d680-c109-433b-8f59-fd75dbda9195
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22878"
    uid: e906dcc9-7b05-4261-a4c0-267976f406a3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:29:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:07Z"
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal.179e340eeff6bc96
    namespace: openshift-kube-apiserver
    resourceVersion: "22889"
    uid: 7489677c-04ce-406e-abea-48dd94c274e4
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22878"
    uid: e906dcc9-7b05-4261-a4c0-267976f406a3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:08Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2023-12-06T09:29:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:08Z"
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal.179e340ef606f58f
    namespace: openshift-kube-apiserver
    resourceVersion: "22890"
    uid: f041353c-b49d-44fb-a0b8-3736cc37903e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22878"
    uid: e906dcc9-7b05-4261-a4c0-267976f406a3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:08Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2023-12-06T09:29:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:08Z"
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal.179e340ef6ddcd70
    namespace: openshift-kube-apiserver
    resourceVersion: "22892"
    uid: 2012101c-97dc-413e-a9b7-af6f64aff1c2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 13
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22878"
    uid: e906dcc9-7b05-4261-a4c0-267976f406a3
  kind: Event
  lastTimestamp: "2023-12-06T09:51:42Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:50:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:51:42Z"
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal.179e353d97e63e12
    namespace: openshift-kube-apiserver
    resourceVersion: "43090"
    uid: abcfc4dc-caae-4339-8635-f298669dabfe
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 12
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:47Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "22878"
    uid: e906dcc9-7b05-4261-a4c0-267976f406a3
  kind: Event
  lastTimestamp: "2023-12-06T09:51:37Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2023-12-06T09:50:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:51:37Z"
    name: kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal.179e353d97e6ace4
    namespace: openshift-kube-apiserver
    resourceVersion: "43051"
    uid: 011cf609-9e2f-4a03-aae9-6c0c1a3522d9
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:09Z"
  involvedObject:
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    name: kube-apiserver-guard-pdb
    namespace: openshift-kube-apiserver
    resourceVersion: "5248"
    uid: 3673d67c-c4a8-46bd-8e5e-19fa7a2f6fc8
  kind: Event
  lastTimestamp: "2023-12-06T09:21:09Z"
  message: No matching pods found
  metadata:
    creationTimestamp: "2023-12-06T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2023-12-06T09:21:09Z"
    name: kube-apiserver-guard-pdb.179e339fa3bae908
    namespace: openshift-kube-apiserver
    resourceVersion: "5252"
    uid: dde99255-3357-468b-a96d-973fe9f346b2
  reason: NoPods
  reportingComponent: controllermanager
  reportingInstance: ""
  source:
    component: controllermanager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:24:53Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
  metadata:
    creationTimestamp: "2023-12-06T09:24:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d3c571519a
    namespace: openshift-kube-apiserver
    resourceVersion: "16400"
    uid: a429ef4f-83b4-4c64-9df8-919cbe1ab3af
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:04Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    in 10.289s (10.289s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:25:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:04Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d62abfa6c9
    namespace: openshift-kube-apiserver
    resourceVersion: "16706"
    uid: 2598adc0-2a9c-4e21-94ce-95fa53571c97
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:25:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6785af3f3
    namespace: openshift-kube-apiserver
    resourceVersion: "16728"
    uid: 5c41d01b-53bb-4caa-bccb-08c3d023cc2e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:25:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6796d3d44
    namespace: openshift-kube-apiserver
    resourceVersion: "16731"
    uid: add0053d-98c0-4953-9752-0ce369f8502e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d690cb3a28
    namespace: openshift-kube-apiserver
    resourceVersion: "16746"
    uid: add5cdf9-4a19-4063-b837-b5ca269fdfbb
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:25:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d697e13e09
    namespace: openshift-kube-apiserver
    resourceVersion: "16750"
    uid: 9e791fe1-c6a4-4c1c-bcb7-a000051a1814
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:25:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d698c356cc
    namespace: openshift-kube-apiserver
    resourceVersion: "16752"
    uid: 00bcf865-bad4-4a3c-b47c-5ab6850a575e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d698d10625
    namespace: openshift-kube-apiserver
    resourceVersion: "16753"
    uid: d1e63b7a-33e3-4056-8b75-9f8b7233e74a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6a0bb0303
    namespace: openshift-kube-apiserver
    resourceVersion: "16762"
    uid: ebab8b67-2752-450e-8373-1ef8241dfb37
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6a1752185
    namespace: openshift-kube-apiserver
    resourceVersion: "16763"
    uid: 2488f59e-0d4a-4560-9cc7-65a4e35d1bdb
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6a17ff9be
    namespace: openshift-kube-apiserver
    resourceVersion: "16766"
    uid: afd2c097-8cc7-43fe-864e-9c093b61aea5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6ab1c4e3f
    namespace: openshift-kube-apiserver
    resourceVersion: "16774"
    uid: 82467a0a-89f6-472c-886d-17acb9bd2e09
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6ac3fe1dc
    namespace: openshift-kube-apiserver
    resourceVersion: "16777"
    uid: 9f9d10b4-acad-4a08-a7f4-200419511e25
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6ac4d1be6
    namespace: openshift-kube-apiserver
    resourceVersion: "16778"
    uid: 5f11544a-6a49-48cb-85ba-c81bed221b66
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6b79288ba
    namespace: openshift-kube-apiserver
    resourceVersion: "16781"
    uid: e3c99f6e-b7b7-46b2-b68a-9a2c9b79ffc4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6b978bed9
    namespace: openshift-kube-apiserver
    resourceVersion: "16782"
    uid: e33e9b12-f36c-4572-853c-6bdd38dc0ff4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6b985c2f1
    namespace: openshift-kube-apiserver
    resourceVersion: "16783"
    uid: 0ef91253-f806-4051-97bb-8c6cd8b2c43d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6c4c51867
    namespace: openshift-kube-apiserver
    resourceVersion: "16787"
    uid: 3b9d165d-c930-4f40-84ef-5364f38b3d55
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d6c678d0e5
    namespace: openshift-kube-apiserver
    resourceVersion: "16788"
    uid: e0313130-d458-4c6d-9f73-3763ffde61ce
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:08Z"
  message: |+
    Startup probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [-]poststarthook/rbac/bootstrap-roles failed: reason withheld
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    healthz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:25:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:08Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d745753538
    namespace: openshift-kube-apiserver
    resourceVersion: "16831"
    uid: 2e50873e-54ae-466b-8af6-bafaeb0f7614
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:25:08Z"
  message: 'Startup probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2023-12-06T09:25:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:08Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d74575aa55
    namespace: openshift-kube-apiserver
    resourceVersion: "16832"
    uid: f4078ca8-e674-4492-a235-9dec55417dbc
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:25:09Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33d7603fc5b1
    namespace: openshift-kube-apiserver
    resourceVersion: "16840"
    uid: e8b8ab2f-7578-49a9-859b-d98df668b831
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:27:13Z"
  message: |+
    Liveness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    livez check failed

  metadata:
    creationTimestamp: "2023-12-06T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:13Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33f45de8b0d1
    namespace: openshift-kube-apiserver
    resourceVersion: "20814"
    uid: 24f2df89-3a2e-44ca-be23-3df54789a392
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:27:13Z"
  message: 'Liveness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2023-12-06T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:13Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33f45de914be
    namespace: openshift-kube-apiserver
    resourceVersion: "20815"
    uid: 3130e67c-db5a-4b09-bc83-687a47251429
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:17Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:27:17Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [-]etcd-readiness failed: reason withheld
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-service-ip-repair-controllers ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [+]shutdown ok
    readyz check failed

  metadata:
    creationTimestamp: "2023-12-06T09:27:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:17Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33f54c4f7a3e
    namespace: openshift-kube-apiserver
    resourceVersion: "20923"
    uid: cd5e27e5-dbb2-4135-9c0a-cebb32682517
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:17Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:27:17Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2023-12-06T09:27:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:17Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33f54c501570
    namespace: openshift-kube-apiserver
    resourceVersion: "20924"
    uid: 7a615130-d3ad-4a6d-bed6-21b33c725199
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2023-12-06T09:27:45Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e33fbc4dbcf8b
    namespace: openshift-kube-apiserver
    resourceVersion: "21497"
    uid: 1a243ae3-1dbf-4925-91c3-ef390a3a34f5
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 2m9s finished
  metadata:
    creationTimestamp: "2023-12-06T09:29:45Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3417c244ba79
    namespace: openshift-kube-apiserver
    resourceVersion: "23465"
    uid: ff430b97-ea08-482c-88e2-ba7b2e4984ef
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2023-12-06T09:29:45Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3417c2bb7cca
    namespace: openshift-kube-apiserver
    resourceVersion: "23466"
    uid: 8e4c22b2-de49-4fbf-806c-0c6797a9fb70
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2023-12-06T09:29:45Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3417c2d72e55
    namespace: openshift-kube-apiserver
    resourceVersion: "23467"
    uid: 656e085c-3426-49be-8f42-d0ee7df69f34
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2023-12-06T09:29:47Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34183a11483d
    namespace: openshift-kube-apiserver
    resourceVersion: "23498"
    uid: 6d6d91ab-82e2-46d4-bed7-86f07676a840
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:29:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3418f0a1d480
    namespace: openshift-kube-apiserver
    resourceVersion: "23545"
    uid: 10110c82-e3ee-4968-9879-1ee56e7cdc5a
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:30:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 6b904ae22112c7189e1c942c89adea07
  kind: Event
  lastTimestamp: "2023-12-06T09:30:30Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:30:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:30:30Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34222359e3af
    namespace: openshift-kube-apiserver
    resourceVersion: "24099"
    uid: 370043a9-9704-4803-ade6-00d82438daaf
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2023-12-06T09:30:30Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3422240d10eb
    namespace: openshift-kube-apiserver
    resourceVersion: "24100"
    uid: c355309c-4e1d-4103-a7c5-068837dc4586
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2023-12-06T09:30:30Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e342226575b13
    namespace: openshift-kube-apiserver
    resourceVersion: "24108"
    uid: 759aa463-4f00-47b6-8e92-1b2973ba6eda
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 2m9s finished
  metadata:
    creationTimestamp: "2023-12-06T09:32:39Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34402deff356
    namespace: openshift-kube-apiserver
    resourceVersion: "25611"
    uid: e2305908-4321-49f8-9ae2-016fed4dc914
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2023-12-06T09:32:39Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34402e652d29
    namespace: openshift-kube-apiserver
    resourceVersion: "25612"
    uid: d0267831-eb99-48f3-ae1d-b24f5a99d9f4
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2023-12-06T09:32:39Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34402e8ec25d
    namespace: openshift-kube-apiserver
    resourceVersion: "25613"
    uid: 18b013e8-6cac-4ef6-aeda-f617aacf061a
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2023-12-06T09:32:40Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34406e1d77a4
    namespace: openshift-kube-apiserver
    resourceVersion: "25631"
    uid: 522b2969-3a4e-4183-a4e2-1c07f3c4163b
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:52Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:32:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:52Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e344321768522
    namespace: openshift-kube-apiserver
    resourceVersion: "25759"
    uid: 7d0c9084-5538-4467-ad32-70bfb17ca2d4
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:52Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:32:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:52Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e344326cf6893
    namespace: openshift-kube-apiserver
    resourceVersion: "25761"
    uid: 72c68951-5ff9-45a3-abd6-ff3a34ee846d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:52Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:32:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:52Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3443277ae834
    namespace: openshift-kube-apiserver
    resourceVersion: "25762"
    uid: bb56b481-e965-496d-b60d-016463eea817
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34435c961bb3
    namespace: openshift-kube-apiserver
    resourceVersion: "25769"
    uid: e0e7cdc7-4e81-4ed0-b20b-b32496fa9775
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34436288cefd
    namespace: openshift-kube-apiserver
    resourceVersion: "25773"
    uid: c1bf8490-8a3f-4c7c-a439-2f86140dd92a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3443633bdaeb
    namespace: openshift-kube-apiserver
    resourceVersion: "25774"
    uid: 5342c4ad-b47a-4c47-9595-3d683b5994c8
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e344363468ad4
    namespace: openshift-kube-apiserver
    resourceVersion: "25775"
    uid: fef8ae5d-7e44-4a36-aea1-c6a99d394d86
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34436a59af41
    namespace: openshift-kube-apiserver
    resourceVersion: "25776"
    uid: ccbed0da-e8cb-4c6a-ae13-90062f377d5c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34436b1cff52
    namespace: openshift-kube-apiserver
    resourceVersion: "25777"
    uid: 734d34b3-fb4c-440d-ad56-3c92b028aa3f
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34436b2724fd
    namespace: openshift-kube-apiserver
    resourceVersion: "25778"
    uid: 2578d144-effd-40d5-9028-935b357b59c5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34437283410f
    namespace: openshift-kube-apiserver
    resourceVersion: "25780"
    uid: e2f5303a-4f61-49d8-9ddb-26da034d50d9
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34437349697f
    namespace: openshift-kube-apiserver
    resourceVersion: "25782"
    uid: 07d205e6-be34-44bd-af81-c87da18c862c
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34437359727f
    namespace: openshift-kube-apiserver
    resourceVersion: "25783"
    uid: 98dc12e4-b5a4-47d7-8ae1-11807f559c58
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34437c3b6734
    namespace: openshift-kube-apiserver
    resourceVersion: "25788"
    uid: 199405b1-37b0-4617-a3c9-1e38737994f1
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34437d791a3e
    namespace: openshift-kube-apiserver
    resourceVersion: "25789"
    uid: 56174dc6-93f0-4c7f-8c11-e704fb347918
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34437d86c631
    namespace: openshift-kube-apiserver
    resourceVersion: "25790"
    uid: 880c4c62-08ff-4b60-9da1-e243f4bc3ae6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3443895d85d8
    namespace: openshift-kube-apiserver
    resourceVersion: "25792"
    uid: 5971ea09-9185-473a-b20c-c6c93f6e0232
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:32:53Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:32:53Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:32:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:32:53Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34438b2b0f71
    namespace: openshift-kube-apiserver
    resourceVersion: "25793"
    uid: 27bbd9c7-8bdc-4ac3-aa80-c7982befa098
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:32:56Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3444293bcacd
    namespace: openshift-kube-apiserver
    resourceVersion: "25835"
    uid: 9daf3815-63bc-4519-81ad-b6a72b542d3e
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:36:12Z"
  message: Stopping container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:36:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3471bdd7306c
    namespace: openshift-kube-apiserver
    resourceVersion: "28327"
    uid: c5427406-c4d0-462d-9b67-9d2445b457a0
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:36:12Z"
  message: Stopping container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:36:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3471bdd9d2bb
    namespace: openshift-kube-apiserver
    resourceVersion: "28328"
    uid: 24eb56d9-0407-4744-bac1-c51e6cf0cb77
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:36:12Z"
  message: Stopping container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:36:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3471bde25414
    namespace: openshift-kube-apiserver
    resourceVersion: "28329"
    uid: 052d3097-6387-4a25-9d8a-9b65f38a1cd2
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:36:12Z"
  message: Stopping container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:36:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3471bde78372
    namespace: openshift-kube-apiserver
    resourceVersion: "28332"
    uid: 2e2f2558-c9e3-4f49-9c26-889d9aafe747
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 5187b61fc06a8c17e1c9ddd5e3cd4a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:36:12Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:36:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3471bdf02540
    namespace: openshift-kube-apiserver
    resourceVersion: "28333"
    uid: 96a155cd-4e87-41cc-9b63-ade8a5f90d06
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3471bec01071
    namespace: openshift-kube-apiserver
    resourceVersion: "28331"
    uid: 0dc79f2f-cacb-46a8-a953-7c850c64c0d2
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2023-12-06T09:36:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3471c0795e71
    namespace: openshift-kube-apiserver
    resourceVersion: "28336"
    uid: 48d875ae-db89-4527-a0db-0c2495de93ad
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 2m9s finished
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e348fc85dd7da
    namespace: openshift-kube-apiserver
    resourceVersion: "30422"
    uid: f0fcb5d5-62a9-4682-9d3c-2ca7a73b123a
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e348fc8d0202f
    namespace: openshift-kube-apiserver
    resourceVersion: "30423"
    uid: 29ee4b61-0db9-4f1a-ace0-7c51263e4a3c
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e348fc9318835
    namespace: openshift-kube-apiserver
    resourceVersion: "30424"
    uid: 4ba31419-31e3-4726-8838-27397d9cc618
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2023-12-06T09:38:22Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490076c9354
    namespace: openshift-kube-apiserver
    resourceVersion: "30450"
    uid: 66dae9b7-6c10-4983-b4d0-a37f1e450b57
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490b32afb48
    namespace: openshift-kube-apiserver
    resourceVersion: "30488"
    uid: 7bbc29bd-7b31-4fdf-9c27-8acebd1b9a5d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:25Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:38:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490b928fa16
    namespace: openshift-kube-apiserver
    resourceVersion: "30489"
    uid: 210986ee-d5b7-496d-8a2f-73748f2b77bf
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:25Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:38:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490b9df7d54
    namespace: openshift-kube-apiserver
    resourceVersion: "30490"
    uid: 388aa82a-407d-499d-9f46-e0e380bf8f77
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490e0fe9536
    namespace: openshift-kube-apiserver
    resourceVersion: "30504"
    uid: cc823d42-fc86-44de-93b6-42b53d863449
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490e6ba7456
    namespace: openshift-kube-apiserver
    resourceVersion: "30508"
    uid: e6a2254c-8a77-4f7f-9c06-1edae0b38552
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490e77565f9
    namespace: openshift-kube-apiserver
    resourceVersion: "30509"
    uid: 698cd7d6-20f9-4b82-8998-1197b5631c6d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490e781ae35
    namespace: openshift-kube-apiserver
    resourceVersion: "30510"
    uid: fcc32f3b-609e-47c0-b5fa-17caba915bd6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490ee461078
    namespace: openshift-kube-apiserver
    resourceVersion: "30511"
    uid: 8efb79e1-8413-47be-869f-933eb719f1fe
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490ef185bb6
    namespace: openshift-kube-apiserver
    resourceVersion: "30512"
    uid: 455f531f-3474-47cd-a3d1-74673233fa51
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490ef231897
    namespace: openshift-kube-apiserver
    resourceVersion: "30513"
    uid: 213ddc0a-d5d4-4044-aee4-931b9bbb26d6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490f67ffa85
    namespace: openshift-kube-apiserver
    resourceVersion: "30514"
    uid: 07741eb0-2600-4f2a-8a1a-14740bc73926
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490f82c6b29
    namespace: openshift-kube-apiserver
    resourceVersion: "30515"
    uid: 987cd2bd-04bd-4d72-911f-282428e69ac7
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3490f83a42d1
    namespace: openshift-kube-apiserver
    resourceVersion: "30516"
    uid: 171ef408-9865-46d0-b351-6dbc97e062f9
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34910437a581
    namespace: openshift-kube-apiserver
    resourceVersion: "30520"
    uid: 0b298a17-e0c5-40ff-9bd2-4b9b0dfdf9e9
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34910655e800
    namespace: openshift-kube-apiserver
    resourceVersion: "30521"
    uid: 4b79fb4f-e602-461e-acd1-afc8911370bb
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e349106639fe6
    namespace: openshift-kube-apiserver
    resourceVersion: "30522"
    uid: 54e53bd3-63d3-4778-9b5e-cdca2c871b91
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34911180b8d1
    namespace: openshift-kube-apiserver
    resourceVersion: "30523"
    uid: 0e787966-4e10-4e98-841e-3ea9ee94e159
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:38:26Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:26Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3491130dd50b
    namespace: openshift-kube-apiserver
    resourceVersion: "30524"
    uid: 475b4787-ca1f-450d-8731-55f7e1efd890
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:38:29Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e3491bb736304
    namespace: openshift-kube-apiserver
    resourceVersion: "30934"
    uid: 07c05d68-411f-46fd-90f7-51f3c54943da
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:40:01Z"
  message: Stopping container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:40:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34a72d58b482
    namespace: openshift-kube-apiserver
    resourceVersion: "34289"
    uid: d6dd98e7-4a2f-429c-9cd7-64fbf8079be5
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:40:01Z"
  message: Stopping container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:40:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34a72d593970
    namespace: openshift-kube-apiserver
    resourceVersion: "34290"
    uid: a1524583-33e0-476b-9a29-2e44b717be09
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:40:01Z"
  message: Stopping container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:40:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34a72d5acfee
    namespace: openshift-kube-apiserver
    resourceVersion: "34291"
    uid: cd8efccd-5a50-46df-b224-946382f5bfa6
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:40:01Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:40:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34a72d5b827d
    namespace: openshift-kube-apiserver
    resourceVersion: "34293"
    uid: 29a0156f-cf28-4a8e-a093-69f4cb0a072e
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 1b05ee1d0e57ae652c5bd74af4a18b00
  kind: Event
  lastTimestamp: "2023-12-06T09:40:01Z"
  message: Stopping container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:40:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34a72d5c4e98
    namespace: openshift-kube-apiserver
    resourceVersion: "34296"
    uid: a0eb88de-7137-4d4b-9a1c-a9bd79a60104
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2023-12-06T09:40:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34a72e2c3b59
    namespace: openshift-kube-apiserver
    resourceVersion: "34294"
    uid: 0f4bfd10-28f4-487a-9d5a-7ff717861cbc
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2023-12-06T09:40:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34a731d4347f
    namespace: openshift-kube-apiserver
    resourceVersion: "34301"
    uid: d0de4ec0-41e2-4934-bcfa-30df4b1aedfb
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 2m9s finished
  metadata:
    creationTimestamp: "2023-12-06T09:42:10Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c5389d2403
    namespace: openshift-kube-apiserver
    resourceVersion: "36874"
    uid: d7c4dff4-4fe4-4e21-a0e9-79a160715366
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2023-12-06T09:42:10Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c53925c9d5
    namespace: openshift-kube-apiserver
    resourceVersion: "36875"
    uid: 84be946d-5d10-48ea-96f6-4faacfb629a1
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2023-12-06T09:42:10Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c5397b6885
    namespace: openshift-kube-apiserver
    resourceVersion: "36876"
    uid: 1c222cd6-ec3b-431a-b09b-1ac1e6df1fa2
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2023-12-06T09:42:12Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c5b0894909
    namespace: openshift-kube-apiserver
    resourceVersion: "36911"
    uid: d8cd27f5-84df-4a0d-a1e4-c09bbd1b7c8f
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:24Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:24Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c8503d738a
    namespace: openshift-kube-apiserver
    resourceVersion: "37022"
    uid: 42e72683-60db-46f9-8600-294c95932b06
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:24Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:42:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:24Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c8565b440b
    namespace: openshift-kube-apiserver
    resourceVersion: "37023"
    uid: 013eb8d1-69ff-49a5-95eb-d0c1e35b885c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:24Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:42:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:24Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c8572a7ed4
    namespace: openshift-kube-apiserver
    resourceVersion: "37025"
    uid: ed362e6a-c624-4037-a2a1-2b767c9b313d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:24Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:24Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c87949cab0
    namespace: openshift-kube-apiserver
    resourceVersion: "37028"
    uid: d1364fe4-b030-4b34-8299-5f3b66dc8b57
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:24Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:42:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:24Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c87f4a8315
    namespace: openshift-kube-apiserver
    resourceVersion: "37033"
    uid: ffb934a4-6620-4230-a66f-b8a488d7ae9f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:24Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:42:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:24Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c88011658a
    namespace: openshift-kube-apiserver
    resourceVersion: "37035"
    uid: 9e15025e-61b1-4a21-961e-44629ef287ce
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:24Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:24Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c8801d810c
    namespace: openshift-kube-apiserver
    resourceVersion: "37036"
    uid: 27729e60-78da-49ca-8e0a-bffec7ef1d81
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c887246c0d
    namespace: openshift-kube-apiserver
    resourceVersion: "37037"
    uid: 1724b5c7-ce70-45b5-942b-4bfdee0ecacc
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c887ea4225
    namespace: openshift-kube-apiserver
    resourceVersion: "37038"
    uid: b504df4e-a5b2-49d9-8542-c47813a1f9da
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c887f6270b
    namespace: openshift-kube-apiserver
    resourceVersion: "37039"
    uid: b10d6725-98c2-458d-9c85-bf100f8154bb
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c88f1cd6a8
    namespace: openshift-kube-apiserver
    resourceVersion: "37041"
    uid: 59967f69-eecc-4ab4-a6be-cdb4ad8f640c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c88fdceb3f
    namespace: openshift-kube-apiserver
    resourceVersion: "37042"
    uid: 399a50ec-8758-436c-be85-6e234befdb41
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c88fe63222
    namespace: openshift-kube-apiserver
    resourceVersion: "37043"
    uid: 1a8d3e32-79da-4284-8511-052e5ade7690
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c897e866c3
    namespace: openshift-kube-apiserver
    resourceVersion: "37044"
    uid: 3c62b257-3b96-4670-bcc5-70c35f8e1ba9
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c898bf24f1
    namespace: openshift-kube-apiserver
    resourceVersion: "37045"
    uid: 02aa6236-6fe4-402e-9f1f-4370932d1096
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c898cbaa3d
    namespace: openshift-kube-apiserver
    resourceVersion: "37046"
    uid: 5b66912d-cae4-4906-afbb-adcd60056273
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c8a1a5d00b
    namespace: openshift-kube-apiserver
    resourceVersion: "37048"
    uid: 4130da70-f6fa-4a48-971d-7c0c763935af
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:25Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:25Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c8a2a89374
    namespace: openshift-kube-apiserver
    resourceVersion: "37049"
    uid: 91befe8a-dc19-4dbd-95d8-45fe45734ad7
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:42:28Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34c95b181ad3
    namespace: openshift-kube-apiserver
    resourceVersion: "37079"
    uid: b79295cf-af54-42a1-aca2-3e25ff263d9b
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:50Z"
  message: Stopping container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7a2e50b8
    namespace: openshift-kube-apiserver
    resourceVersion: "37449"
    uid: 6ca4cba4-c4be-43a2-a147-2a9c84c0b75e
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:50Z"
  message: Stopping container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7a3111b1
    namespace: openshift-kube-apiserver
    resourceVersion: "37450"
    uid: bde04c6e-0b4b-4b76-adf3-5518b1c4d286
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:50Z"
  message: Stopping container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7a31226a
    namespace: openshift-kube-apiserver
    resourceVersion: "37452"
    uid: 3f5bf143-8f87-4722-8838-2523cd239860
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:50Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7a31d944
    namespace: openshift-kube-apiserver
    resourceVersion: "37454"
    uid: b3584513-0d7e-4f7b-9140-8588c786fce4
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: ff48a57d50c5217cb37929254081594d
  kind: Event
  lastTimestamp: "2023-12-06T09:42:50Z"
  message: Stopping container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7a35e6e7
    namespace: openshift-kube-apiserver
    resourceVersion: "37455"
    uid: 2e41af91-05fe-4ab0-93ae-54943a23fd60
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7ad7490a
    namespace: openshift-kube-apiserver
    resourceVersion: "37451"
    uid: b6177522-b573-42d0-a380-f266bb550f1d
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2023-12-06T09:42:50Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ce7c9d7794
    namespace: openshift-kube-apiserver
    resourceVersion: "37458"
    uid: 42c1376d-48e7-4602-89a5-33405d4265f8
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 2m9s finished
  metadata:
    creationTimestamp: "2023-12-06T09:44:59Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ec8427137b
    namespace: openshift-kube-apiserver
    resourceVersion: "38903"
    uid: 6699b46e-0cd1-4dfd-ab53-43bffaedcfaf
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2023-12-06T09:44:59Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ec84992816
    namespace: openshift-kube-apiserver
    resourceVersion: "38904"
    uid: 00e1baf2-8636-4bea-9c08-bff05aec2f50
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2023-12-06T09:44:59Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ec84bc04f0
    namespace: openshift-kube-apiserver
    resourceVersion: "38905"
    uid: 2f6c9b0b-122c-4cd9-8870-d0b1368fe172
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2023-12-06T09:45:01Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ecfbf2267b
    namespace: openshift-kube-apiserver
    resourceVersion: "38949"
    uid: dd6bcee2-5765-44f6-bba4-553310a258f7
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee42e58433
    namespace: openshift-kube-apiserver
    resourceVersion: "39023"
    uid: 4cac2fe9-9d67-4cfc-b7c7-9587f6a2390b
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee4a02537b
    namespace: openshift-kube-apiserver
    resourceVersion: "39024"
    uid: 8d42ae98-c473-458f-a8ea-d7e9b21f5acb
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee4ac9dfd2
    namespace: openshift-kube-apiserver
    resourceVersion: "39026"
    uid: 0e94690d-3357-4923-944f-7dc2e53b29a3
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee4dd8641c
    namespace: openshift-kube-apiserver
    resourceVersion: "39027"
    uid: b8fbadfd-5fb9-4e0a-ab42-f96cf77eea12
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee53bae8fe
    namespace: openshift-kube-apiserver
    resourceVersion: "39031"
    uid: e34118c4-d980-4196-8b2b-87c372036d80
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee54704347
    namespace: openshift-kube-apiserver
    resourceVersion: "39032"
    uid: cc8dfc87-499d-4228-9414-50bce71e708f
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee547a4be1
    namespace: openshift-kube-apiserver
    resourceVersion: "39033"
    uid: d3e47288-4f47-4cab-ab7e-6943e2928a9d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee5b537bca
    namespace: openshift-kube-apiserver
    resourceVersion: "39035"
    uid: bf0dacb7-e282-4593-a0c3-e642b685b9b0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee5c671ed9
    namespace: openshift-kube-apiserver
    resourceVersion: "39036"
    uid: 885c3dea-38ad-45a8-a3f8-fc99a9ae3f0e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee5c72dae4
    namespace: openshift-kube-apiserver
    resourceVersion: "39037"
    uid: 386401da-2408-4d49-b5e3-943a8d7241c8
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee63712ad7
    namespace: openshift-kube-apiserver
    resourceVersion: "39039"
    uid: 57632891-d0bc-409b-8634-32c431fb59a8
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee642d6ebb
    namespace: openshift-kube-apiserver
    resourceVersion: "39040"
    uid: 71b74903-8f5c-4651-8d14-3d1b9a43ae27
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee64375a27
    namespace: openshift-kube-apiserver
    resourceVersion: "39041"
    uid: e6f9d09d-1196-4297-b184-9e563860ea61
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee6dca0c94
    namespace: openshift-kube-apiserver
    resourceVersion: "39042"
    uid: b562dd41-d197-4c16-9e31-37248c993948
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee6eeb55b0
    namespace: openshift-kube-apiserver
    resourceVersion: "39043"
    uid: 5ca2a6c9-08f2-4e45-ac2d-694eb0419679
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:07Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee6efcd395
    namespace: openshift-kube-apiserver
    resourceVersion: "39044"
    uid: a7166ca1-d537-4d30-b75a-04c1a57fc9ee
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:08Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:45:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:08Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee7964dce2
    namespace: openshift-kube-apiserver
    resourceVersion: "39048"
    uid: 0818f70f-2a5b-4093-aef9-da2e0c34d400
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: eb2ad82b8e1f4816142e791bc782e40b
  kind: Event
  lastTimestamp: "2023-12-06T09:45:08Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:45:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:08Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ee7bca9277
    namespace: openshift-kube-apiserver
    resourceVersion: "39049"
    uid: b645e8fa-152b-40ee-86f7-057bf799a36e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:45:10Z"
    name: kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal.179e34ef25dc8f74
    namespace: openshift-kube-apiserver
    resourceVersion: "39085"
    uid: cacc8e59-108e-4fd7-9f90-65f536da5f88
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-106-212
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f6f8672b4d
    namespace: openshift-kube-apiserver
    resourceVersion: "21030"
    uid: af7dec7c-e708-4dc3-b98c-7ef45557726c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f7000f97b6
    namespace: openshift-kube-apiserver
    resourceVersion: "21031"
    uid: 6917858f-8d25-4e72-805c-01fa99981464
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f700e12f97
    namespace: openshift-kube-apiserver
    resourceVersion: "21033"
    uid: 99b643c9-0fd4-4d38-9636-692f9af52bdf
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f7191c9dba
    namespace: openshift-kube-apiserver
    resourceVersion: "21044"
    uid: 2dcc1b2d-4d14-431f-bd3b-84a92f6a91c9
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f71fadb5c8
    namespace: openshift-kube-apiserver
    resourceVersion: "21049"
    uid: 0db6a0d2-4623-4d21-aa5c-08010356307d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f7206bbb63
    namespace: openshift-kube-apiserver
    resourceVersion: "21050"
    uid: 6f795b5b-30ca-419a-99c4-171e266acb7e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f7207741e3
    namespace: openshift-kube-apiserver
    resourceVersion: "21051"
    uid: af5242af-96af-4ad7-b2c4-2e19a3bd8015
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f729185fed
    namespace: openshift-kube-apiserver
    resourceVersion: "21059"
    uid: 9049a8b4-d1b0-4706-b5ae-5a8deae6f111
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f72a67af81
    namespace: openshift-kube-apiserver
    resourceVersion: "21060"
    uid: 89ad7431-7959-47b8-ba5e-d23795a90dd6
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:25Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:27:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:25Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f72aa243a4
    namespace: openshift-kube-apiserver
    resourceVersion: "21061"
    uid: 1276d285-217b-4b88-a4eb-6d89ce2426d1
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f7339394e9
    namespace: openshift-kube-apiserver
    resourceVersion: "21064"
    uid: 9bd80bed-5cfd-4eff-b640-19a3a94906d4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f7349099ee
    namespace: openshift-kube-apiserver
    resourceVersion: "21065"
    uid: cf0d1f9c-0c64-41fc-a8b2-95926bada96d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f7349dc4ad
    namespace: openshift-kube-apiserver
    resourceVersion: "21066"
    uid: cfcd5895-1098-43fe-aed8-07d2fb0985ad
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f73fa21989
    namespace: openshift-kube-apiserver
    resourceVersion: "21071"
    uid: 1776524f-523a-4773-884d-f3d924088e85
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f740a5a9a3
    namespace: openshift-kube-apiserver
    resourceVersion: "21072"
    uid: 030a445c-ac39-4eda-9ba7-07df90bd5335
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f740b18019
    namespace: openshift-kube-apiserver
    resourceVersion: "21073"
    uid: 35268581-20df-4c28-bccf-407a6994e929
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f74c67bc6d
    namespace: openshift-kube-apiserver
    resourceVersion: "21077"
    uid: 1ba06d11-2ab9-4593-943f-b3b1a9492b36
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:27:26Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:27:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:27:26Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f74d672c5e
    namespace: openshift-kube-apiserver
    resourceVersion: "21078"
    uid: 76b2761e-002c-4a21-bf6a-32fec6b44d60
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:27:29Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e33f80ffde0af
    namespace: openshift-kube-apiserver
    resourceVersion: "21152"
    uid: 1c6a1158-2925-4abd-9196-a383051761d0
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:48Z"
  message: Stopping container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:48Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3505e18bf877
    namespace: openshift-kube-apiserver
    resourceVersion: "40171"
    uid: 65f92b5c-cf8e-49d5-b0c4-28976f851082
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:48Z"
  message: Stopping container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:48Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3505e18ca6b0
    namespace: openshift-kube-apiserver
    resourceVersion: "40173"
    uid: d9011485-e8c1-496a-ab55-9d50b49d3c4d
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:48Z"
  message: Stopping container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:48Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3505e18dd6cc
    namespace: openshift-kube-apiserver
    resourceVersion: "40177"
    uid: 8ee0279e-091c-4bd4-81c8-1150fa4d930b
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:48Z"
  message: Stopping container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:48Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3505e18fb0df
    namespace: openshift-kube-apiserver
    resourceVersion: "40178"
    uid: 70b850b5-36b8-4665-967c-44156ae24eb7
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 72c84859cfeee6548ea8801cd0cf57d6
  kind: Event
  lastTimestamp: "2023-12-06T09:46:48Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:46:48Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3505e190f86a
    namespace: openshift-kube-apiserver
    resourceVersion: "40181"
    uid: 56d827b1-e33f-46fa-b8d7-b7cb3892a46e
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3505e26dda30
    namespace: openshift-kube-apiserver
    resourceVersion: "40175"
    uid: 428ebde9-30b7-4f5a-82a1-bd7672cd845d
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2023-12-06T09:46:48Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3505e504413d
    namespace: openshift-kube-apiserver
    resourceVersion: "40180"
    uid: 5f7f777b-3b12-484f-b037-6a5f71019863
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 2m9s finished
  metadata:
    creationTimestamp: "2023-12-06T09:48:57Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3523ec21c2fa
    namespace: openshift-kube-apiserver
    resourceVersion: "41399"
    uid: 029fa3ae-4372-45dc-8d74-0fa950d0e594
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2023-12-06T09:48:57Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3523ecaf9e67
    namespace: openshift-kube-apiserver
    resourceVersion: "41400"
    uid: 03d23c18-7319-4951-accb-bd1fafdfec17
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2023-12-06T09:48:57Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3523ed3d0421
    namespace: openshift-kube-apiserver
    resourceVersion: "41401"
    uid: 282a733f-5b21-4ecc-9653-511b29ca49e5
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2023-12-06T09:48:59Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35246475a105
    namespace: openshift-kube-apiserver
    resourceVersion: "41420"
    uid: 0267b2c0-abda-463b-bc79-080f03fc22af
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:49:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35253ad3ec17
    namespace: openshift-kube-apiserver
    resourceVersion: "41469"
    uid: e285dd68-e66b-40a1-bae2-06d60641b8cb
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:49:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e352542608c23
    namespace: openshift-kube-apiserver
    resourceVersion: "41470"
    uid: cb0095ff-ae79-473e-8eb4-88794662148a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:49:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3525433f0772
    namespace: openshift-kube-apiserver
    resourceVersion: "41471"
    uid: 80f3673f-a535-40f2-b9bd-68674cf4fa92
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:49:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35255b7b534b
    namespace: openshift-kube-apiserver
    resourceVersion: "41473"
    uid: 38240398-54a1-4010-bb25-2eacc83b0953
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:49:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3525624ab6bd
    namespace: openshift-kube-apiserver
    resourceVersion: "41477"
    uid: 7ad378e8-6162-4722-afcd-72373fe8eb67
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:49:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e352563332d1b
    namespace: openshift-kube-apiserver
    resourceVersion: "41478"
    uid: 07702754-bc79-4bea-b09e-740fbc123809
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:03Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:49:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:03Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35256342f0a1
    namespace: openshift-kube-apiserver
    resourceVersion: "41479"
    uid: e7e5fb75-680b-434f-92ec-178b17bd1d4e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35256b6209e0
    namespace: openshift-kube-apiserver
    resourceVersion: "41482"
    uid: 6e212016-2b68-48ec-b244-30cd896ef235
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35256c4e5d40
    namespace: openshift-kube-apiserver
    resourceVersion: "41483"
    uid: c3e3f586-01a4-4cca-9a5d-c00cfd632208
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35256c63391a
    namespace: openshift-kube-apiserver
    resourceVersion: "41484"
    uid: ed09839e-249f-4dce-af65-4bbb6ca1517e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3525775a6bb4
    namespace: openshift-kube-apiserver
    resourceVersion: "41486"
    uid: 00fb5e5f-9e91-41ae-a87a-701c2bec773f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e352578410f89
    namespace: openshift-kube-apiserver
    resourceVersion: "41487"
    uid: 31dd36fe-e7ed-4200-984d-dcde14eb5bf4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3525784c81ff
    namespace: openshift-kube-apiserver
    resourceVersion: "41488"
    uid: c67a4a10-7800-430f-9de8-ff251c674537
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e3525815c697b
    namespace: openshift-kube-apiserver
    resourceVersion: "41491"
    uid: e1e70092-ec0f-4dec-862e-ef5c645bd18a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e352582513fe4
    namespace: openshift-kube-apiserver
    resourceVersion: "41492"
    uid: 906a7803-dab8-40f5-8104-4e7ffb6bde3d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35258260549b
    namespace: openshift-kube-apiserver
    resourceVersion: "41493"
    uid: 440419b1-2c2d-4aa6-b89e-2030c1f5b3d4
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35259027efb1
    namespace: openshift-kube-apiserver
    resourceVersion: "41495"
    uid: 42fe84a2-7f15-4f4b-81d1-15ba31d2f855
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: 771dcdcc2ffdc37a0141113de89bf2a4
  kind: Event
  lastTimestamp: "2023-12-06T09:49:04Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:49:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:49:04Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35259270fe62
    namespace: openshift-kube-apiserver
    resourceVersion: "41496"
    uid: 4157dedf-11f3-4207-8b2d-048147b5aaac
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:49:07Z"
    name: kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal.179e35264338293b
    namespace: openshift-kube-apiserver
    resourceVersion: "41526"
    uid: 022e828f-496a-44f5-8c21-904c6cd30283
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-21-63
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:58Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:28:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:58Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340cc1b08491
    namespace: openshift-kube-apiserver
    resourceVersion: "22727"
    uid: 663ae66f-1eb0-4d4a-8dc7-f7c5a359567f
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:58Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:28:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:58Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340cc758b158
    namespace: openshift-kube-apiserver
    resourceVersion: "22733"
    uid: 70cf5b35-d79a-4b69-b219-e8ddcda07706
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:58Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:28:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:58Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340cc821c3d3
    namespace: openshift-kube-apiserver
    resourceVersion: "22735"
    uid: b0d25cf1-d141-4cb7-8984-aeeed0efead6
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340cfe0bb1e1
    namespace: openshift-kube-apiserver
    resourceVersion: "22745"
    uid: be2252ef-6230-48a4-89b9-e0878e275dec
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d05daf1ee
    namespace: openshift-kube-apiserver
    resourceVersion: "22751"
    uid: a6b0c9e4-18d2-4689-8136-1cb006a5c018
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d06d601f2
    namespace: openshift-kube-apiserver
    resourceVersion: "22752"
    uid: 316d7ad3-e67d-46e7-9887-6618d4dac70f
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d06e0d65d
    namespace: openshift-kube-apiserver
    resourceVersion: "22753"
    uid: 940cae93-f6b9-4d3e-94e7-2f466b8ae71a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d0d9bb8a0
    namespace: openshift-kube-apiserver
    resourceVersion: "22754"
    uid: ec11be31-be06-4a09-a5e7-c311f7654427
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d0e5e4ee4
    namespace: openshift-kube-apiserver
    resourceVersion: "22755"
    uid: 44860748-cec9-4f91-b383-f8ae133ffeb2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d0e6af4dc
    namespace: openshift-kube-apiserver
    resourceVersion: "22756"
    uid: 726b5a96-718e-41cb-aa44-1bdcc1e356f5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:28:59Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:28:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:28:59Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d15b7ab3f
    namespace: openshift-kube-apiserver
    resourceVersion: "22764"
    uid: d6b6ad6e-2ed4-4b9e-8edc-74add5eb9d17
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:29:00Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:29:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:00Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d1679c11d
    namespace: openshift-kube-apiserver
    resourceVersion: "22765"
    uid: 7769c0bb-7d9d-4802-9a37-5f5493335dbf
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:29:00Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:29:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:00Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d16844267
    namespace: openshift-kube-apiserver
    resourceVersion: "22766"
    uid: 2c07dfc9-a88e-415d-ac08-3baa4f2f178e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:29:00Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:29:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:00Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d1e4d08a9
    namespace: openshift-kube-apiserver
    resourceVersion: "22782"
    uid: c5406f66-dbc2-4d6b-846f-1468e648808b
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:29:00Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:29:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:00Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d1f103336
    namespace: openshift-kube-apiserver
    resourceVersion: "22783"
    uid: 919a16fa-2261-4a6a-9700-fa5c9d598aeb
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:29:00Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:29:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:00Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d1f1a3941
    namespace: openshift-kube-apiserver
    resourceVersion: "22785"
    uid: e23fd395-8254-4592-8142-696a9b9fb5f7
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:29:00Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:29:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:00Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d280aefde
    namespace: openshift-kube-apiserver
    resourceVersion: "22790"
    uid: f38e66e9-1e74-452c-a46d-ee318e2f13da
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:29:00Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:29:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:29:00Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340d2969be90
    namespace: openshift-kube-apiserver
    resourceVersion: "22791"
    uid: dbd67f8e-b169-4992-aea3-39933c1bcf65
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:29:03Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e340dcd478a5d
    namespace: openshift-kube-apiserver
    resourceVersion: "22823"
    uid: c1cd44dd-5e18-4165-9fc9-637f01cd6899
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:50:43Z"
  message: Stopping container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:50:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:43Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e353ca8e883ef
    namespace: openshift-kube-apiserver
    resourceVersion: "42463"
    uid: 236780a8-f3d3-42a2-8352-1437b3597ccb
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:50:43Z"
  message: Stopping container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:50:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:43Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e353ca8e89aa1
    namespace: openshift-kube-apiserver
    resourceVersion: "42464"
    uid: 65ea5079-b395-4729-8fe4-cdd7eafba192
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:50:43Z"
  message: Stopping container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:50:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:43Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e353ca8e9da34
    namespace: openshift-kube-apiserver
    resourceVersion: "42465"
    uid: 9bc874f0-cca6-4598-9824-b2e4a6c85b29
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:50:43Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:50:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:43Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e353ca8eab71b
    namespace: openshift-kube-apiserver
    resourceVersion: "42467"
    uid: 05ddfbed-8633-4c00-bdfc-55d4e2eed994
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: fd9f9508f60d5dae553ca4781bb876ef
  kind: Event
  lastTimestamp: "2023-12-06T09:50:43Z"
  message: Stopping container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:50:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:50:43Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e353ca8eb012b
    namespace: openshift-kube-apiserver
    resourceVersion: "42468"
    uid: ca1950c0-f8b8-4bdd-8845-fb57f193ef57
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2023-12-06T09:50:43Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e353caa553713
    namespace: openshift-kube-apiserver
    resourceVersion: "42470"
    uid: fd11589a-f7be-44de-b300-c1a7c2a802b4
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2023-12-06T09:50:43Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e353cad20b2cf
    namespace: openshift-kube-apiserver
    resourceVersion: "42473"
    uid: d638f689-74f7-497d-8e79-9ea4a9f4d12c
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 2m9s finished
  metadata:
    creationTimestamp: "2023-12-06T09:52:52Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355ab4982ae7
    namespace: openshift-kube-apiserver
    resourceVersion: "43772"
    uid: 35e3ad1b-f772-4d79-9046-b19b8adb88bf
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2023-12-06T09:52:52Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355ab5088161
    namespace: openshift-kube-apiserver
    resourceVersion: "43773"
    uid: 3769f3b1-9248-4b8f-a8b4-b7bb62fd635d
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2023-12-06T09:52:52Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355ab5154b68
    namespace: openshift-kube-apiserver
    resourceVersion: "43774"
    uid: cbbd7dba-e34f-44bf-bec7-5680dcba70f7
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2023-12-06T09:52:54Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355b2c586c9d
    namespace: openshift-kube-apiserver
    resourceVersion: "43800"
    uid: cef80381-3bb4-42ad-8a53-0bd7bbca1226
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:07Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:53:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:07Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e2bd7c398
    namespace: openshift-kube-apiserver
    resourceVersion: "43932"
    uid: b3f12e86-5380-44f1-81fd-ac43e8946f9c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:07Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2023-12-06T09:53:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:07Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e31ad1163
    namespace: openshift-kube-apiserver
    resourceVersion: "43933"
    uid: ce3acea0-9a33-49c3-baeb-8df376cb0d3a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:07Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2023-12-06T09:53:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:07Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e32569898
    namespace: openshift-kube-apiserver
    resourceVersion: "43934"
    uid: 9e2d300a-f681-4bf7-855b-e1659cd62f62
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:08Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:53:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:08Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e65faada3
    namespace: openshift-kube-apiserver
    resourceVersion: "43946"
    uid: 0414d227-4e67-404f-a56c-2b1e4f8b82df
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:08Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:53:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:08Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e6c8c2cf0
    namespace: openshift-kube-apiserver
    resourceVersion: "43950"
    uid: 1f0249e2-ddf2-4f7d-819a-ae964bc57781
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:08Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2023-12-06T09:53:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:08Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e6d56428a
    namespace: openshift-kube-apiserver
    resourceVersion: "43951"
    uid: aa99d25c-f9cd-4a69-86ab-8cfb31415c80
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:08Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:53:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:08Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e6d611ba5
    namespace: openshift-kube-apiserver
    resourceVersion: "43952"
    uid: 3507e29a-8193-4646-a982-536005274f8b
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:08Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:53:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:08Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e74bf16f8
    namespace: openshift-kube-apiserver
    resourceVersion: "43953"
    uid: a4ea3af9-5832-44cc-a4e2-aa6720502a26
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e7594e91a
    namespace: openshift-kube-apiserver
    resourceVersion: "43954"
    uid: 32171154-efc1-483e-96a0-7358ad813b1a
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e759f7e79
    namespace: openshift-kube-apiserver
    resourceVersion: "43955"
    uid: 5e1cbf36-17b3-4817-9884-b1519ac27557
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e7ce1730f
    namespace: openshift-kube-apiserver
    resourceVersion: "43956"
    uid: 0d34e1ed-1d73-4915-add4-f1a4a0176f05
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e7dbfdbef
    namespace: openshift-kube-apiserver
    resourceVersion: "43957"
    uid: 4c61490e-0fb5-4649-96ed-a1f163adb996
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e7dca8359
    namespace: openshift-kube-apiserver
    resourceVersion: "43958"
    uid: 4a410d3b-dab3-4ab1-b786-9778ca82200f
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e86666b04
    namespace: openshift-kube-apiserver
    resourceVersion: "43961"
    uid: 7d78d9d7-6443-4026-8ecb-705c5757ce76
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e8997472e
    namespace: openshift-kube-apiserver
    resourceVersion: "43963"
    uid: d87b323c-7b15-4f2c-99f4-b537ecf0726e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e89a3e24a
    namespace: openshift-kube-apiserver
    resourceVersion: "43964"
    uid: dcf6c717-6d5d-47e3-be37-c6fee8034926
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e992cc707
    namespace: openshift-kube-apiserver
    resourceVersion: "43967"
    uid: 32b33056-9173-4563-98de-b542bb137ef3
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    uid: e267d72fdb7f932f1a260c914109e539
  kind: Event
  lastTimestamp: "2023-12-06T09:53:09Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2023-12-06T09:53:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:09Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355e9ac3250e
    namespace: openshift-kube-apiserver
    resourceVersion: "43968"
    uid: dd76a322-6a9d-4fcd-b082-2546ccd884f4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2023-12-06T09:53:12Z"
    name: kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal.179e355f482fcd7f
    namespace: openshift-kube-apiserver
    resourceVersion: "44002"
    uid: 556f4843-988c-44ac-8076-28e73f0ebc34
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: ip-10-0-94-160
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:10Z"
  involvedObject:
    apiVersion: v1
    kind: Namespace
    name: openshift-kube-apiserver
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: "2023-12-06T09:53:10Z"
  message: 'unable to get control plane topology, using HA cluster values for leader
    election: infrastructures.config.openshift.io "cluster" is forbidden: User "system:serviceaccount:openshift-kube-apiserver:localhost-recovery-client"
    cannot get resource "infrastructures" in API group "config.openshift.io" at the
    cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:public-info-viewer"
    not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found,
    clusterrole.rbac.authorization.k8s.io "system:build-strategy-source" not found,
    clusterrole.rbac.authorization.k8s.io "console-extensions-reader" not found, clusterrole.rbac.authorization.k8s.io
    "system:oauth-token-deleter" not found, clusterrole.rbac.authorization.k8s.io
    "helm-chartrepos-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:build-strategy-docker"
    not found, clusterrole.rbac.authorization.k8s.io "system:build-strategy-jenkinspipeline"
    not found, clusterrole.rbac.authorization.k8s.io "system:webhook" not found, clusterrole.rbac.authorization.k8s.io
    "cluster-status" not found, clusterrole.rbac.authorization.k8s.io "system:basic-user"
    not found, clusterrole.rbac.authorization.k8s.io "cluster-admin" not found, clusterrole.rbac.authorization.k8s.io
    "system:openshift:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io
    "system:scope-impersonation" not found, clusterrole.rbac.authorization.k8s.io
    "system:service-account-issuer-discovery" not found, clusterrole.rbac.authorization.k8s.io
    "system:openshift:discovery" not found, clusterrole.rbac.authorization.k8s.io
    "basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:openshift:scc:restricted-v2"
    not found, clusterrole.rbac.authorization.k8s.io "self-access-reviewer" not found]'
  metadata:
    creationTimestamp: "2023-12-06T09:53:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:53:10Z"
    name: openshift-kube-apiserver.179e355ee2f51463
    namespace: openshift-kube-apiserver
    resourceVersion: "43974"
    uid: 7fa83993-9308-41c4-aeb7-c56ae68f90eb
  reason: ControlPlaneTopology
  reportingComponent: cert-regeneration-controller
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:51Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47688"
    uid: 4eaf80f6-4433-4bf2-8ddc-46edbbb5643a
  kind: Event
  lastTimestamp: "2023-12-06T09:57:51Z"
  message: Add eth0 [10.128.0.67/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:57:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:57:51Z"
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal.179e35a0215119e6
    namespace: openshift-kube-apiserver
    resourceVersion: "47693"
    uid: 6020370b-cad6-449a-937f-23f594601739
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:51Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47685"
    uid: 4eaf80f6-4433-4bf2-8ddc-46edbbb5643a
  kind: Event
  lastTimestamp: "2023-12-06T09:57:51Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:57:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:51Z"
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal.179e35a02310ede0
    namespace: openshift-kube-apiserver
    resourceVersion: "47695"
    uid: 5cca8f0b-b108-4e4d-9924-0723f6713f30
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:51Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47685"
    uid: 4eaf80f6-4433-4bf2-8ddc-46edbbb5643a
  kind: Event
  lastTimestamp: "2023-12-06T09:57:51Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:57:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:51Z"
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal.179e35a03122f71b
    namespace: openshift-kube-apiserver
    resourceVersion: "47698"
    uid: 4a30a295-e775-4f34-8bb0-b5eb2ab2d58f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:51Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47685"
    uid: 4eaf80f6-4433-4bf2-8ddc-46edbbb5643a
  kind: Event
  lastTimestamp: "2023-12-06T09:57:51Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:57:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:51Z"
    name: revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal.179e35a032440600
    namespace: openshift-kube-apiserver
    resourceVersion: "47699"
    uid: 5a102a9e-a809-4724-ae32-e39d00b67a48
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:54Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47727"
    uid: 9367ec6f-7ab1-440e-8be0-aa47f33cef53
  kind: Event
  lastTimestamp: "2023-12-06T09:57:54Z"
  message: Add eth0 [10.129.0.92/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:57:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:57:54Z"
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal.179e35a0eb3fc111
    namespace: openshift-kube-apiserver
    resourceVersion: "47730"
    uid: 7019cc45-2702-49cb-99dc-85ab9923b5da
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:54Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47724"
    uid: 9367ec6f-7ab1-440e-8be0-aa47f33cef53
  kind: Event
  lastTimestamp: "2023-12-06T09:57:54Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:57:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:54Z"
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal.179e35a0ed7cd42d
    namespace: openshift-kube-apiserver
    resourceVersion: "47732"
    uid: fbb23246-eb6f-4b0b-bd15-f1b5576d2ad2
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:54Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47724"
    uid: 9367ec6f-7ab1-440e-8be0-aa47f33cef53
  kind: Event
  lastTimestamp: "2023-12-06T09:57:54Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:57:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:54Z"
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal.179e35a0feac468d
    namespace: openshift-kube-apiserver
    resourceVersion: "47735"
    uid: 6c30d2ac-13e3-432a-a073-77383bad84e7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:54Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47724"
    uid: 9367ec6f-7ab1-440e-8be0-aa47f33cef53
  kind: Event
  lastTimestamp: "2023-12-06T09:57:54Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:57:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:54Z"
    name: revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal.179e35a0ffbdf4d7
    namespace: openshift-kube-apiserver
    resourceVersion: "47736"
    uid: 436b09ee-1374-41cf-bd6d-823765dc0f53
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:57Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47755"
    uid: e558f095-c5e8-42b4-80c7-27aa50078b85
  kind: Event
  lastTimestamp: "2023-12-06T09:57:57Z"
  message: Add eth0 [10.130.0.51/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:57:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:57:57Z"
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal.179e35a1b2a3d9a7
    namespace: openshift-kube-apiserver
    resourceVersion: "47769"
    uid: 5ea647bc-faad-4b44-a658-dd1098c77274
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:57Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47751"
    uid: e558f095-c5e8-42b4-80c7-27aa50078b85
  kind: Event
  lastTimestamp: "2023-12-06T09:57:57Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:57:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:57Z"
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal.179e35a1b4800235
    namespace: openshift-kube-apiserver
    resourceVersion: "47772"
    uid: 9c7fb871-1764-4069-a224-7fe06ca57327
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47751"
    uid: e558f095-c5e8-42b4-80c7-27aa50078b85
  kind: Event
  lastTimestamp: "2023-12-06T09:57:58Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:57:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:58Z"
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal.179e35a1c0bf44ff
    namespace: openshift-kube-apiserver
    resourceVersion: "47776"
    uid: 050f3ae6-9279-4901-a8d0-c2c2b10456b8
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "47751"
    uid: e558f095-c5e8-42b4-80c7-27aa50078b85
  kind: Event
  lastTimestamp: "2023-12-06T09:57:58Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:57:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:58Z"
    name: revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal.179e35a1c18afbbf
    namespace: openshift-kube-apiserver
    resourceVersion: "47777"
    uid: 5fe072f8-2d11-4b00-9bb7-70ca70b8c268
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:00Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44494"
    uid: 44dacac3-3a70-4caa-ba6b-0b03636475d0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:00Z"
  message: Add eth0 [10.128.0.61/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:54:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:54:00Z"
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal.179e356a68bf1b89
    namespace: openshift-kube-apiserver
    resourceVersion: "44502"
    uid: 6b91e4e8-5eba-4ba0-bb09-283d2013be7b
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44491"
    uid: 44dacac3-3a70-4caa-ba6b-0b03636475d0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:00Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:54:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:00Z"
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal.179e356a6a59af79
    namespace: openshift-kube-apiserver
    resourceVersion: "44504"
    uid: b1c4432e-cf30-4800-8c2f-484402b35f0e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44491"
    uid: 44dacac3-3a70-4caa-ba6b-0b03636475d0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:00Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:54:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:00Z"
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal.179e356a72f9d405
    namespace: openshift-kube-apiserver
    resourceVersion: "44505"
    uid: cc125073-65fb-40d1-b341-4ee1fe8fc802
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44491"
    uid: 44dacac3-3a70-4caa-ba6b-0b03636475d0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:00Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:54:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:00Z"
    name: revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal.179e356a73cb1f8e
    namespace: openshift-kube-apiserver
    resourceVersion: "44506"
    uid: f43846ec-7ac4-4ce4-a09f-16ece78f931b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:03Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44556"
    uid: ed93f3eb-f15a-49ae-a0f4-fb4af440d35b
  kind: Event
  lastTimestamp: "2023-12-06T09:54:03Z"
  message: Add eth0 [10.129.0.90/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:54:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:54:03Z"
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal.179e356b2e98c71d
    namespace: openshift-kube-apiserver
    resourceVersion: "44568"
    uid: c90347b6-9a26-4798-be8e-63b0d326ed11
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44553"
    uid: ed93f3eb-f15a-49ae-a0f4-fb4af440d35b
  kind: Event
  lastTimestamp: "2023-12-06T09:54:03Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:54:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:03Z"
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal.179e356b30243d62
    namespace: openshift-kube-apiserver
    resourceVersion: "44571"
    uid: 791374aa-06ce-49fd-83dd-d97098d4e5d6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44553"
    uid: ed93f3eb-f15a-49ae-a0f4-fb4af440d35b
  kind: Event
  lastTimestamp: "2023-12-06T09:54:03Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:54:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:03Z"
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal.179e356b40fb1ff8
    namespace: openshift-kube-apiserver
    resourceVersion: "44580"
    uid: 0f50f591-8c1b-4e61-b3fd-86e6e52baaa7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44553"
    uid: ed93f3eb-f15a-49ae-a0f4-fb4af440d35b
  kind: Event
  lastTimestamp: "2023-12-06T09:54:03Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:54:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:03Z"
    name: revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal.179e356b41e96240
    namespace: openshift-kube-apiserver
    resourceVersion: "44582"
    uid: d0768ddd-2f31-4af1-bf18-a747e9d8cd56
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:06Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44608"
    uid: b37a1f80-6693-4ef1-8189-e324ce99bde0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:06Z"
  message: Add eth0 [10.130.0.50/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:54:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:54:06Z"
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal.179e356bcdc81955
    namespace: openshift-kube-apiserver
    resourceVersion: "44611"
    uid: 5dd980ae-aa76-4570-881c-dffcf4e7d402
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44605"
    uid: b37a1f80-6693-4ef1-8189-e324ce99bde0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:06Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:54:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:06Z"
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal.179e356bd15cb9b9
    namespace: openshift-kube-apiserver
    resourceVersion: "44613"
    uid: 1da9f707-cd20-46cc-afd4-5481fff0770d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44605"
    uid: b37a1f80-6693-4ef1-8189-e324ce99bde0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:06Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:54:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:06Z"
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal.179e356bdac46b90
    namespace: openshift-kube-apiserver
    resourceVersion: "44615"
    uid: 2e1c22c4-eff3-408a-a502-c614ca01797f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-apiserver
    resourceVersion: "44605"
    uid: b37a1f80-6693-4ef1-8189-e324ce99bde0
  kind: Event
  lastTimestamp: "2023-12-06T09:54:06Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2023-12-06T09:54:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:06Z"
    name: revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal.179e356bdb8ae68b
    namespace: openshift-kube-apiserver
    resourceVersion: "44616"
    uid: cdaa39d3-08b2-4c73-85df-f0f382b1d686
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
kind: EventList
metadata:
  resourceVersion: "47829"
