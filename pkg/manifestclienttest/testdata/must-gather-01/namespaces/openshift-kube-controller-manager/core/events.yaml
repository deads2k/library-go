---
apiVersion: v1
items:
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:22Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-recovery-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "30447"
    uid: b78141fe-c2ab-47c7-9953-750ec6ea3626
  kind: Event
  lastTimestamp: "2023-12-06T09:38:22Z"
  message: ip-10-0-21-63_63e09512-ddff-419b-b916-80769c5dc28d became leader
  metadata:
    creationTimestamp: "2023-12-06T09:38:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:38:22Z"
    name: cert-recovery-controller-lock.179e34900409018b
    namespace: openshift-kube-controller-manager
    resourceVersion: "30448"
    uid: 6eec04fa-b814-4eca-953c-ea1a0d7cfd39
  reason: LeaderElection
  reportingComponent: cert-recovery-controller
  reportingInstance: ""
  source:
    component: cert-recovery-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:03Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-recovery-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "37642"
    uid: b78141fe-c2ab-47c7-9953-750ec6ea3626
  kind: Event
  lastTimestamp: "2023-12-06T09:43:03Z"
  message: ip-10-0-94-160_f114e0e6-6335-4238-8801-1d0d9ab3c8f4 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:43:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:43:03Z"
    name: cert-recovery-controller-lock.179e34d184482db5
    namespace: openshift-kube-controller-manager
    resourceVersion: "37643"
    uid: e8f01e5f-1bc1-4678-aff3-a5fe18b0e8e6
  reason: LeaderElection
  reportingComponent: cert-recovery-controller
  reportingInstance: ""
  source:
    component: cert-recovery-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:48Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-recovery-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "38793"
    uid: b78141fe-c2ab-47c7-9953-750ec6ea3626
  kind: Event
  lastTimestamp: "2023-12-06T09:44:48Z"
  message: ip-10-0-106-212_c3562c87-1679-4056-9ff8-48eed5578851 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:44:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:44:48Z"
    name: cert-recovery-controller-lock.179e34e9f7989bfd
    namespace: openshift-kube-controller-manager
    resourceVersion: "38795"
    uid: 4020be60-b14c-4f4f-ad96-648c67c30184
  reason: LeaderElection
  reportingComponent: cert-recovery-controller
  reportingInstance: ""
  source:
    component: cert-recovery-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:14Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cluster-policy-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "12080"
    uid: 7bc282de-0a8b-4191-9ba0-6077bba64172
  kind: Event
  lastTimestamp: "2023-12-06T09:23:14Z"
  message: ip-10-0-21-63_cfa02e70-516c-4cc9-88ca-22bce6cd8348 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:23:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:23:14Z"
    name: cluster-policy-controller-lock.179e33bca3bda3da
    namespace: openshift-kube-controller-manager
    resourceVersion: "12082"
    uid: cb1e0de2-1fd4-424d-b4b0-8157292c04ab
  reason: LeaderElection
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cluster-policy-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "30439"
    uid: 7bc282de-0a8b-4191-9ba0-6077bba64172
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: ip-10-0-21-63_810df7a2-b173-4ceb-b679-3f12042df049 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: cluster-policy-controller-lock.179e348fec20e916
    namespace: openshift-kube-controller-manager
    resourceVersion: "30441"
    uid: 73c1d0b2-df3e-4767-91dd-308080bcce4b
  reason: LeaderElection
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:59Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cluster-policy-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "37582"
    uid: 7bc282de-0a8b-4191-9ba0-6077bba64172
  kind: Event
  lastTimestamp: "2023-12-06T09:42:59Z"
  message: ip-10-0-21-63_73c99530-ba5a-4efd-a8a2-884681e1a4b6 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:42:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:42:59Z"
    name: cluster-policy-controller-lock.179e34d074d88d9d
    namespace: openshift-kube-controller-manager
    resourceVersion: "37583"
    uid: bc2a7b2e-34fc-4601-98c0-bc16f8e8d075
  reason: LeaderElection
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:25Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cluster-policy-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "37836"
    uid: 7bc282de-0a8b-4191-9ba0-6077bba64172
  kind: Event
  lastTimestamp: "2023-12-06T09:43:25Z"
  message: ip-10-0-106-212_4b187b7c-7592-4f2c-9eec-379e50b9e933 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:43:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:43:25Z"
    name: cluster-policy-controller-lock.179e34d6b6b66be1
    namespace: openshift-kube-controller-manager
    resourceVersion: "37837"
    uid: bd6e0f88-01cc-4c63-89f1-51a881f9ceac
  reason: LeaderElection
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cluster-policy-controller-lock
    namespace: openshift-kube-controller-manager
    resourceVersion: "39540"
    uid: 7bc282de-0a8b-4191-9ba0-6077bba64172
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: ip-10-0-106-212_2e50b426-d098-4741-b5e0-0db461d4fdf4 became leader
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: cluster-policy-controller-lock.179e34f7ff6c855c
    namespace: openshift-kube-controller-manager
    resourceVersion: "39541"
    uid: ef76c72f-b79e-4e5d-a09b-fc27b5cef844
  reason: LeaderElection
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:56Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "16453"
    uid: 4897c415-d05e-45e2-9fd0-767c84b3b7a7
  kind: Event
  lastTimestamp: "2023-12-06T09:24:56Z"
  message: Add eth0 [10.128.0.26/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:24:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:24:56Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33d45c56dea2
    namespace: openshift-kube-controller-manager
    resourceVersion: "16493"
    uid: 492c8d58-90ec-43e0-a8e8-a74226c122a9
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:56Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "16450"
    uid: 4897c415-d05e-45e2-9fd0-767c84b3b7a7
  kind: Event
  lastTimestamp: "2023-12-06T09:24:56Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
  metadata:
    creationTimestamp: "2023-12-06T09:24:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:56Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33d45ddbec47
    namespace: openshift-kube-controller-manager
    resourceVersion: "16496"
    uid: ac6f0c50-c1b4-4dd2-ae64-7c9160c49281
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "16450"
    uid: 4897c415-d05e-45e2-9fd0-767c84b3b7a7
  kind: Event
  lastTimestamp: "2023-12-06T09:25:00Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    in 4.402s (4.402s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:25:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:00Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33d56440d2c7
    namespace: openshift-kube-controller-manager
    resourceVersion: "16645"
    uid: 9e994506-c478-4443-bf5d-7a88c3b5309c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "16450"
    uid: 4897c415-d05e-45e2-9fd0-767c84b3b7a7
  kind: Event
  lastTimestamp: "2023-12-06T09:25:01Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:25:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:01Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33d571634f7f
    namespace: openshift-kube-controller-manager
    resourceVersion: "16654"
    uid: 218da387-c3b9-4d1e-88c5-006e0063488d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "16450"
    uid: 4897c415-d05e-45e2-9fd0-767c84b3b7a7
  kind: Event
  lastTimestamp: "2023-12-06T09:25:01Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:25:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:01Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33d575e79115
    namespace: openshift-kube-controller-manager
    resourceVersion: "16657"
    uid: 499d7929-d05a-4f88-99a5-652058be3a58
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:33Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 4897c415-d05e-45e2-9fd0-767c84b3b7a7
  kind: Event
  lastTimestamp: "2023-12-06T09:25:33Z"
  message: Successfully installed revision 2
  metadata:
    creationTimestamp: "2023-12-06T09:25:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:25:33Z"
    name: installer-2-ip-10-0-106-212.us-west-1.compute.internal.179e33dcfc7d0c09
    namespace: openshift-kube-controller-manager
    resourceVersion: "17990"
    uid: f309af21-e971-4381-8af7-80d253eb284e
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "10260"
    uid: c88faa13-1859-4624-bc92-534ee7f1f0ac
  kind: Event
  lastTimestamp: "2023-12-06T09:22:24Z"
  message: Add eth0 [10.129.0.61/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:22:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:22:24Z"
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal.179e33b0e8fb07ab
    namespace: openshift-kube-controller-manager
    resourceVersion: "10436"
    uid: dfa2725a-876a-42b6-88dc-58d19eec624f
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "10257"
    uid: c88faa13-1859-4624-bc92-534ee7f1f0ac
  kind: Event
  lastTimestamp: "2023-12-06T09:22:24Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:22:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:22:24Z"
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal.179e33b0ea96cafc
    namespace: openshift-kube-controller-manager
    resourceVersion: "10438"
    uid: f4a7f25c-b7b8-4c8b-aab2-291cbd536cd5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "10257"
    uid: c88faa13-1859-4624-bc92-534ee7f1f0ac
  kind: Event
  lastTimestamp: "2023-12-06T09:22:24Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:22:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:22:24Z"
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal.179e33b10982b4dc
    namespace: openshift-kube-controller-manager
    resourceVersion: "10466"
    uid: 6dd7cd8b-1e61-4081-bd9d-f608afb908d1
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "10257"
    uid: c88faa13-1859-4624-bc92-534ee7f1f0ac
  kind: Event
  lastTimestamp: "2023-12-06T09:22:24Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:22:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:22:24Z"
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal.179e33b112308164
    namespace: openshift-kube-controller-manager
    resourceVersion: "10470"
    uid: a8c55762-5110-4f57-b8c8-363dc1cf6e3b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:57Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: c88faa13-1859-4624-bc92-534ee7f1f0ac
  kind: Event
  lastTimestamp: "2023-12-06T09:22:57Z"
  message: Successfully installed revision 2
  metadata:
    creationTimestamp: "2023-12-06T09:22:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:22:57Z"
    name: installer-2-ip-10-0-21-63.us-west-1.compute.internal.179e33b895c32848
    namespace: openshift-kube-controller-manager
    resourceVersion: "11626"
    uid: f6698a5d-4a42-40ec-a9f3-8074088ed3be
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:37Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "14364"
    uid: fae0d361-9ec2-421e-aa2f-68bd0af98d8d
  kind: Event
  lastTimestamp: "2023-12-06T09:23:37Z"
  message: Add eth0 [10.130.0.24/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:23:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:23:37Z"
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal.179e33c1f5994ea1
    namespace: openshift-kube-controller-manager
    resourceVersion: "14437"
    uid: dcd97235-1aa2-4785-8dc7-7d1686b24e4d
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "14360"
    uid: fae0d361-9ec2-421e-aa2f-68bd0af98d8d
  kind: Event
  lastTimestamp: "2023-12-06T09:23:37Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
  metadata:
    creationTimestamp: "2023-12-06T09:23:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:37Z"
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal.179e33c1f7ab8870
    namespace: openshift-kube-controller-manager
    resourceVersion: "14442"
    uid: 04aefc6c-2196-4c84-b443-764f275fc810
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "14360"
    uid: fae0d361-9ec2-421e-aa2f-68bd0af98d8d
  kind: Event
  lastTimestamp: "2023-12-06T09:23:40Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    in 3.086s (3.086s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:40Z"
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal.179e33c2afa19768
    namespace: openshift-kube-controller-manager
    resourceVersion: "14723"
    uid: da1f3034-0d78-4ebf-88a7-73d57b303656
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "14360"
    uid: fae0d361-9ec2-421e-aa2f-68bd0af98d8d
  kind: Event
  lastTimestamp: "2023-12-06T09:23:40Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:40Z"
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal.179e33c2bb006b17
    namespace: openshift-kube-controller-manager
    resourceVersion: "14736"
    uid: da20f105-688e-41ec-9aa9-e6e97aaed0ad
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "14360"
    uid: fae0d361-9ec2-421e-aa2f-68bd0af98d8d
  kind: Event
  lastTimestamp: "2023-12-06T09:23:40Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:40Z"
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal.179e33c2bc16f597
    namespace: openshift-kube-controller-manager
    resourceVersion: "14739"
    uid: 0c17d56b-08ae-4f2c-90dc-8fa181212fc8
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:13Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fae0d361-9ec2-421e-aa2f-68bd0af98d8d
  kind: Event
  lastTimestamp: "2023-12-06T09:24:13Z"
  message: Successfully installed revision 2
  metadata:
    creationTimestamp: "2023-12-06T09:24:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:24:13Z"
    name: installer-2-ip-10-0-94-160.us-west-1.compute.internal.179e33ca4726575b
    namespace: openshift-kube-controller-manager
    resourceVersion: "15832"
    uid: ebeac4ca-3355-4fcc-9e15-5185e9aaf02c
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:54Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "35333"
    uid: e47372dc-223e-4460-93ce-75b030a24e98
  kind: Event
  lastTimestamp: "2023-12-06T09:40:54Z"
  message: Add eth0 [10.128.0.54/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:40:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:40:54Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e34b371682716
    namespace: openshift-kube-controller-manager
    resourceVersion: "35337"
    uid: d7dfbc8c-7832-44cc-ac83-1a633746a63b
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:54Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "35330"
    uid: e47372dc-223e-4460-93ce-75b030a24e98
  kind: Event
  lastTimestamp: "2023-12-06T09:40:54Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:40:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:54Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e34b373035bd3
    namespace: openshift-kube-controller-manager
    resourceVersion: "35339"
    uid: 4ef64805-4bcd-4d97-b6f3-46cf356470dd
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:54Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "35330"
    uid: e47372dc-223e-4460-93ce-75b030a24e98
  kind: Event
  lastTimestamp: "2023-12-06T09:40:54Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:40:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:54Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e34b37d6104be
    namespace: openshift-kube-controller-manager
    resourceVersion: "35355"
    uid: 79b87295-7ad9-47e6-b19d-c7e45b054c59
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:54Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "35330"
    uid: e47372dc-223e-4460-93ce-75b030a24e98
  kind: Event
  lastTimestamp: "2023-12-06T09:40:54Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:40:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:54Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e34b37e16a5a8
    namespace: openshift-kube-controller-manager
    resourceVersion: "35357"
    uid: 8c0c4917-5b9f-4622-b099-4eb767af0911
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:27Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e47372dc-223e-4460-93ce-75b030a24e98
  kind: Event
  lastTimestamp: "2023-12-06T09:41:27Z"
  message: Successfully installed revision 3
  metadata:
    creationTimestamp: "2023-12-06T09:41:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:41:27Z"
    name: installer-3-ip-10-0-106-212.us-west-1.compute.internal.179e34bb0909e8eb
    namespace: openshift-kube-controller-manager
    resourceVersion: "35835"
    uid: cd879778-8cec-4300-85e3-b1b1cfbf8f78
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:36Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "29684"
    uid: eee7bb5a-5b50-44c7-bfc2-c821dd783885
  kind: Event
  lastTimestamp: "2023-12-06T09:37:36Z"
  message: Add eth0 [10.129.0.81/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:37:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:37:42Z"
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal.179e34855546368c
    namespace: openshift-kube-controller-manager
    resourceVersion: "29779"
    uid: dfdf7a26-a654-430c-a3a9-6efe27f4f092
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "29680"
    uid: eee7bb5a-5b50-44c7-bfc2-c821dd783885
  kind: Event
  lastTimestamp: "2023-12-06T09:37:37Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:37:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:37:37Z"
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal.179e34859294f50e
    namespace: openshift-kube-controller-manager
    resourceVersion: "29716"
    uid: 33ed5c6d-fe26-4a53-91e2-842ecf094a38
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "29680"
    uid: eee7bb5a-5b50-44c7-bfc2-c821dd783885
  kind: Event
  lastTimestamp: "2023-12-06T09:37:37Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:37:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:37:37Z"
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal.179e3485a2c377d9
    namespace: openshift-kube-controller-manager
    resourceVersion: "29717"
    uid: 7de73438-b327-4b70-b5bb-8482053e45c3
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "29680"
    uid: eee7bb5a-5b50-44c7-bfc2-c821dd783885
  kind: Event
  lastTimestamp: "2023-12-06T09:37:37Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:37:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:37:37Z"
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal.179e3485a3ce07a3
    namespace: openshift-kube-controller-manager
    resourceVersion: "29718"
    uid: a63fa385-1fdf-4c3d-9288-d7e448b4d8c3
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:10Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: eee7bb5a-5b50-44c7-bfc2-c821dd783885
  kind: Event
  lastTimestamp: "2023-12-06T09:38:10Z"
  message: Successfully installed revision 3
  metadata:
    creationTimestamp: "2023-12-06T09:38:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:38:10Z"
    name: installer-3-ip-10-0-21-63.us-west-1.compute.internal.179e348d2f2d128a
    namespace: openshift-kube-controller-manager
    resourceVersion: "30261"
    uid: 6074fd8a-4776-46cf-9747-fe1e3fc61428
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:48Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "31361"
    uid: f9ca10fe-37a6-47dd-8a2a-45b645ac865e
  kind: Event
  lastTimestamp: "2023-12-06T09:38:48Z"
  message: Add eth0 [10.130.0.41/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:38:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:38:48Z"
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal.179e34962309265a
    namespace: openshift-kube-controller-manager
    resourceVersion: "31363"
    uid: f3cba502-cc57-41bd-bcdd-510c29d85a15
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "31358"
    uid: f9ca10fe-37a6-47dd-8a2a-45b645ac865e
  kind: Event
  lastTimestamp: "2023-12-06T09:38:48Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:48Z"
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal.179e3496247e89f9
    namespace: openshift-kube-controller-manager
    resourceVersion: "31365"
    uid: 137367de-85ee-41ba-a56b-08bee159842c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "31358"
    uid: f9ca10fe-37a6-47dd-8a2a-45b645ac865e
  kind: Event
  lastTimestamp: "2023-12-06T09:38:48Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:38:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:48Z"
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal.179e34962f501d12
    namespace: openshift-kube-controller-manager
    resourceVersion: "31367"
    uid: 2f02d815-641f-4dc5-b890-835025068bc3
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "31358"
    uid: f9ca10fe-37a6-47dd-8a2a-45b645ac865e
  kind: Event
  lastTimestamp: "2023-12-06T09:38:48Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:38:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:48Z"
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal.179e349630272599
    namespace: openshift-kube-controller-manager
    resourceVersion: "31368"
    uid: 23e77d5d-b3df-44f4-b9a4-1af70a0455a2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:21Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: f9ca10fe-37a6-47dd-8a2a-45b645ac865e
  kind: Event
  lastTimestamp: "2023-12-06T09:39:21Z"
  message: Successfully installed revision 3
  metadata:
    creationTimestamp: "2023-12-06T09:39:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:39:21Z"
    name: installer-3-ip-10-0-94-160.us-west-1.compute.internal.179e349dbb29a910
    namespace: openshift-kube-controller-manager
    resourceVersion: "33229"
    uid: e88551b2-a522-496e-be1b-33a342b024c9
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:09Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "36849"
    uid: 0b5c9469-6d49-491c-a4fe-accb7503e162
  kind: Event
  lastTimestamp: "2023-12-06T09:42:09Z"
  message: Add eth0 [10.129.0.87/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:42:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:42:09Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e34c50044941f
    namespace: openshift-kube-controller-manager
    resourceVersion: "36859"
    uid: b2948d82-7ed9-4010-b656-b0614746ac5b
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "36846"
    uid: 0b5c9469-6d49-491c-a4fe-accb7503e162
  kind: Event
  lastTimestamp: "2023-12-06T09:42:09Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:09Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e34c502073973
    namespace: openshift-kube-controller-manager
    resourceVersion: "36862"
    uid: 861b7f1a-6a0b-4a4b-bb0b-4e15f79f8042
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:10Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "36846"
    uid: 0b5c9469-6d49-491c-a4fe-accb7503e162
  kind: Event
  lastTimestamp: "2023-12-06T09:42:10Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:42:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:10Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e34c50f8bb518
    namespace: openshift-kube-controller-manager
    resourceVersion: "36865"
    uid: c9d66505-436d-4187-aefb-49066e3eba4a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:10Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "36846"
    uid: 0b5c9469-6d49-491c-a4fe-accb7503e162
  kind: Event
  lastTimestamp: "2023-12-06T09:42:10Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:42:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:10Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e34c510808806
    namespace: openshift-kube-controller-manager
    resourceVersion: "36866"
    uid: eb59c875-a838-4446-841e-23793996be16
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:42Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 0b5c9469-6d49-491c-a4fe-accb7503e162
  kind: Event
  lastTimestamp: "2023-12-06T09:42:42Z"
  message: Successfully installed revision 4
  metadata:
    creationTimestamp: "2023-12-06T09:42:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:42:42Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e34cc9c290035
    namespace: openshift-kube-controller-manager
    resourceVersion: "37332"
    uid: 02c82c64-671b-4888-80b4-9068eb103b58
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "36846"
    uid: 0b5c9469-6d49-491c-a4fe-accb7503e162
  kind: Event
  lastTimestamp: "2023-12-06T09:42:43Z"
  message: Stopping container installer
  metadata:
    creationTimestamp: "2023-12-06T09:42:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:43Z"
    name: installer-4-ip-10-0-21-63.us-west-1.compute.internal.179e34ccb95fe4ae
    namespace: openshift-kube-controller-manager
    resourceVersion: "37338"
    uid: b1e0181a-87cc-4f25-abcd-c8a67c686731
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:04Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38983"
    uid: c13a0867-f587-4fe6-80e3-246660ef1098
  kind: Event
  lastTimestamp: "2023-12-06T09:45:04Z"
  message: Add eth0 [10.128.0.58/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:45:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:45:04Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34edabd1db87
    namespace: openshift-kube-controller-manager
    resourceVersion: "38987"
    uid: 22feac53-9621-42e1-8cce-a4c044fdde46
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38980"
    uid: c13a0867-f587-4fe6-80e3-246660ef1098
  kind: Event
  lastTimestamp: "2023-12-06T09:45:04Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:04Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34edad859eac
    namespace: openshift-kube-controller-manager
    resourceVersion: "38989"
    uid: 3b5f5593-38d3-40c2-b16f-1f036b64d57b
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38980"
    uid: c13a0867-f587-4fe6-80e3-246660ef1098
  kind: Event
  lastTimestamp: "2023-12-06T09:45:04Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:45:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:04Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34edb8c1877e
    namespace: openshift-kube-controller-manager
    resourceVersion: "38990"
    uid: e95caf11-7bc0-4a89-ba3a-3cba001b3ad7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38980"
    uid: c13a0867-f587-4fe6-80e3-246660ef1098
  kind: Event
  lastTimestamp: "2023-12-06T09:45:04Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:45:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:04Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34edb979a48c
    namespace: openshift-kube-controller-manager
    resourceVersion: "38991"
    uid: 9aa76386-002b-46e4-8444-041c24fc4829
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:37Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: c13a0867-f587-4fe6-80e3-246660ef1098
  kind: Event
  lastTimestamp: "2023-12-06T09:45:37Z"
  message: Successfully installed revision 5
  metadata:
    creationTimestamp: "2023-12-06T09:45:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:45:37Z"
    name: installer-5-ip-10-0-106-212.us-west-1.compute.internal.179e34f544c2fa7f
    namespace: openshift-kube-controller-manager
    resourceVersion: "39379"
    uid: ef452f12-87ed-4cfb-8c8e-aa54006c8de4
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:46Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "37375"
    uid: 4195de55-54d2-4bf0-9a35-a0fc2488c713
  kind: Event
  lastTimestamp: "2023-12-06T09:42:46Z"
  message: Add eth0 [10.129.0.88/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:42:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:42:46Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e34cd7b2832c9
    namespace: openshift-kube-controller-manager
    resourceVersion: "37391"
    uid: 5f6cb5aa-6090-4620-94ad-105cbb152898
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:46Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "37372"
    uid: 4195de55-54d2-4bf0-9a35-a0fc2488c713
  kind: Event
  lastTimestamp: "2023-12-06T09:42:46Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:46Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e34cd7cea8609
    namespace: openshift-kube-controller-manager
    resourceVersion: "37394"
    uid: c2ca47ca-f404-4c11-89b9-aa3b1de3f394
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:46Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "37372"
    uid: 4195de55-54d2-4bf0-9a35-a0fc2488c713
  kind: Event
  lastTimestamp: "2023-12-06T09:42:46Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:42:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:46Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e34cd89329638
    namespace: openshift-kube-controller-manager
    resourceVersion: "37395"
    uid: d889c9a7-d074-4def-a669-3369945c2160
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:46Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "37372"
    uid: 4195de55-54d2-4bf0-9a35-a0fc2488c713
  kind: Event
  lastTimestamp: "2023-12-06T09:42:46Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:42:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:46Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e34cd8a52d6a8
    namespace: openshift-kube-controller-manager
    resourceVersion: "37396"
    uid: 89404ba6-30e7-45a9-88e0-e08adb192ddb
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:18Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 4195de55-54d2-4bf0-9a35-a0fc2488c713
  kind: Event
  lastTimestamp: "2023-12-06T09:43:18Z"
  message: Successfully installed revision 5
  metadata:
    creationTimestamp: "2023-12-06T09:43:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:43:19Z"
    name: installer-5-ip-10-0-21-63.us-west-1.compute.internal.179e34d51560d52f
    namespace: openshift-kube-controller-manager
    resourceVersion: "37771"
    uid: e4966a09-4182-4376-bd60-73cfcd3794ec
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:55Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38192"
    uid: 3d0d4557-5fd3-493f-b776-183b278713b0
  kind: Event
  lastTimestamp: "2023-12-06T09:43:55Z"
  message: Add eth0 [10.130.0.48/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:43:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:43:55Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e34ddb080437c
    namespace: openshift-kube-controller-manager
    resourceVersion: "38199"
    uid: e322f9af-3ec9-43c3-88b9-8708bb7807d8
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:55Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38189"
    uid: 3d0d4557-5fd3-493f-b776-183b278713b0
  kind: Event
  lastTimestamp: "2023-12-06T09:43:55Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:43:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:55Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e34ddb2177e7a
    namespace: openshift-kube-controller-manager
    resourceVersion: "38201"
    uid: 6c2d341a-2b29-4508-969a-8b2b29ff4517
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:56Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38189"
    uid: 3d0d4557-5fd3-493f-b776-183b278713b0
  kind: Event
  lastTimestamp: "2023-12-06T09:43:56Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:43:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:56Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e34ddbc11e0cf
    namespace: openshift-kube-controller-manager
    resourceVersion: "38203"
    uid: 4b325e59-27bd-4187-840d-cca4b0215d59
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:56Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "38189"
    uid: 3d0d4557-5fd3-493f-b776-183b278713b0
  kind: Event
  lastTimestamp: "2023-12-06T09:43:56Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:43:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:56Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e34ddbcdb2930
    namespace: openshift-kube-controller-manager
    resourceVersion: "38204"
    uid: 18475205-98ff-4f79-9eac-a152deba9d0b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:28Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 3d0d4557-5fd3-493f-b776-183b278713b0
  kind: Event
  lastTimestamp: "2023-12-06T09:44:28Z"
  message: Successfully installed revision 5
  metadata:
    creationTimestamp: "2023-12-06T09:44:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2023-12-06T09:44:28Z"
    name: installer-5-ip-10-0-94-160.us-west-1.compute.internal.179e34e548874a72
    namespace: openshift-kube-controller-manager
    resourceVersion: "38531"
    uid: 42aadfe5-9256-4aa7-9758-1dcd7a894826
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:46Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "47620"
    uid: d96dbaa2-0a8f-43ac-9a6d-9281b60a9326
  kind: Event
  lastTimestamp: "2023-12-06T09:57:46Z"
  message: Add eth0 [10.129.0.91/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:57:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:57:46Z"
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal.179e359f1095ce64
    namespace: openshift-kube-controller-manager
    resourceVersion: "47625"
    uid: 66e957f3-01a7-48b9-a688-2b0dbc92fa4d
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:46Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "47617"
    uid: d96dbaa2-0a8f-43ac-9a6d-9281b60a9326
  kind: Event
  lastTimestamp: "2023-12-06T09:57:46Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:57:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:46Z"
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal.179e359f12508e30
    namespace: openshift-kube-controller-manager
    resourceVersion: "47627"
    uid: a8e60fbf-2c6d-4037-8f10-a886e972bc0a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:46Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "47617"
    uid: d96dbaa2-0a8f-43ac-9a6d-9281b60a9326
  kind: Event
  lastTimestamp: "2023-12-06T09:57:46Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2023-12-06T09:57:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:46Z"
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal.179e359f20e79344
    namespace: openshift-kube-controller-manager
    resourceVersion: "47629"
    uid: 45e242cb-99b1-41fe-a584-b611fe3994a6
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:46Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "47617"
    uid: d96dbaa2-0a8f-43ac-9a6d-9281b60a9326
  kind: Event
  lastTimestamp: "2023-12-06T09:57:46Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2023-12-06T09:57:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:57:46Z"
    name: installer-6-ip-10-0-21-63.us-west-1.compute.internal.179e359f2238d987
    namespace: openshift-kube-controller-manager
    resourceVersion: "47630"
    uid: bc7d1ef5-4ed5-49a6-9179-c28d98e9f3b0
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:40Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "18207"
    uid: 5cbe13a7-617d-4165-89d9-eb7aeac71005
  kind: Event
  lastTimestamp: "2023-12-06T09:25:40Z"
  message: Add eth0 [10.128.0.30/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:25:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:25:40Z"
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33de8e4e1d0b
    namespace: openshift-kube-controller-manager
    resourceVersion: "18253"
    uid: 016cdc77-5006-45d7-a1e0-1c6b91ac1f4e
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "18203"
    uid: 5cbe13a7-617d-4165-89d9-eb7aeac71005
  kind: Event
  lastTimestamp: "2023-12-06T09:25:40Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:40Z"
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33de8f754a53
    namespace: openshift-kube-controller-manager
    resourceVersion: "18255"
    uid: d318b17b-796e-4263-8c47-b0f3a896828c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "18203"
    uid: 5cbe13a7-617d-4165-89d9-eb7aeac71005
  kind: Event
  lastTimestamp: "2023-12-06T09:25:40Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2023-12-06T09:25:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:40Z"
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33de94f8983d
    namespace: openshift-kube-controller-manager
    resourceVersion: "18259"
    uid: f42f1cca-5264-4a64-b899-723f6f904ef5
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "18203"
    uid: 5cbe13a7-617d-4165-89d9-eb7aeac71005
  kind: Event
  lastTimestamp: "2023-12-06T09:25:40Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2023-12-06T09:25:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:40Z"
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal.179e33de95a51ba8
    namespace: openshift-kube-controller-manager
    resourceVersion: "18260"
    uid: 6f400989-9da1-4671-be75-6ce38b69b87c
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 6
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "18203"
    uid: 5cbe13a7-617d-4165-89d9-eb7aeac71005
  kind: Event
  lastTimestamp: "2023-12-06T09:45:45Z"
  message: "Readiness probe error: Get \"https://10.0.106.212:10257/healthz\": dial
    tcp 10.0.106.212:10257: connect: connection refused\nbody: \n"
  metadata:
    creationTimestamp: "2023-12-06T09:41:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:45Z"
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal.179e34bbba75d1e3
    namespace: openshift-kube-controller-manager
    resourceVersion: "39480"
    uid: 7c5248c7-de03-4cb2-87ac-3c1bd2aa8f5e
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 6
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "18203"
    uid: 5cbe13a7-617d-4165-89d9-eb7aeac71005
  kind: Event
  lastTimestamp: "2023-12-06T09:45:45Z"
  message: 'Readiness probe failed: Get "https://10.0.106.212:10257/healthz": dial
    tcp 10.0.106.212:10257: connect: connection refused'
  metadata:
    creationTimestamp: "2023-12-06T09:41:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:45Z"
    name: kube-controller-manager-guard-ip-10-0-106-212.us-west-1.compute.internal.179e34bbba763eae
    namespace: openshift-kube-controller-manager
    resourceVersion: "39481"
    uid: 056d1972-a67a-41ca-a279-00aac9faccb3
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:02Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "11750"
    uid: 6901968a-aa94-469e-99b6-e5a02fcdb5a0
  kind: Event
  lastTimestamp: "2023-12-06T09:23:02Z"
  message: Add eth0 [10.129.0.64/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:23:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:23:02Z"
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33b9d1b2da02
    namespace: openshift-kube-controller-manager
    resourceVersion: "11770"
    uid: 8c28e5d8-77cf-4ac7-8ab0-324d6f18f827
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:02Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "11745"
    uid: 6901968a-aa94-469e-99b6-e5a02fcdb5a0
  kind: Event
  lastTimestamp: "2023-12-06T09:23:02Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:23:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:02Z"
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33b9d2ec95df
    namespace: openshift-kube-controller-manager
    resourceVersion: "11772"
    uid: baa03031-dbc7-4679-8913-c51da8b28de5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "11745"
    uid: 6901968a-aa94-469e-99b6-e5a02fcdb5a0
  kind: Event
  lastTimestamp: "2023-12-06T09:23:04Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2023-12-06T09:23:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:04Z"
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33ba62ccba08
    namespace: openshift-kube-controller-manager
    resourceVersion: "11819"
    uid: b7744a1d-0f61-4d4c-bab5-73ac4f45cfd6
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "11745"
    uid: 6901968a-aa94-469e-99b6-e5a02fcdb5a0
  kind: Event
  lastTimestamp: "2023-12-06T09:23:04Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2023-12-06T09:23:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:04Z"
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33ba64500552
    namespace: openshift-kube-controller-manager
    resourceVersion: "11820"
    uid: 8adb8739-5c65-4af2-9cdd-988504a1a2c7
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 13
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "11745"
    uid: 6901968a-aa94-469e-99b6-e5a02fcdb5a0
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: "Readiness probe error: Get \"https://10.0.21.63:10257/healthz\": dial
    tcp 10.0.21.63:10257: connect: connection refused\nbody: \n"
  metadata:
    creationTimestamp: "2023-12-06T09:23:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33ba8bd611b6
    namespace: openshift-kube-controller-manager
    resourceVersion: "37924"
    uid: bc2eb518-f74b-43e4-849c-d84d8a0e3d81
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 13
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "11745"
    uid: 6901968a-aa94-469e-99b6-e5a02fcdb5a0
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: 'Readiness probe failed: Get "https://10.0.21.63:10257/healthz": dial tcp
    10.0.21.63:10257: connect: connection refused'
  metadata:
    creationTimestamp: "2023-12-06T09:23:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-guard-ip-10-0-21-63.us-west-1.compute.internal.179e33ba8bd6770b
    namespace: openshift-kube-controller-manager
    resourceVersion: "37928"
    uid: bd3cd267-5ad8-4566-bef1-db11e0048915
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "16021"
    uid: 7cebc8f2-33f4-49ef-b325-09b25d81566a
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Add eth0 [10.130.0.28/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal.179e33cd6d6dc7d8
    namespace: openshift-kube-controller-manager
    resourceVersion: "16029"
    uid: 60160689-2e9f-469e-b2e8-d9ccb1fd7e69
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "15973"
    uid: 7cebc8f2-33f4-49ef-b325-09b25d81566a
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal.179e33cd701b44e0
    namespace: openshift-kube-controller-manager
    resourceVersion: "16032"
    uid: 8689d857-4aa7-4e9b-9f94-24a9619b871d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "15973"
    uid: 7cebc8f2-33f4-49ef-b325-09b25d81566a
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal.179e33cd7a27ce15
    namespace: openshift-kube-controller-manager
    resourceVersion: "16036"
    uid: a0d44fe9-5bd0-4306-a772-fa4a10240558
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "15973"
    uid: 7cebc8f2-33f4-49ef-b325-09b25d81566a
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal.179e33cd7b6ef0f2
    namespace: openshift-kube-controller-manager
    resourceVersion: "16037"
    uid: 9eed4f28-97b0-4a09-b112-bd732598c73c
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 14
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "15973"
    uid: 7cebc8f2-33f4-49ef-b325-09b25d81566a
  kind: Event
  lastTimestamp: "2023-12-06T09:44:32Z"
  message: "Readiness probe error: Get \"https://10.0.94.160:10257/healthz\": dial
    tcp 10.0.94.160:10257: connect: connection refused\nbody: \n"
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:32Z"
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal.179e33cd7c7b12d0
    namespace: openshift-kube-controller-manager
    resourceVersion: "38596"
    uid: cd70e04d-5477-45e7-aaf3-13a9a8e417e5
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 12
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    resourceVersion: "15973"
    uid: 7cebc8f2-33f4-49ef-b325-09b25d81566a
  kind: Event
  lastTimestamp: "2023-12-06T09:40:07Z"
  message: 'Readiness probe failed: Get "https://10.0.94.160:10257/healthz": dial
    tcp 10.0.94.160:10257: connect: connection refused'
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:07Z"
    name: kube-controller-manager-guard-ip-10-0-94-160.us-west-1.compute.internal.179e33cd7c7b7a05
    namespace: openshift-kube-controller-manager
    resourceVersion: "34407"
    uid: a678f713-324e-4902-9e49-ce33092ae1cf
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:11Z"
  involvedObject:
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    name: kube-controller-manager-guard-pdb
    namespace: openshift-kube-controller-manager
    resourceVersion: "5584"
    uid: b3dbc7e8-18a4-43e9-912c-b2af2ea8d2d6
  kind: Event
  lastTimestamp: "2023-12-06T09:21:11Z"
  message: No matching pods found
  metadata:
    creationTimestamp: "2023-12-06T09:21:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2023-12-06T09:21:11Z"
    name: kube-controller-manager-guard-pdb.179e339ff206dee8
    namespace: openshift-kube-controller-manager
    resourceVersion: "5590"
    uid: 5070294e-6d18-4b5a-8b53-29fa315cc751
  reason: NoPods
  reportingComponent: controllermanager
  reportingInstance: ""
  source:
    component: controllermanager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:33Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:33Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33dd102b6305
    namespace: openshift-kube-controller-manager
    resourceVersion: "17993"
    uid: a459c3a3-e86c-42c8-9d41-1e7eb25ce6a0
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:33Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:25:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:33Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33dd1625d1d1
    namespace: openshift-kube-controller-manager
    resourceVersion: "17997"
    uid: d51c213f-8925-4841-b454-f12b841c193e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:33Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:25:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:33Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33dd1709ba0a
    namespace: openshift-kube-controller-manager
    resourceVersion: "17998"
    uid: 7f2553d3-3d72-4f3f-bd55-612cba50be16
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:33Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
  metadata:
    creationTimestamp: "2023-12-06T09:25:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:33Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33dd1713a3b4
    namespace: openshift-kube-controller-manager
    resourceVersion: "17999"
    uid: d5ae165d-b2f7-42db-bb77-2c0350338a63
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:37Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    in 3.482s (3.482s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33dde6a752c0
    namespace: openshift-kube-controller-manager
    resourceVersion: "18144"
    uid: ac207747-9fde-459d-92ae-b1b663ee5514
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:37Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33ddec6f892f
    namespace: openshift-kube-controller-manager
    resourceVersion: "18147"
    uid: 5daa9487-a210-48d3-befe-c21f4e58be2e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:37Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33dded1d16a0
    namespace: openshift-kube-controller-manager
    resourceVersion: "18148"
    uid: 068e9307-d823-4270-8006-dd713cbe16a2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:35:38Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:35:38Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33dded285513
    namespace: openshift-kube-controller-manager
    resourceVersion: "27944"
    uid: 8116e862-6f5b-4a91-a136-e7a6eeca2bb7
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:35:38Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:35:38Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33ddf39aae7a
    namespace: openshift-kube-controller-manager
    resourceVersion: "27948"
    uid: a110c45f-7c87-4045-a2b8-e4faa63d4b91
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:35:38Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:35:38Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33ddf45b31c2
    namespace: openshift-kube-controller-manager
    resourceVersion: "27949"
    uid: 9b4a988c-9505-4ca7-814e-e38ccc4bb180
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:37Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33ddf4660194
    namespace: openshift-kube-controller-manager
    resourceVersion: "18152"
    uid: d6ae5edc-3f36-43e8-ac02-1fb5998d5328
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:37Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33ddfb874e34
    namespace: openshift-kube-controller-manager
    resourceVersion: "18168"
    uid: 52a3a834-2d54-4b01-932d-b8b651d8150e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:25:37Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:25:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33ddfc5ef525
    namespace: openshift-kube-controller-manager
    resourceVersion: "18171"
    uid: 7ffc2ba1-3f88-4b92-8488-ab72053ef286
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:25:37Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:25:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e33ddfd2b90b1
    namespace: openshift-kube-controller-manager
    resourceVersion: "18176"
    uid: 3edd44ce-aec5-4f48-ba10-ea60da9c08e4
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:41:27Z"
  message: Stopping container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:41:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:27Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34bb0912604d
    namespace: openshift-kube-controller-manager
    resourceVersion: "35824"
    uid: d0bfd561-b151-4f13-94fb-2a0a760f0c8c
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:41:27Z"
  message: Stopping container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:41:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:27Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34bb09131de0
    namespace: openshift-kube-controller-manager
    resourceVersion: "35826"
    uid: 28902447-4377-47cd-8ba7-0007b9ea9440
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:41:27Z"
  message: Stopping container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:41:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:27Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34bb0914594f
    namespace: openshift-kube-controller-manager
    resourceVersion: "35828"
    uid: f4ba3d80-3d98-4b0b-9c65-196c5d0e1222
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 6a8ab39adcf132697f78bedc80185534
  kind: Event
  lastTimestamp: "2023-12-06T09:41:27Z"
  message: Stopping container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:41:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:27Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34bb09152114
    namespace: openshift-kube-controller-manager
    resourceVersion: "35830"
    uid: a73e1a7d-7fba-4700-94d1-03ebf42f72bc
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be10d40643
    namespace: openshift-kube-controller-manager
    resourceVersion: "35987"
    uid: 0861f773-1081-4797-a3c3-f2aa6dd34970
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be16967c22
    namespace: openshift-kube-controller-manager
    resourceVersion: "35988"
    uid: 63cf34d8-3bb9-4bf3-8e2d-73eb8ee9e1cc
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be175f6beb
    namespace: openshift-kube-controller-manager
    resourceVersion: "35989"
    uid: 60a72602-070d-42dd-9257-aefa6af9e5cd
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be176b4bd1
    namespace: openshift-kube-controller-manager
    resourceVersion: "35990"
    uid: 692c3392-d90f-49e3-9c79-a8821bcce997
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be1de23c7f
    namespace: openshift-kube-controller-manager
    resourceVersion: "35991"
    uid: 0ebb2d29-14d5-46b2-abc8-f810d80e9d86
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be1ebc962d
    namespace: openshift-kube-controller-manager
    resourceVersion: "35992"
    uid: 97370b95-dfd3-42b9-acb9-ae17cc02e416
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be1ecc91bd
    namespace: openshift-kube-controller-manager
    resourceVersion: "35993"
    uid: d4e3dad6-6023-482d-a8bb-7f14a6191c4d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be25d67eee
    namespace: openshift-kube-controller-manager
    resourceVersion: "35994"
    uid: f4426e5b-a6c1-45db-ba04-e14045e17e9f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be269f4a9f
    namespace: openshift-kube-controller-manager
    resourceVersion: "35996"
    uid: ec0d4dab-8b87-42ba-9234-d0f7ac541a11
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be26ab9e3a
    namespace: openshift-kube-controller-manager
    resourceVersion: "35997"
    uid: b22b8364-f8a6-48a1-89b9-870ea9ccfb1d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be2ee55a62
    namespace: openshift-kube-controller-manager
    resourceVersion: "35999"
    uid: 2842725b-6347-4e5f-b861-f42984816317
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be2fbaae9c
    namespace: openshift-kube-controller-manager
    resourceVersion: "36000"
    uid: cac1fb0c-d988-4d34-85d8-d445a7e84ade
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:40Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:41:40Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:41:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:41:40Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34be3661eb4f
    namespace: openshift-kube-controller-manager
    resourceVersion: "36003"
    uid: 33c7c02f-f356-4569-8278-20c3e80f4f3c
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:45:37Z"
  message: Stopping container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:45:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f544ca4a04
    namespace: openshift-kube-controller-manager
    resourceVersion: "39373"
    uid: 93f827e4-352a-4e07-9246-c94cdb7ef424
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:45:37Z"
  message: Stopping container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f544cab9db
    namespace: openshift-kube-controller-manager
    resourceVersion: "39374"
    uid: 29aeaf60-c53a-43b4-b287-267fc852de35
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:45:37Z"
  message: Stopping container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f544cd6a62
    namespace: openshift-kube-controller-manager
    resourceVersion: "39377"
    uid: 60d4015c-f6f9-4bc5-af49-e3a3d3758301
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 64bdf022907489e779c786d5b4cea013
  kind: Event
  lastTimestamp: "2023-12-06T09:45:37Z"
  message: Stopping container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:45:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:37Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f544ce7737
    namespace: openshift-kube-controller-manager
    resourceVersion: "39378"
    uid: 9bb435c4-995c-4979-ab0e-fa0bcd5d3e49
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7cfb38c6b
    namespace: openshift-kube-controller-manager
    resourceVersion: "39520"
    uid: 90ac89ff-0c42-499c-9453-edce43f456de
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7d5cf414a
    namespace: openshift-kube-controller-manager
    resourceVersion: "39523"
    uid: a4dbd7a2-3969-4fd9-9dee-9b088e1a0359
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7d674ac2a
    namespace: openshift-kube-controller-manager
    resourceVersion: "39524"
    uid: 705ebdde-3712-49fd-9086-0fe1046802db
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7d67f40c5
    namespace: openshift-kube-controller-manager
    resourceVersion: "39525"
    uid: 58b59837-af83-43b0-a3c4-05ebf21d68c5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7dcc96b07
    namespace: openshift-kube-controller-manager
    resourceVersion: "39527"
    uid: e31c980d-bf93-453e-98ab-fe183ed84504
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7dd86acf1
    namespace: openshift-kube-controller-manager
    resourceVersion: "39528"
    uid: c4f5e491-add9-4130-936a-356db7d85d6e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:55:49Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:55:49Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7dd96fd31
    namespace: openshift-kube-controller-manager
    resourceVersion: "45772"
    uid: b1530e6d-67a1-4cc7-8624-0ae5c44aa398
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:55:49Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:55:49Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7e5399f9d
    namespace: openshift-kube-controller-manager
    resourceVersion: "45777"
    uid: 8a3aa7d8-afab-4559-b310-10b674ddb0db
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:55:49Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:55:49Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7e60d0ba9
    namespace: openshift-kube-controller-manager
    resourceVersion: "45778"
    uid: 224ebb02-2395-4ac9-a6a6-0a3a6fd066a3
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7e618d433
    namespace: openshift-kube-controller-manager
    resourceVersion: "39532"
    uid: 6dceba25-fe25-42c3-ab60-f6d759f8443e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7edad46f4
    namespace: openshift-kube-controller-manager
    resourceVersion: "39534"
    uid: 9c947267-3296-48b9-9a81-109a3038a9ab
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fea914c52ac756d8857b3b6a97505b15
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7ee796097
    namespace: openshift-kube-controller-manager
    resourceVersion: "39535"
    uid: 5cd4a3d0-707d-44a5-8562-7cb794cdd8ef
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-106-212.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-106-212.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:48Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:45:48Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:45:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:45:48Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e34f7fe8f85f1
    namespace: openshift-kube-controller-manager
    resourceVersion: "39538"
    uid: 0671f2a2-7979-4e06-b6f2-9e228a82cd11
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:56:19Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:56:19Z"
  message: created SCC ranges for openshift-must-gather-2gjxc namespace
  metadata:
    creationTimestamp: "2023-12-06T09:56:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:56:19Z"
    name: kube-controller-manager-ip-10-0-106-212.us-west-1.compute.internal.179e358adefff9bf
    namespace: openshift-kube-controller-manager
    resourceVersion: "46087"
    uid: 7dac7ec8-9e92-4d9a-90c4-a554eb9c8b6c
  reason: CreatedSCCRanges
  reportingComponent: cluster-policy-controller-namespace-security-allocation-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller-namespace-security-allocation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:57Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:22:57Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
  metadata:
    creationTimestamp: "2023-12-06T09:22:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:22:57Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33b8bfe992c9
    namespace: openshift-kube-controller-manager
    resourceVersion: "11646"
    uid: 0d2b977d-5409-49fb-a4a7-f6bcaf42d982
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:08Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    in 10.788s (10.788s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:23:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:08Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bb42fa0737
    namespace: openshift-kube-controller-manager
    resourceVersion: "11916"
    uid: c223f783-068e-4740-a7ed-414e9af090da
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:08Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:23:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:08Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bb4e5c6d99
    namespace: openshift-kube-controller-manager
    resourceVersion: "11918"
    uid: d74b53c1-c6e9-4ef0-b7ad-d9e07c1f9718
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:08Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:23:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:08Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bb509a8d68
    namespace: openshift-kube-controller-manager
    resourceVersion: "11919"
    uid: 64038ff7-190f-4dde-afac-1b06ec25efa2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:08Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
  metadata:
    creationTimestamp: "2023-12-06T09:23:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:08Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bb50a71569
    namespace: openshift-kube-controller-manager
    resourceVersion: "11920"
    uid: 68423cf8-250f-4d52-9cb1-23c045e8a23b
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:13Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    in 4.638s (4.638s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:23:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:13Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc65275674
    namespace: openshift-kube-controller-manager
    resourceVersion: "12004"
    uid: 7e59769c-cec6-4801-bf0d-3b240f4af2cf
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:13Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:23:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:13Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc6ff0f835
    namespace: openshift-kube-controller-manager
    resourceVersion: "12006"
    uid: b96b3114-0be7-42c9-b799-f35afde6d06c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:13Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:23:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:13Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc72f7d900
    namespace: openshift-kube-controller-manager
    resourceVersion: "12008"
    uid: 8f005a82-2d67-4041-aa67-b82784309150
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:33:14Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:23:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:33:14Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc73070b2c
    namespace: openshift-kube-controller-manager
    resourceVersion: "26066"
    uid: 314cacea-c4c0-4705-90e5-2a4267764dbe
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:33:17Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:23:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:33:17Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc8622a741
    namespace: openshift-kube-controller-manager
    resourceVersion: "26108"
    uid: 89c8c8d7-7c9e-40ba-a56c-6f9d346874b5
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:33:17Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:23:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:33:17Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc88fe6d5f
    namespace: openshift-kube-controller-manager
    resourceVersion: "26109"
    uid: b83f2f3b-bcd2-421e-ad26-105090d40d70
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:14Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:23:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:14Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc8911cd9b
    namespace: openshift-kube-controller-manager
    resourceVersion: "12048"
    uid: 1cfaf3cd-f80a-42ed-b802-7981b99f9dc2
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:14Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:23:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:14Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bc9c3e50bf
    namespace: openshift-kube-controller-manager
    resourceVersion: "12073"
    uid: 3ef371c0-eda2-4ea2-bdae-702161bfb52c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:23:14Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:23:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:23:14Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bca0fd036f
    namespace: openshift-kube-controller-manager
    resourceVersion: "12074"
    uid: 79346db2-817c-481b-b518-02113bfec87a
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:14Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:23:14Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:23:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:23:14Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33bca2f1779d
    namespace: openshift-kube-controller-manager
    resourceVersion: "12078"
    uid: adf4bae2-c64e-4f5d-acf4-993d9dbe9244
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:43Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:23:43Z"
  message: created SCC ranges for openshift-ingress-canary namespace
  metadata:
    creationTimestamp: "2023-12-06T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:23:43Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e33c36eade0ed
    namespace: openshift-kube-controller-manager
    resourceVersion: "14961"
    uid: 48d35bd4-a6e7-4018-981f-f913f27d2655
  reason: CreatedSCCRanges
  reportingComponent: cluster-policy-controller-namespace-security-allocation-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller-namespace-security-allocation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:00Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:38:00Z"
  message: created SCC ranges for openshift-console namespace
  metadata:
    creationTimestamp: "2023-12-06T09:38:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:38:00Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348ad32c4fbb
    namespace: openshift-kube-controller-manager
    resourceVersion: "29986"
    uid: 75aef964-2721-48c5-9204-a008bdde0cd7
  reason: CreatedSCCRanges
  reportingComponent: cluster-policy-controller-namespace-security-allocation-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller-namespace-security-allocation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:00Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:38:00Z"
  message: created SCC ranges for openshift-console-operator namespace
  metadata:
    creationTimestamp: "2023-12-06T09:38:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:38:00Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348afd470901
    namespace: openshift-kube-controller-manager
    resourceVersion: "30033"
    uid: d752360a-a3ed-4747-9c64-fa06985e4fdf
  reason: CreatedSCCRanges
  reportingComponent: cluster-policy-controller-namespace-security-allocation-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller-namespace-security-allocation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:10Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:38:10Z"
  message: Stopping container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:38:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:10Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348d2f378388
    namespace: openshift-kube-controller-manager
    resourceVersion: "30253"
    uid: 350a9511-c6d6-4ed0-ab27-5964f7e50cec
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:10Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:38:10Z"
  message: Stopping container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:38:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:10Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348d2f3b55cc
    namespace: openshift-kube-controller-manager
    resourceVersion: "30254"
    uid: 4e80a34c-c75b-49e9-a017-df6b67cb236c
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:10Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:38:10Z"
  message: Stopping container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:10Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348d2f3cc21a
    namespace: openshift-kube-controller-manager
    resourceVersion: "30255"
    uid: a2a42be2-c644-4f2b-9d88-2940241d354f
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:10Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: e1441b38739b4c2818d26129729d9427
  kind: Event
  lastTimestamp: "2023-12-06T09:38:10Z"
  message: Stopping container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:10Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348d2f3e0e24
    namespace: openshift-kube-controller-manager
    resourceVersion: "30257"
    uid: d19b2201-2261-4493-acb3-3abc3f170286
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fc0168ce8
    namespace: openshift-kube-controller-manager
    resourceVersion: "30420"
    uid: cf553965-3fba-4a4b-9c6e-9973b66572b9
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fc956172f
    namespace: openshift-kube-controller-manager
    resourceVersion: "30425"
    uid: 8253c0f3-5ee0-48e9-98ff-3e837624eeb9
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fca56ce8d
    namespace: openshift-kube-controller-manager
    resourceVersion: "30426"
    uid: e55c209d-d145-4914-bbfd-5f42f02a9e68
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fca6959f8
    namespace: openshift-kube-controller-manager
    resourceVersion: "30427"
    uid: f83548e4-c6dd-4aed-9ced-7a6853b38386
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fd340e820
    namespace: openshift-kube-controller-manager
    resourceVersion: "30428"
    uid: 2ef5f231-5e31-4fab-b387-40c369a99c24
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fd467a7c7
    namespace: openshift-kube-controller-manager
    resourceVersion: "30429"
    uid: 7ad0ce0d-1978-48b3-81a7-097ebb4da78b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fd47bd4be
    namespace: openshift-kube-controller-manager
    resourceVersion: "30430"
    uid: 885e5adb-a034-465e-887f-831e3faa9c47
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fdfc25cfe
    namespace: openshift-kube-controller-manager
    resourceVersion: "30433"
    uid: 18cbe2c5-b044-487a-8965-a2eb7fca59dd
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fe13b646d
    namespace: openshift-kube-controller-manager
    resourceVersion: "30434"
    uid: d5dfb8ec-fee5-4ef4-a0ea-0ee36aa8c87b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fe2943393
    namespace: openshift-kube-controller-manager
    resourceVersion: "30435"
    uid: 36298a94-9190-44a3-bc4f-d10fecd368af
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:21Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:38:21Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:38:21Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348fea1cb564
    namespace: openshift-kube-controller-manager
    resourceVersion: "30438"
    uid: 6cc802d7-8a7d-4a36-b22c-3d1f70a18843
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:22Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:22Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:22Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348ff247e18f
    namespace: openshift-kube-controller-manager
    resourceVersion: "30444"
    uid: b2b4c0cd-7e89-4cdc-8bc8-be5d1f9c298a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:22Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:38:22Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:38:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:38:22Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e348ff3aafc1f
    namespace: openshift-kube-controller-manager
    resourceVersion: "30445"
    uid: 18553c8f-5738-4f47-b3c4-329aec38a2c1
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:42:42Z"
  message: Stopping container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:42:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:42Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34cc9c311070
    namespace: openshift-kube-controller-manager
    resourceVersion: "37326"
    uid: 52cb28a0-7d39-415d-9909-76372c814284
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:42:42Z"
  message: Stopping container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:42Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34cc9c31ca39
    namespace: openshift-kube-controller-manager
    resourceVersion: "37328"
    uid: 403adc44-107e-4939-b786-a3410758d88f
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:42:42Z"
  message: Stopping container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:42:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:42Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34cc9c36edb9
    namespace: openshift-kube-controller-manager
    resourceVersion: "37330"
    uid: 4c005c28-2b52-49ad-ac93-57e7157d0fcc
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 79c7bb2e5060b838f52d2731cea1f913
  kind: Event
  lastTimestamp: "2023-12-06T09:42:42Z"
  message: Stopping container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:42Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34cc9c37a4ee
    namespace: openshift-kube-controller-manager
    resourceVersion: "37331"
    uid: dbf320fd-166f-424d-84ab-6eedbee7375b
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d03eab6bf0
    namespace: openshift-kube-controller-manager
    resourceVersion: "37567"
    uid: aae88ed4-2298-4721-899e-40aaa08cb25e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d046c09fb0
    namespace: openshift-kube-controller-manager
    resourceVersion: "37568"
    uid: 81503e46-82f2-4759-905b-d9b1f12c68a0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d0479fc964
    namespace: openshift-kube-controller-manager
    resourceVersion: "37569"
    uid: 8a3ca437-fab0-40e6-a00c-9ae6b9a6aa16
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d047add920
    namespace: openshift-kube-controller-manager
    resourceVersion: "37570"
    uid: 55b930f0-c6ba-4a44-9401-683bfbd57710
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d0507d16d7
    namespace: openshift-kube-controller-manager
    resourceVersion: "37571"
    uid: 2431d876-42fd-4c27-ad43-61cec57c5375
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d0518e9c2d
    namespace: openshift-kube-controller-manager
    resourceVersion: "37573"
    uid: 11a92a58-a90e-45b6-ab85-9372399bfa79
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d051a80932
    namespace: openshift-kube-controller-manager
    resourceVersion: "37574"
    uid: def106c9-5ac7-44ec-9962-57dfd6d48668
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d05ac88a0f
    namespace: openshift-kube-controller-manager
    resourceVersion: "37576"
    uid: 68f95f8b-4137-478b-a5a5-e7942eeecff5
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d05be82664
    namespace: openshift-kube-controller-manager
    resourceVersion: "37577"
    uid: ac08f5d2-0d8c-416c-a973-724d370cf833
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d05bf7aa70
    namespace: openshift-kube-controller-manager
    resourceVersion: "37578"
    uid: b3a77251-d94d-4810-a500-a96cb7525cb7
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d065775ab5
    namespace: openshift-kube-controller-manager
    resourceVersion: "37579"
    uid: 7cd35a38-fb4a-40b2-9fc7-8c0e2b4cde1e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:42:58Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:42:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:42:58Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d0667f301a
    namespace: openshift-kube-controller-manager
    resourceVersion: "37580"
    uid: dbd411dd-f862-42d1-bfd7-37e3623fd6bd
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:59Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:42:59Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:42:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:42:59Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d0740f4cde
    namespace: openshift-kube-controller-manager
    resourceVersion: "37581"
    uid: a6f30227-508a-4061-a96a-ec19df9dd739
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:18Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:43:18Z"
  message: Stopping container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:43:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:18Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d5156696bb
    namespace: openshift-kube-controller-manager
    resourceVersion: "37764"
    uid: 4abb5287-6220-41d0-b39e-38a0345a0700
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:18Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:43:18Z"
  message: Stopping container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:43:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:19Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d51566b46c
    namespace: openshift-kube-controller-manager
    resourceVersion: "37766"
    uid: 171d9e8a-9f80-4b70-9f47-e81986b304c4
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:18Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:43:18Z"
  message: Stopping container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:43:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:19Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d5156771d7
    namespace: openshift-kube-controller-manager
    resourceVersion: "37767"
    uid: a4bf3488-089e-4283-a97f-ccab0e0d3186
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:18Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 1a5df31fd7848941f5ed37f5a4a9c874
  kind: Event
  lastTimestamp: "2023-12-06T09:43:18Z"
  message: Stopping container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:43:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:19Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d51568c291
    namespace: openshift-kube-controller-manager
    resourceVersion: "37768"
    uid: d0216b17-29ca-44b7-a87e-f6855c92848d
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d829f278f5
    namespace: openshift-kube-controller-manager
    resourceVersion: "37923"
    uid: d67ed349-0cab-4cf8-b9dd-12104fc1dc62
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d833d7adc2
    namespace: openshift-kube-controller-manager
    resourceVersion: "37933"
    uid: ba6c9490-e069-4ada-a963-5f55e038db87
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d834ea9a7d
    namespace: openshift-kube-controller-manager
    resourceVersion: "37934"
    uid: f4d9e3c8-ddd3-42f4-9174-406880c87903
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d834f62eb3
    namespace: openshift-kube-controller-manager
    resourceVersion: "37935"
    uid: 3808102b-f554-4b94-9123-1104db7358f5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d83c6c7066
    namespace: openshift-kube-controller-manager
    resourceVersion: "37936"
    uid: 9f673d94-4604-4f3f-85a0-238a2bdf9c30
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d83d6be198
    namespace: openshift-kube-controller-manager
    resourceVersion: "37937"
    uid: 8693b5c6-879f-40d3-96c0-8ad9a4b9e76f
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:53:32Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d83d77f5d0
    namespace: openshift-kube-controller-manager
    resourceVersion: "44224"
    uid: 33cbe2cb-72ea-4837-bfff-b2b935b4856c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:53:33Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:33Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d845399b24
    namespace: openshift-kube-controller-manager
    resourceVersion: "44229"
    uid: 270bcaad-704a-4e3b-8160-069c58f9defa
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:53:33Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:53:33Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d84643a95a
    namespace: openshift-kube-controller-manager
    resourceVersion: "44230"
    uid: fbf5850e-4628-4112-8766-e724e44de8b9
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d8465c104b
    namespace: openshift-kube-controller-manager
    resourceVersion: "37941"
    uid: 2128ce48-7f44-4f45-a19b-0ac371e6f40c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d84fb7e086
    namespace: openshift-kube-controller-manager
    resourceVersion: "37942"
    uid: 6e7a019c-8e8b-406c-8298-403ee6b620c2
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: dd2f6e83571c51135364c3c57dba8230
  kind: Event
  lastTimestamp: "2023-12-06T09:43:32Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:43:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:43:32Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d8512c96eb
    namespace: openshift-kube-controller-manager
    resourceVersion: "37943"
    uid: 0e782381-c685-4862-9402-b520dbc204a9
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:43:33Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:43:33Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:43:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:43:33Z"
    name: kube-controller-manager-ip-10-0-21-63.us-west-1.compute.internal.179e34d859f7fb29
    namespace: openshift-kube-controller-manager
    resourceVersion: "37945"
    uid: b5b72a1e-d480-4e44-9fc6-ec955c2ebea8
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:13Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:13Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
  metadata:
    creationTimestamp: "2023-12-06T09:24:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:13Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ca6062e6e4
    namespace: openshift-kube-controller-manager
    resourceVersion: "15838"
    uid: 0d63b2c0-17d8-41da-bcdf-583eb7862d0d
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    in 13.066s (13.066s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33cd6b32c3fa
    namespace: openshift-kube-controller-manager
    resourceVersion: "16028"
    uid: 440b4579-88db-499c-9eac-6555711c8bf1
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33cd769c8425
    namespace: openshift-kube-controller-manager
    resourceVersion: "16033"
    uid: 20ceb64a-315a-48c3-8724-759f6c94bbc5
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33cd77d34495
    namespace: openshift-kube-controller-manager
    resourceVersion: "16034"
    uid: ecfe475f-b224-4d8f-9781-ec7f497abf70
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:26Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
  metadata:
    creationTimestamp: "2023-12-06T09:24:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:26Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33cd77dfedad
    namespace: openshift-kube-controller-manager
    resourceVersion: "16035"
    uid: 74b3693d-99ea-44ff-b6fc-32785246cd85
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:30Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    in 3.41s (3.41s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce432fe290
    namespace: openshift-kube-controller-manager
    resourceVersion: "16059"
    uid: b547322f-f3b6-4e8e-9c67-374db66ad976
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:30Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce48e6b257
    namespace: openshift-kube-controller-manager
    resourceVersion: "16062"
    uid: 21dc93d4-2e41-4f2d-b88e-6846d5330325
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:30Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce4994382e
    namespace: openshift-kube-controller-manager
    resourceVersion: "16063"
    uid: c4cd5621-fd19-43e2-9a08-6ed2da24f38e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:34:30Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:34:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce499df72c
    namespace: openshift-kube-controller-manager
    resourceVersion: "26933"
    uid: b72db50b-a82e-47a2-9077-903b7e18391f
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:34:30Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:34:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce4faf67be
    namespace: openshift-kube-controller-manager
    resourceVersion: "26937"
    uid: 1597fbc4-d1f7-4412-8a04-6392e0d8db0f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:34:30Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:34:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce5066a851
    namespace: openshift-kube-controller-manager
    resourceVersion: "26938"
    uid: 4434cd2a-5137-4cdc-92cd-49768b448e58
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:30Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce507068c1
    namespace: openshift-kube-controller-manager
    resourceVersion: "16069"
    uid: af45f24f-aec4-459d-9eb2-32f1b127c209
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:30Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce572ad1c3
    namespace: openshift-kube-controller-manager
    resourceVersion: "16070"
    uid: 76822f58-0728-4cf3-84a1-d1e3ae392bc4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:24:30Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:24:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce57dea88a
    namespace: openshift-kube-controller-manager
    resourceVersion: "16071"
    uid: 397db0ed-05ff-4972-bb0f-ae82f386bbf3
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:30Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:24:30Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:24:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:24:30Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e33ce6b7d43e6
    namespace: openshift-kube-controller-manager
    resourceVersion: "16078"
    uid: a9658449-8b0e-4f3b-b63c-c15d1b12f3fd
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:39:21Z"
  message: Stopping container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:39:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:21Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e349dbb02a0e8
    namespace: openshift-kube-controller-manager
    resourceVersion: "33213"
    uid: 2ee6db8c-f360-428e-a23e-749cdb450d22
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:39:21Z"
  message: Stopping container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:39:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:21Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e349dbb05812b
    namespace: openshift-kube-controller-manager
    resourceVersion: "33214"
    uid: 0219f77f-0597-4bf0-8217-4376a9aca8c8
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:39:21Z"
  message: Stopping container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:39:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:21Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e349dbb0653d5
    namespace: openshift-kube-controller-manager
    resourceVersion: "33216"
    uid: 6c7e8a87-a2a4-4a88-a26f-22f09afc4393
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: 934227bd39596dc7121be8f90311e0e2
  kind: Event
  lastTimestamp: "2023-12-06T09:39:21Z"
  message: Stopping container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:39:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:21Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e349dbb06ef94
    namespace: openshift-kube-controller-manager
    resourceVersion: "33218"
    uid: ae3e71fa-eab5-4e25-b923-b8a19f7a8f1b
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:40:33Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:39:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:33Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0a61c5b3a
    namespace: openshift-kube-controller-manager
    resourceVersion: "34943"
    uid: 307c8482-0888-48c7-b056-9f7fa1964e0c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:40:33Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:39:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:33Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0abffac0e
    namespace: openshift-kube-controller-manager
    resourceVersion: "34944"
    uid: a6af0cd3-48b8-4143-b39c-cbf9f0436d5c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:40:33Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:39:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:33Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0acc02ec5
    namespace: openshift-kube-controller-manager
    resourceVersion: "34946"
    uid: 62d2d2f6-4979-4006-b27a-cd2f599e3666
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:33Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:39:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:33Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0accc272f
    namespace: openshift-kube-controller-manager
    resourceVersion: "33659"
    uid: 27377aaf-9f23-4073-841c-02fa7c82ed6a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:33Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:39:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:33Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0b26d7db0
    namespace: openshift-kube-controller-manager
    resourceVersion: "33661"
    uid: e2e04bf8-2b46-4b87-9b36-f185bafae64e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:33Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:39:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:33Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0b31adce4
    namespace: openshift-kube-controller-manager
    resourceVersion: "33662"
    uid: a86fb45a-ee9a-41a4-a8b9-7337a7078aa0
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:33Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:39:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:34Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0b3252f8a
    namespace: openshift-kube-controller-manager
    resourceVersion: "33663"
    uid: 6121b3de-23d3-4f98-b7e8-f662ef61a6ce
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:34Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:39:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:34Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0b93805fd
    namespace: openshift-kube-controller-manager
    resourceVersion: "33664"
    uid: 640afcd9-168e-498a-8898-c8c368b1b3f7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:34Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:39:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:34Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0ba07e609
    namespace: openshift-kube-controller-manager
    resourceVersion: "33665"
    uid: 26a1b9c6-dbc9-4b7b-9e45-219d5deece68
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:34Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:39:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:34Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0ba13c7d4
    namespace: openshift-kube-controller-manager
    resourceVersion: "33666"
    uid: 76537708-380e-49db-b0b5-be14164e6605
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:34Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:39:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:34Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0c0dd5332
    namespace: openshift-kube-controller-manager
    resourceVersion: "33669"
    uid: e829330c-b8b9-4550-9d22-8ad010df850d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:39:34Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:39:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:39:34Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0c19069da
    namespace: openshift-kube-controller-manager
    resourceVersion: "33670"
    uid: 32041ea1-d716-449e-95fe-8cff472a7df7
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:34Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:39:34Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:39:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:39:34Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a0c83e2338
    namespace: openshift-kube-controller-manager
    resourceVersion: "33671"
    uid: d5cb7f82-7666-4726-96e0-e66283e14c15
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:40:03Z"
  message: "Startup probe error: Get \"https://10.0.94.160:10257/healthz\": dial tcp
    10.0.94.160:10257: connect: connection refused\nbody: \n"
  metadata:
    creationTimestamp: "2023-12-06T09:39:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:03Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a2f8d92569
    namespace: openshift-kube-controller-manager
    resourceVersion: "34339"
    uid: 244f5f24-06be-45bc-8c48-f97bd002fe57
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:40:03Z"
  message: 'Startup probe failed: Get "https://10.0.94.160:10257/healthz": dial tcp
    10.0.94.160:10257: connect: connection refused'
  metadata:
    creationTimestamp: "2023-12-06T09:39:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:03Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a2f8d99388
    namespace: openshift-kube-controller-manager
    resourceVersion: "34340"
    uid: 662fa15a-b8a2-48c0-ac95-851310dba67c
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:40:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:40:03Z"
  message: Container kube-controller-manager failed startup probe, will be restarted
  metadata:
    creationTimestamp: "2023-12-06T09:40:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:40:03Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34a7a1098921
    namespace: openshift-kube-controller-manager
    resourceVersion: "34341"
    uid: 14a2eeb0-f684-4d32-913c-907a0d836070
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:28Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:44:28Z"
  message: Stopping container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:44:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:28Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e5488c741a
    namespace: openshift-kube-controller-manager
    resourceVersion: "38526"
    uid: 83ae81c0-1791-44da-b60a-28708306c876
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:28Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:44:28Z"
  message: Stopping container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:44:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:28Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e5488ce03a
    namespace: openshift-kube-controller-manager
    resourceVersion: "38527"
    uid: 40818ed6-ad17-497a-ae4b-87f0d6d81bc6
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:28Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: fb20b51b08377c89867491c11dde1a0c
  kind: Event
  lastTimestamp: "2023-12-06T09:44:28Z"
  message: Stopping container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:44:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:28Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e5488d5254
    namespace: openshift-kube-controller-manager
    resourceVersion: "38529"
    uid: 53818712-928b-4a5f-8ae8-9524db0fd724
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:41Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c7976e17396681de12993cb44704f01b2fa08b0b24b5f651b4d69dd4b43873f9"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:44:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:41Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e85c36bd08
    namespace: openshift-kube-controller-manager
    resourceVersion: "38691"
    uid: 2d00e81c-2d5a-45a4-88a9-18b02b07fbaf
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:41Z"
  message: Created container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:44:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:41Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e863c4d0e5
    namespace: openshift-kube-controller-manager
    resourceVersion: "38698"
    uid: 924395a3-dc70-4d89-a213-b0025ddf56f0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:41Z"
  message: Started container kube-controller-manager
  metadata:
    creationTimestamp: "2023-12-06T09:44:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:41Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e864a73032
    namespace: openshift-kube-controller-manager
    resourceVersion: "38699"
    uid: bc70aec3-d968-452c-9206-3d800ae7b7f4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:41Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ad49f1a8d97c64265b29f8b6afd83fa16d7c98680a707b30c40e5f3390d170a1"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:44:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:41Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e864b16672
    namespace: openshift-kube-controller-manager
    resourceVersion: "38700"
    uid: 207c69ed-ca37-4e65-8a31-76951758a621
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:42Z"
  message: Created container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:42Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e86b4d6ef6
    namespace: openshift-kube-controller-manager
    resourceVersion: "38705"
    uid: 6dec182e-dd20-42f6-8900-14f4a39eeaea
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{cluster-policy-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:42Z"
  message: Started container cluster-policy-controller
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:42Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e86c0df64a
    namespace: openshift-kube-controller-manager
    resourceVersion: "38706"
    uid: d071157f-076b-4b69-a60f-c1f7757fae12
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:54:43Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:43Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e86c18f55e
    namespace: openshift-kube-controller-manager
    resourceVersion: "45110"
    uid: 29e50c9c-5478-4d28-a2ca-d557ebd57a9e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:54:43Z"
  message: Created container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:43Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e8752341f0
    namespace: openshift-kube-controller-manager
    resourceVersion: "45117"
    uid: 154a04cf-81e3-48ff-9f2d-a1a063cd6892
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-cert-syncer}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:54:43Z"
  message: Started container kube-controller-manager-cert-syncer
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:54:43Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e87668b940
    namespace: openshift-kube-controller-manager
    resourceVersion: "45118"
    uid: 8c9f70c4-5599-49d4-9d1a-194a2a0798c5
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:42Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:c936b6297ca6b08bc72aa2b56c865ea18cb04838f10f843997c5f38745354be4"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:42Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e87677de0f
    namespace: openshift-kube-controller-manager
    resourceVersion: "38716"
    uid: d09971a0-b35b-4c7c-9640-1e74363f9f9c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:42Z"
  message: Created container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:42Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e87dfbe1df
    namespace: openshift-kube-controller-manager
    resourceVersion: "38717"
    uid: ef83ab8b-8b3c-4cc8-89de-311b5b073a6b
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-recovery-controller}
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
    uid: a0c56413a085b2cbf127096b8a7d80c5
  kind: Event
  lastTimestamp: "2023-12-06T09:44:42Z"
  message: Started container kube-controller-manager-recovery-controller
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:44:42Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e87eb9c41f
    namespace: openshift-kube-controller-manager
    resourceVersion: "38718"
    uid: 46a66706-3c95-4439-a009-4ddc8ca35946
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-94-160.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-94-160.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:44:42Z"
  involvedObject:
    kind: Pod
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal
    namespace: openshift-kube-controller-manager
  kind: Event
  lastTimestamp: "2023-12-06T09:44:42Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:kube-controller-manager" cannot get resource "infrastructures" in API
    group "config.openshift.io" at the cluster scope'
  metadata:
    creationTimestamp: "2023-12-06T09:44:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-policy-controller
      operation: Update
      time: "2023-12-06T09:44:42Z"
    name: kube-controller-manager-ip-10-0-94-160.us-west-1.compute.internal.179e34e8952371d6
    namespace: openshift-kube-controller-manager
    resourceVersion: "38722"
    uid: d1f979f4-20ca-4262-8dc8-1b174dd6a00b
  reason: ClusterInfrastructureStatus
  reportingComponent: cluster-policy-controller
  reportingInstance: ""
  source:
    component: cluster-policy-controller
  type: Warning
kind: EventList
metadata:
  resourceVersion: "47880"
