---
apiVersion: v1
items:
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:18:38Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "2368"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:18:38Z"
  message: '0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized:
    true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..'
  metadata:
    creationTimestamp: "2023-12-06T09:18:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2023-12-06T09:18:38Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e337c56c4e31d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "2370"
    uid: 97bec2d9-4251-4b2b-bcca-bfff1727d0a8
  reason: FailedScheduling
  reportingComponent: default-scheduler
  reportingInstance: ""
  source:
    component: default-scheduler
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:20:49Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "2372"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:20:49Z"
  message: Successfully assigned openshift-kube-apiserver-operator/kube-apiserver-operator-77bdf6cc54-wdwt8
    to ip-10-0-21-63.us-west-1.compute.internal
  metadata:
    creationTimestamp: "2023-12-06T09:20:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2023-12-06T09:20:49Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e339adf92a5b5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4410"
    uid: 7756fdbc-7187-46e9-844e-ddf57af9ca5f
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: ""
  source:
    component: default-scheduler
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:20:50Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4404"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:20:50Z"
  message: Add eth0 [10.129.0.16/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2023-12-06T09:20:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2023-12-06T09:20:50Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e339b0c8864a5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4490"
    uid: 72a35dd8-fa77-4e95-91b9-1939144d2103
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:20:50Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-operator}
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4368"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:20:50Z"
  message: Pulling image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
  metadata:
    creationTimestamp: "2023-12-06T09:20:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:20:50Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e339b0dc597ad
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4502"
    uid: a120f885-3708-40b4-a122-a877fe2ad686
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:02Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-operator}
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4368"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:21:02Z"
  message: Successfully pulled image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    in 12.437s (12.437s including waiting)
  metadata:
    creationTimestamp: "2023-12-06T09:21:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:21:02Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e339df315bc5a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4722"
    uid: e398e36b-ba5a-4c4f-90e3-fa6e41b5d600
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:05Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-operator}
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4368"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:22:37Z"
  message: Created container kube-apiserver-operator
  metadata:
    creationTimestamp: "2023-12-06T09:21:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:22:37Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e339eae4f7229
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11046"
    uid: 2e15cd38-8c68-4637-ae9e-6fb100476a8b
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-operator}
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4368"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:22:37Z"
  message: Started container kube-apiserver-operator
  metadata:
    creationTimestamp: "2023-12-06T09:21:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:22:37Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e339ebb551d37
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11047"
    uid: eebeb8b9-868f-4951-b358-d0c130eb9c1d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:07Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4606"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:21:07Z"
  message: 'failed to add remote pod openshift-kube-apiserver-operator/kube-apiserver-operator-77bdf6cc54-wdwt8
    to namespace: failed add ips to address set default-network-controller:Namespace:openshift-kube-apiserver-operator:
    (error in transact with ops [{Op:mutate Table:Address_Set Row:map[] Rows:[] Columns:[]
    Mutations:[{Column:addresses Mutator:insert Value:{GoSet:[10.129.0.16]}}] Timeout:<nil>
    Where:[where column _uuid == {aef845b6-1a9b-469e-986e-72cf3dcb3345}] Until: Durable:<nil>
    Comment:<nil> Lock:<nil> UUID: UUIDName:}]: context deadline exceeded: while awaiting
    reconnection)'
  metadata:
    creationTimestamp: "2023-12-06T09:21:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: ip-10-0-94-160
      operation: Update
      time: "2023-12-06T09:21:07Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e339f177140f9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4967"
    uid: 79dbc887-38a1-4476-adf1-20f284337c88
  reason: ErrorUpdatingResource
  reportingComponent: controlplane
  reportingInstance: ""
  source:
    component: controlplane
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-operator}
    kind: Pod
    name: kube-apiserver-operator-77bdf6cc54-wdwt8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4368"
    uid: 3f76be65-9fe7-4902-b550-a2780e97ac9e
  kind: Event
  lastTimestamp: "2023-12-06T09:22:37Z"
  message: Container image "registry.build03.ci.openshift.org/ci-op-2j285qtr/stable@sha256:ae6e1c62c9475900e7abe01717f623bf9f1c27cc9903b09b773a57d43e613199"
    already present on machine
  metadata:
    creationTimestamp: "2023-12-06T09:22:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2023-12-06T09:22:37Z"
    name: kube-apiserver-operator-77bdf6cc54-wdwt8.179e33b3fe2f28c5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11035"
    uid: c1f3ab93-4645-4c70-a5cc-3d2b5a779a67
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-21-63.us-west-1.compute.internal
  source:
    component: kubelet
    host: ip-10-0-21-63.us-west-1.compute.internal
  type: Normal
- apiVersion: v1
  count: 12
  eventTime: null
  firstTimestamp: "2023-12-06T09:18:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: kube-apiserver-operator-77bdf6cc54
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "1992"
    uid: a98d8028-e458-459c-bf6a-9cd34534fa56
  kind: Event
  lastTimestamp: "2023-12-06T09:18:28Z"
  message: 'Error creating: pods "kube-apiserver-operator-77bdf6cc54-" is forbidden:
    autoscaling.openshift.io/ManagementCPUsOverride the cluster does not have any
    nodes'
  metadata:
    creationTimestamp: "2023-12-06T09:18:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2023-12-06T09:18:28Z"
    name: kube-apiserver-operator-77bdf6cc54.179e33779085bcff
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "2294"
    uid: f688a388-49d6-405d-956e-10ed8bb63055
  reason: FailedCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:18:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: kube-apiserver-operator-77bdf6cc54
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "1996"
    uid: a98d8028-e458-459c-bf6a-9cd34534fa56
  kind: Event
  lastTimestamp: "2023-12-06T09:18:38Z"
  message: 'Created pod: kube-apiserver-operator-77bdf6cc54-wdwt8'
  metadata:
    creationTimestamp: "2023-12-06T09:18:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2023-12-06T09:18:38Z"
    name: kube-apiserver-operator-77bdf6cc54.179e337c56b408df
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "2369"
    uid: d44eacf0-11d5-4d7a-b210-b45e8ff02552
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:07Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: kube-apiserver-operator-lock
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4985"
    uid: 2df3180f-eb0a-4da6-a5d9-585f0f286e87
  kind: Event
  lastTimestamp: "2023-12-06T09:21:07Z"
  message: kube-apiserver-operator-77bdf6cc54-wdwt8_2796e8cf-c0c0-498a-bf53-a53208da8cbd
    became leader
  metadata:
    creationTimestamp: "2023-12-06T09:21:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:07Z"
    name: kube-apiserver-operator-lock.179e339f2afea833
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4987"
    uid: 9ab642fe-264b-4292-9e53-d75dac5c87f4
  reason: LeaderElection
  reportingComponent: kube-apiserver-operator
  reportingInstance: ""
  source:
    component: kube-apiserver-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:37Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: kube-apiserver-operator-lock
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11051"
    uid: 2df3180f-eb0a-4da6-a5d9-585f0f286e87
  kind: Event
  lastTimestamp: "2023-12-06T09:22:37Z"
  message: kube-apiserver-operator-77bdf6cc54-wdwt8_4e14dbf9-1353-4738-a9cc-60d6a3dc72f7
    became leader
  metadata:
    creationTimestamp: "2023-12-06T09:22:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:37Z"
    name: kube-apiserver-operator-lock.179e33b421a416b7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11052"
    uid: 11501681-b7b0-4fd3-842c-124f97a7e432
  reason: LeaderElection
  reportingComponent: kube-apiserver-operator
  reportingInstance: ""
  source:
    component: kube-apiserver-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:18:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "1991"
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:18:17Z"
  message: Scaled up replica set kube-apiserver-operator-77bdf6cc54 to 1
  metadata:
    creationTimestamp: "2023-12-06T09:18:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2023-12-06T09:18:17Z"
    name: kube-apiserver-operator.179e3377904cdb05
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "1993"
    uid: 8c3438af-1d3d-4f80-b21a-674236319741
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:07Z"
  message: FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform",
    "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProvider",
    "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "ExternalCloudProviderGCP",
    "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy",
    "AutomatedEtcdBackup", "CSIDriverSharedResource", "ClusterAPIInstall", "DNSNameResolver",
    "DisableKubeletCloudCredentialProviders", "DynamicResourceAllocation", "EventedPLEG",
    "GCPClusterHostedDNS", "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "InstallAlternateInfrastructureAWS",
    "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack",
    "MachineConfigNodes", "ManagedBootImages", "MaxUnavailableStatefulSet", "MetricsServer",
    "MixedCPUsAllocation", "NetworkLiveMigration", "NodeSwap", "RouteExternalCertificate",
    "SigstoreImageVerification", "VSphereControlPlaneMachineSet", "VSphereStaticIPs",
    "ValidatingAdmissionPolicy"}}
  metadata:
    creationTimestamp: "2023-12-06T09:21:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:07Z"
    name: kube-apiserver-operator.179e339f2e8de144
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "4988"
    uid: b642bab4-9b7d-47cd-a5d4-ac8999e9cc40
  reason: FeatureGatesInitialized
  reportingComponent: kube-apiserver-operator
  reportingInstance: ""
  source:
    component: kube-apiserver-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:08Z"
  message: Issuer set to default value "https://kubernetes.default.svc"
  metadata:
    creationTimestamp: "2023-12-06T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:08Z"
    name: kube-apiserver-operator.179e339f51376763
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5032"
    uid: da17a4ef-532c-4ee6-8b61-d8e2b935c6f9
  reason: ServiceAccountIssuer
  reportingComponent: kube-apiserver-operator-serviceaccountissuercontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-serviceaccountissuercontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:08Z"
  message: Observed new master node ip-10-0-106-212.us-west-1.compute.internal
  metadata:
    creationTimestamp: "2023-12-06T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:08Z"
    name: kube-apiserver-operator.179e339f524527de
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5047"
    uid: 6f032c9f-daba-462d-a85c-9d628331efd8
  reason: MasterNodeObserved
  reportingComponent: kube-apiserver-operator-nodecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-nodecontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:08Z"
  message: Observed new master node ip-10-0-21-63.us-west-1.compute.internal
  metadata:
    creationTimestamp: "2023-12-06T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:08Z"
    name: kube-apiserver-operator.179e339f5245560a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5049"
    uid: d7627050-681e-4271-bf24-404d50f15689
  reason: MasterNodeObserved
  reportingComponent: kube-apiserver-operator-nodecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-nodecontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:08Z"
  message: Observed new master node ip-10-0-94-160.us-west-1.compute.internal
  metadata:
    creationTimestamp: "2023-12-06T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:08Z"
    name: kube-apiserver-operator.179e339f52455f38
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5052"
    uid: cce580e9-9a3b-40a7-9ab6-be270679025d
  reason: MasterNodeObserved
  reportingComponent: kube-apiserver-operator-nodecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-nodecontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:08Z"
  message: clusteroperator/kube-apiserver version "raw-internal" changed from "" to
    "4.15.0-0.ci.test-2023-12-06-090630-ci-op-2j285qtr-latest"
  metadata:
    creationTimestamp: "2023-12-06T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:08Z"
    name: kube-apiserver-operator.179e339f5a23b285
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5080"
    uid: e1489190-187c-4926-b0c9-098127e3f7c8
  reason: OperatorVersionChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:08Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded set to False
    ("NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)"),Progressing set to Unknown (""),Available
    set to Unknown (""),Upgradeable set to True ("KubeletMinorVersionUpgradeable:
    Kubelet and API server minor versions are synced."),status.relatedObjects changed
    from [{"operator.openshift.io" "kubeapiservers" "" "cluster"} {"apiextensions.k8s.io"
    "customresourcedefinitions" "" ""} {"security.openshift.io" "securitycontextconstraints"
    "" ""} {"" "namespaces" "" "openshift-config"} {"" "namespaces" "" "openshift-config-managed"}
    {"" "namespaces" "" "openshift-kube-apiserver-operator"} {"" "namespaces" "" "openshift-kube-apiserver"}
    {"admissionregistration.k8s.io" "mutatingwebhookconfigurations" "" ""} {"admissionregistration.k8s.io"
    "validatingwebhookconfigurations" "" ""} {"controlplane.operator.openshift.io"
    "podnetworkconnectivitychecks" "openshift-kube-apiserver" ""} {"apiserver.openshift.io"
    "apirequestcounts" "" ""}] to [{"operator.openshift.io" "kubeapiservers" "" "cluster"}
    {"apiextensions.k8s.io" "customresourcedefinitions" "" ""} {"security.openshift.io"
    "securitycontextconstraints" "" ""} {"" "namespaces" "" "openshift-config"} {""
    "namespaces" "" "openshift-config-managed"} {"" "namespaces" "" "openshift-kube-apiserver-operator"}
    {"" "namespaces" "" "openshift-kube-apiserver"} {"admissionregistration.k8s.io"
    "mutatingwebhookconfigurations" "" ""} {"admissionregistration.k8s.io" "validatingwebhookconfigurations"
    "" ""} {"controlplane.operator.openshift.io" "podnetworkconnectivitychecks" "openshift-kube-apiserver"
    ""} {"apiserver.openshift.io" "apirequestcounts" "" ""} {"config.openshift.io"
    "nodes" "" "cluster"}],status.versions changed from [] to [{"raw-internal" "4.15.0-0.ci.test-2023-12-06-090630-ci-op-2j285qtr-latest"}]'
  metadata:
    creationTimestamp: "2023-12-06T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:08Z"
    name: kube-apiserver-operator.179e339f6a3f4bc0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5078"
    uid: 9e2a86e8-a307-461f-89d9-2a79c03199cd
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:09Z"
  message: Controller "auditPolicyController" resync interval is set to 10s which
    might lead to client request throttling
  metadata:
    creationTimestamp: "2023-12-06T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:09Z"
    name: kube-apiserver-operator.179e339f7bf4e516
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5152"
    uid: 79cfb3c3-5bfe-4879-9976-1bec3200acd8
  reason: FastControllerResync
  reportingComponent: kube-apiserver-operator-audit-policy-controller-auditpolicycontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-audit-policy-controller-auditpolicycontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:09Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing changed
    from Unknown to False ("All is well")'
  metadata:
    creationTimestamp: "2023-12-06T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:09Z"
    name: kube-apiserver-operator.179e339f81184ecd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5175"
    uid: 88888636-d8c8-4dd6-9d49-5801cf63dfaf
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:09Z"
  message: new revision 1 triggered by "configmap \"kube-apiserver-pod\" not found"
  metadata:
    creationTimestamp: "2023-12-06T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:09Z"
    name: kube-apiserver-operator.179e339f87c00d6b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5183"
    uid: 2e68e206-9d3e-4dc8-8bfb-14af13d5dfab
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 13
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:14Z"
  message: 'configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0'
  metadata:
    creationTimestamp: "2023-12-06T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:17Z"
    name: kube-apiserver-operator.179e339f9f9987d1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6373"
    uid: 910da853-f6f8-41c8-ae8d-e50fb46fa7df
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:09Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)" to "NodeControllerDegraded: The master nodes
    not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\" not ready since
    2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container runtime network
    not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin
    returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your
    network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]",Progressing
    message changed from "All is well" to "NodeInstallerProgressing: 3 nodes are at
    revision 0",Available changed from Unknown to False ("StaticPodsAvailable: 0 nodes
    are active; 3 nodes are at revision 0")'
  metadata:
    creationTimestamp: "2023-12-06T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:09Z"
    name: kube-apiserver-operator.179e339fa22c9fb8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5244"
    uid: e2e41083-1061-4796-b398-a602a5fb737a
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:09Z"
  message: Created PodDisruptionBudget.policy/kube-apiserver-guard-pdb -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:10Z"
    name: kube-apiserver-operator.179e339fa3f8098a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5293"
    uid: 205f70e2-f4d6-42e0-9127-87567287fa70
  reason: PodDisruptionBudgetCreated
  reportingComponent: kube-apiserver-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 21
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:14Z"
  message: no observedConfig
  metadata:
    creationTimestamp: "2023-12-06T09:21:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:27Z"
    name: kube-apiserver-operator.179e339fcf1b8d79
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7161"
    uid: c25ac1fe-6eaa-47cc-b60a-3016aa79f508
  reason: ConfigMissing
  reportingComponent: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:49Z"
  message: 'configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found'
  metadata:
    creationTimestamp: "2023-12-06T09:21:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:49Z"
    name: kube-apiserver-operator.179e339fdb062c56
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "8278"
    uid: c192e548-0068-47ed-8a07-1dfb5d523cbe
  reason: ObserveStorageFailed
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: Updated storage urls to https://localhost:2379
  metadata:
    creationTimestamp: "2023-12-06T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:12Z"
    name: kube-apiserver-operator.179e339fdb066bd0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5711"
    uid: 3a1781bb-57bb-4f40-a453-4442c470342f
  reason: ObserveStorageUpdated
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: CloudProvider config file changed to /etc/kubernetes/static-pod-resources/configmaps/cloud-config/config
  metadata:
    creationTimestamp: "2023-12-06T09:21:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:13Z"
    name: kube-apiserver-operator.179e339fdb09737f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5842"
    uid: 2d31e3bc-9282-48d6-8e8e-355afbdebbf8
  reason: ObserveCloudProviderNamesChanges
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: minTLSVersion changed to VersionTLS12
  metadata:
    creationTimestamp: "2023-12-06T09:21:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:14Z"
    name: kube-apiserver-operator.179e339fdb0b2b3b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5976"
    uid: 5c07746e-4255-4250-843a-1693e4c4ad6e
  reason: ObserveTLSSecurityProfile
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: cipherSuites changed to ["TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"
    "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"
    "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256" "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"]
  metadata:
    creationTimestamp: "2023-12-06T09:21:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:15Z"
    name: kube-apiserver-operator.179e339fdb0b74ac
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6067"
    uid: 505a4be9-79f0-4119-9b3d-284d82946218
  reason: ObserveTLSSecurityProfile
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: Updated apiServerArguments.feature-gates to AdminNetworkPolicy=false,AlibabaPlatform=true,AutomatedEtcdBackup=false,AzureWorkloadIdentity=true,BuildCSIVolumes=true,CSIDriverSharedResource=false,CloudDualStackNodeIPs=true,ClusterAPIInstall=false,DNSNameResolver=false,DisableKubeletCloudCredentialProviders=false,DynamicResourceAllocation=false,EventedPLEG=false,ExternalCloudProvider=true,ExternalCloudProviderAzure=true,ExternalCloudProviderExternal=true,ExternalCloudProviderGCP=true,GCPClusterHostedDNS=false,GCPLabelsTags=false,GatewayAPI=false,InsightsConfigAPI=false,InstallAlternateInfrastructureAWS=false,MachineAPIOperatorDisableMachineHealthCheckController=false,MachineAPIProviderOpenStack=false,MachineConfigNodes=false,ManagedBootImages=false,MaxUnavailableStatefulSet=false,MetricsServer=false,MixedCPUsAllocation=false,NetworkLiveMigration=false,NodeSwap=false,OpenShiftPodSecurityAdmission=true,PrivateHostedZoneAWS=true,RouteExternalCertificate=false,SigstoreImageVerification=false,VSphereControlPlaneMachineSet=false,VSphereStaticIPs=false,ValidatingAdmissionPolicy=false
  metadata:
    creationTimestamp: "2023-12-06T09:21:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:16Z"
    name: kube-apiserver-operator.179e339fdb0cf9fa
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6257"
    uid: 8e2b523e-2f1c-4364-84b0-a802a64cd638
  reason: ObserveFeatureFlagsUpdated
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: "Writing updated observed config:   map[string]any{\n+ \t\"admission\":
    map[string]any{\n+ \t\t\"pluginConfig\": map[string]any{\n+ \t\t\t\"PodSecurity\":
    \                                      map[string]any{\"configuration\": map[string]any{...}},\n+
    \t\t\t\"network.openshift.io/ExternalIPRanger\":             map[string]any{\"configuration\":
    map[string]any{...}},\n+ \t\t\t\"network.openshift.io/RestrictedEndpointsAdmission\":
    map[string]any{\"configuration\": map[string]any{...}},\n+ \t\t},\n+ \t},\n+ \t\"apiServerArguments\":
    map[string]any{\n+ \t\t\"api-audiences\":  []any{string(\"https://kubernetes.default.svc\")},\n+
    \t\t\"cloud-config\":   []any{string(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/config\")},\n+
    \t\t\"cloud-provider\": []any{string(\"external\")},\n+ \t\t\"etcd-servers\":
    \  []any{string(\"https://localhost:2379\")},\n+ \t\t\"feature-gates\": []any{\n+
    \t\t\tstring(\"AdminNetworkPolicy=false\"), string(\"AlibabaPlatform=true\"),\n+
    \t\t\tstring(\"AutomatedEtcdBackup=false\"), string(\"AzureWorkloadIdentity=true\"),\n+
    \t\t\tstring(\"BuildCSIVolumes=true\"), string(\"CSIDriverSharedResource=false\"),\n+
    \t\t\tstring(\"CloudDualStackNodeIPs=true\"), string(\"ClusterAPIInstall=false\"),
    ...,\n+ \t\t},\n+ \t\t\"send-retry-after-while-not-ready-once\": []any{string(\"false\")},\n+
    \t\t\"service-account-issuer\":                []any{string(\"https://kubernetes.default.svc\")},\n+
    \t\t\"service-account-jwks-uri\":              []any{string(\"https://api.ci-op-2j285qtr-234c7.origin-ci-int-aws.dev.rhcloud.c\"...)},\n+
    \t\t\"shutdown-delay-duration\":               []any{string(\"129s\")},\n+ \t},\n+
    \t\"corsAllowedOrigins\":          []any{string(`//127\\.0\\.0\\.1(:|$)`), string(\"//localhost(:|$)\")},\n+
    \t\"gracefulTerminationDuration\": string(\"194\"),\n+ \t\"servicesSubnet\":              string(\"172.30.0.0/16\"),\n+
    \t\"servingInfo\": map[string]any{\n+ \t\t\"bindAddress\": string(\"0.0.0.0:6443\"),\n+
    \t\t\"bindNetwork\": string(\"tcp4\"),\n+ \t\t\"cipherSuites\": []any{\n+ \t\t\tstring(\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\"),\n+
    \t\t\tstring(\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\"),\n+ \t\t\tstring(\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"),\n+
    \t\t\tstring(\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\"),\n+ \t\t\tstring(\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\"),\n+
    \t\t\tstring(\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"),\n+ \t\t},\n+ \t\t\"minTLSVersion\":
    string(\"VersionTLS12\"),\n+ \t\t\"namedCertificates\": []any{\n+ \t\t\tmap[string]any{\n+
    \t\t\t\t\"certFile\": string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t\t\"keyFile\":
    \ string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t},\n+ \t\t\tmap[string]any{\n+
    \t\t\t\t\"certFile\": string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t\t\"keyFile\":
    \ string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t},\n+ \t\t\tmap[string]any{\n+
    \t\t\t\t\"certFile\": string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t\t\"keyFile\":
    \ string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t},\n+ \t\t\tmap[string]any{\n+
    \t\t\t\t\"certFile\": string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t\t\"keyFile\":
    \ string(\"/etc/kubernetes/static-pod-certs\"...),\n+ \t\t\t},\n+ \t\t\tmap[string]any{\n+
    \t\t\t\t\"certFile\": string(\"/etc/kubernetes/static-pod-resou\"...),\n+ \t\t\t\t\"keyFile\":
    \ string(\"/etc/kubernetes/static-pod-resou\"...),\n+ \t\t\t},\n+ \t\t},\n+ \t},\n
    \ }\n"
  metadata:
    creationTimestamp: "2023-12-06T09:21:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:17Z"
    name: kube-apiserver-operator.179e339fdb17234a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6396"
    uid: 9861d035-efc1-48a8-8c4d-8601cc34f2f7
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"node-system-admin-signer" in "openshift-kube-apiserver-operator" requires
    a new signing cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:11Z"
    name: kube-apiserver-operator.179e339fdb56c7dd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5646"
    uid: 0d7ac6f7-b8d2-4f7b-830d-6a98b3e9c3ad
  reason: SignerUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 4
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"kube-control-plane-signer-ca" in "openshift-kube-apiserver-operator"
    requires a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:19Z"
    name: kube-apiserver-operator.179e339fdb8b4b4e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6692"
    uid: 2e41a8f9-0ded-4269-93f4-eabefaa01d50
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"loadbalancer-serving-ca" in "openshift-kube-apiserver-operator" requires
    a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:17Z"
    name: kube-apiserver-operator.179e339fdb94c115
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6457"
    uid: 155a16b5-3941-4698-b2a1-8d55a7fd21e6
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"kube-apiserver-aggregator-client-ca" in "openshift-config-managed" requires
    a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:14Z"
    name: kube-apiserver-operator.179e339fdb9f6a0e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6001"
    uid: c795da21-afe5-498e-bdfa-68acdcb1aaee
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"kube-apiserver-to-kubelet-client-ca" in "openshift-kube-apiserver-operator"
    requires a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:15Z"
    name: kube-apiserver-operator.179e339fdbadc29a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6088"
    uid: f003d414-17b5-4cb3-936d-9d1f5a752c99
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"localhost-recovery-serving-signer" in "openshift-kube-apiserver-operator"
    requires a new signing cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:18Z"
    name: kube-apiserver-operator.179e339fdbd04094
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6595"
    uid: 1db308b0-7973-4fea-a85d-ba0d6682aa82
  reason: SignerUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"service-network-serving-ca" in "openshift-kube-apiserver-operator" requires
    a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:20Z"
    name: kube-apiserver-operator.179e339fdbebf08f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6792"
    uid: af14b6d1-7b59-42d2-aea2-d71515f33342
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:10Z"
  message: '"localhost-serving-ca" in "openshift-kube-apiserver-operator" requires
    a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:21Z"
    name: kube-apiserver-operator.179e339fdbf83092
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6830"
    uid: f47e918c-2b28-4bc7-ad8a-6451eae62ddb
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:11Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:11Z"
  message: Created ConfigMap/revision-status-1 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:12Z"
    name: kube-apiserver-operator.179e33a009d0a11f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5759"
    uid: dd34b76f-83f4-4dee-ace0-d81568fd40ed
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:12Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]"
    to "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found"'
  metadata:
    creationTimestamp: "2023-12-06T09:21:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:13Z"
    name: kube-apiserver-operator.179e33a0348936c6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5907"
    uid: 4b1de9bf-5755-4e45-8246-a2f7af49dd5d
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:12Z"
  message: Created ConfigMap/bound-sa-token-signing-certs -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:13Z"
    name: kube-apiserver-operator.179e33a0465ca84f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "5927"
    uid: 89583cae-1991-42af-b7f5-e02c393f3596
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-boundsatokensignercontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-boundsatokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:15Z"
  message: Created ConfigMap/etcd-serving-ca -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:15Z"
    name: kube-apiserver-operator.179e33a0d484a045
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6219"
    uid: 674ec0c9-3269-4330-ad08-aac3cf0fb4fc
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:15Z"
  message: Created ConfigMap/kube-apiserver-audit-policies -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:16Z"
    name: kube-apiserver-operator.179e33a0ec5dc614
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6295"
    uid: 6cb454d8-7fd1-4369-b4fb-a0ab4907ddf4
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-audit-policy-controller-auditpolicycontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-audit-policy-controller-auditpolicycontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:15Z"
  message: Created ServiceAccount/installer-sa -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:16Z"
    name: kube-apiserver-operator.179e33a0f829a169
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6329"
    uid: 4beac83c-1e02-49ae-8dd2-8a15a256a126
  reason: ServiceAccountCreated
  reportingComponent: kube-apiserver-operator-backingresourcecontroller-backingresourcecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-backingresourcecontroller-backingresourcecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:15Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:operator:openshift-kube-apiserver-installer
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:18Z"
    name: kube-apiserver-operator.179e33a0f86f8393
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6499"
    uid: 5d9ecaf3-9aa7-4a6b-bef7-cc3a749c4fb7
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-apiserver-operator-backingresourcecontroller-backingresourcecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-backingresourcecontroller-backingresourcecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:16Z"
  message: Created Secret/bound-service-account-signing-key -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:17Z"
    name: kube-apiserver-operator.179e33a11bf5855d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6436"
    uid: f589d37a-0285-40bf-a01e-474225d1549f
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-boundsatokensignercontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-boundsatokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:16Z"
  message: Created ConfigMap/kube-control-plane-signer-ca -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:21Z"
    name: kube-apiserver-operator.179e33a127ebb517
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6860"
    uid: e3fe7e4a-d61a-467c-8e88-74736c69301f
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:16Z"
  message: '"check-endpoints-client-cert-key" in "openshift-kube-apiserver" requires
    a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:22Z"
    name: kube-apiserver-operator.179e33a127ed07b1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6951"
    uid: 6d13b973-87e9-4fa6-8888-4f11b460b0a9
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:16Z"
  message: Created ConfigMap/loadbalancer-serving-ca -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:23Z"
    name: kube-apiserver-operator.179e33a133c0fb10
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6981"
    uid: 987c6f4b-d55c-4c46-bbde-38480dfa1cfa
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:16Z"
  message: '"external-loadbalancer-serving-certkey" in "openshift-kube-apiserver"
    requires a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:23Z"
    name: kube-apiserver-operator.179e33a133c299af
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7006"
    uid: 1ec5de5e-fd70-40bd-a44a-cfd38cd9d073
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:16Z"
  message: Created ConfigMap/kube-apiserver-aggregator-client-ca -n openshift-config-managed
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:25Z"
    name: kube-apiserver-operator.179e33a13fc0c068
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7046"
    uid: 01db9ff0-0d90-4846-bb51-be68048db464
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:16Z"
  message: '"aggregator-client" in "openshift-kube-apiserver" requires a new target
    cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:25Z"
    name: kube-apiserver-operator.179e33a13fc29715
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7080"
    uid: 4c553eaa-374f-4718-820b-7471e65f08b3
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:17Z"
  message: Created ConfigMap/kube-apiserver-to-kubelet-client-ca -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:26Z"
    name: kube-apiserver-operator.179e33a14baaca23
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7107"
    uid: adeb3f0d-cf2e-47e6-b88c-e9831e9f4207
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:17Z"
  message: '"kubelet-client" in "openshift-kube-apiserver" requires a new target cert/key
    pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:27Z"
    name: kube-apiserver-operator.179e33a14bac179f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7139"
    uid: 50e4a324-52f8-40fa-bc40-d3281cf943a9
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:19Z"
  message: 'configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0'
  metadata:
    creationTimestamp: "2023-12-06T09:21:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:20Z"
    name: kube-apiserver-operator.179e33a153d56d1d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6780"
    uid: 549f4ad2-7707-4f2b-a0ee-a4715697f3b7
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:17Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found" to
    "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found"'
  metadata:
    creationTimestamp: "2023-12-06T09:21:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:18Z"
    name: kube-apiserver-operator.179e33a153df9ab9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6565"
    uid: 790757dc-a503-46ee-9bca-99eddfafa71e
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:17Z"
  message: 'Failed to create ConfigMap/kube-control-plane-signer-ca -n openshift-kube-apiserver-operator:
    configmaps "kube-control-plane-signer-ca" already exists'
  metadata:
    creationTimestamp: "2023-12-06T09:21:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:30Z"
    name: kube-apiserver-operator.179e33a15795d613
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7284"
    uid: fd7d56c6-0972-49d0-835e-950e58d49ef9
  reason: ConfigMapCreateFailed
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:17Z"
  message: 'Failed to create ConfigMap/loadbalancer-serving-ca -n openshift-kube-apiserver-operator:
    configmaps "loadbalancer-serving-ca" already exists'
  metadata:
    creationTimestamp: "2023-12-06T09:21:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:28Z"
    name: kube-apiserver-operator.179e33a163a3ca18
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7217"
    uid: b3576673-211b-41a6-a994-38d522ce04a0
  reason: ConfigMapCreateFailed
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:18Z"
  message: Created ConfigMap/service-network-serving-ca -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:30Z"
    name: kube-apiserver-operator.179e33a1873991fd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7344"
    uid: 6be37784-1715-41df-b58d-419a8400a030
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:18Z"
  message: '"service-network-serving-certkey" in "openshift-kube-apiserver" requires
    a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:31Z"
    name: kube-apiserver-operator.179e33a1873b034b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7372"
    uid: e4e91512-30b5-45b7-bc45-b31d685287cd
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:18Z"
  message: Created ConfigMap/localhost-serving-ca -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:31Z"
    name: kube-apiserver-operator.179e33a1931b90f5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7380"
    uid: 50f0b10a-3cc8-4b32-b5fa-f75decf9a201
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:18Z"
  message: '"localhost-serving-cert-certkey" in "openshift-kube-apiserver" requires
    a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:31Z"
    name: kube-apiserver-operator.179e33a1931d67ac
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7384"
    uid: d99a2a69-bca7-4470-8c3e-1dbfe863a8cb
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:18Z"
  message: Created Secret/localhost-recovery-serving-signer -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:32Z"
    name: kube-apiserver-operator.179e33a19f349698
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7407"
    uid: 75ac72ad-e207-4641-af50-94f1d752d1dc
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:18Z"
  message: '"localhost-recovery-serving-ca" in "openshift-kube-apiserver-operator"
    requires a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:32Z"
    name: kube-apiserver-operator.179e33a19f3ec327
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7422"
    uid: 7f5b80cc-927e-4f3e-a941-abba997ef060
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:18Z"
  message: Created ConfigMap/sa-token-signing-certs -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:19Z"
    name: kube-apiserver-operator.179e33a1b6f93051
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6655"
    uid: a40bb641-d845-4ae9-be82-dc7ca523f40d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:19Z"
  message: Created Secret/node-system-admin-signer -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:33Z"
    name: kube-apiserver-operator.179e33a1c3334de2
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7444"
    uid: 46cac08d-6e67-4da2-948e-cda35415914a
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:19Z"
  message: '"node-system-admin-ca" in "openshift-kube-apiserver-operator" requires
    a new cert'
  metadata:
    creationTimestamp: "2023-12-06T09:21:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:33Z"
    name: kube-apiserver-operator.179e33a1c33a3226
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7456"
    uid: fc3057c6-5c8f-4b2f-a047-afcdf04beb45
  reason: CABundleUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:19Z"
  message: Created Service/apiserver -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:19Z"
    name: kube-apiserver-operator.179e33a1dacdb03b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6703"
    uid: 49a14b31-a627-42aa-8623-11eab1290ea1
  reason: ServiceCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:19Z"
  message: 'Failed to create Secret/bound-service-account-signing-key -n openshift-kube-apiserver:
    secrets "bound-service-account-signing-key" already exists'
  metadata:
    creationTimestamp: "2023-12-06T09:21:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:20Z"
    name: kube-apiserver-operator.179e33a1e6a55c99
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6757"
    uid: e423742b-fd74-4a3f-bdd1-6622988aaaa9
  reason: SecretCreateFailed
  reportingComponent: kube-apiserver-operator-boundsatokensignercontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-boundsatokensignercontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:19Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found" to
    "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found"'
  metadata:
    creationTimestamp: "2023-12-06T09:21:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:20Z"
    name: kube-apiserver-operator.179e33a1ed6a8c74
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6812"
    uid: 529d5aa5-d38c-4a8a-8a66-00e8c65ddc56
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ConfigMap/config -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:28Z"
    name: kube-apiserver-operator.179e33a245f9553e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7205"
    uid: 5d7ee9a5-fedb-494c-93b6-831db839aa16
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ConfigMap/cloud-config -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:21Z"
    name: kube-apiserver-operator.179e33a251d4bfc2
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6903"
    uid: d454774b-f235-4db6-91b0-ece735e07529
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:22Z"
    name: kube-apiserver-operator.179e33a269d0db8d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6957"
    uid: b9475538-405e-486f-aab6-8dec3bc2c851
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ClusterRole.rbac.authorization.k8s.io/system:openshift:controller:check-endpoints
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:23Z"
    name: kube-apiserver-operator.179e33a26a358c0b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6990"
    uid: efe3ad40-363a-4540-9908-e20301f7b06d
  reason: ClusterRoleCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ClusterRole.rbac.authorization.k8s.io/system:openshift:controller:check-endpoints-node-reader
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:24Z"
    name: kube-apiserver-operator.179e33a26a85cef4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7017"
    uid: 4cfef7db-35c6-4c39-af2f-262922f7f7f3
  reason: ClusterRoleCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ClusterRole.rbac.authorization.k8s.io/system:openshift:controller:check-endpoints-crd-reader
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:25Z"
    name: kube-apiserver-operator.179e33a26b26a213
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7053"
    uid: 966890dd-4b31-47d3-be16-d2ae12512ff1
  reason: ClusterRoleCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:26Z"
    name: kube-apiserver-operator.179e33a26bda25ed
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7090"
    uid: fc755fb1-1511-4ad1-9f2a-eb148a2b8eed
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:controller:kube-apiserver-check-endpoints-node-reader
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:26Z"
    name: kube-apiserver-operator.179e33a26c6880cf
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7118"
    uid: 0519d84d-3935-4ed5-8c28-3eb8ad461e5d
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:21Z"
  message: 'Failed to create revision 1: configmaps "kube-apiserver-pod" not found'
  metadata:
    creationTimestamp: "2023-12-06T09:21:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:22Z"
    name: kube-apiserver-operator.179e33a26ff2db77
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "6966"
    uid: 8bd15968-3a2f-41f3-a306-4355549f17be
  reason: RevisionCreateFailed
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:22Z"
  message: Created Secret/check-endpoints-client-cert-key -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:33Z"
    name: kube-apiserver-operator.179e33a275c87caa
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7466"
    uid: 99aae549-02b2-4f41-994b-bc4e47e90d15
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:22Z"
  message: Created Secret/external-loadbalancer-serving-certkey -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:34Z"
    name: kube-apiserver-operator.179e33a28197f7b6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7483"
    uid: 6e75c282-0e1a-4550-af86-f3b837bc5691
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:22Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:27Z"
    name: kube-apiserver-operator.179e33a281e17a06
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7155"
    uid: 3c8310e0-0fcb-489c-91d4-fb2535065dc6
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:22Z"
  message: Created Secret/aggregator-client -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:34Z"
    name: kube-apiserver-operator.179e33a28da044ef
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7493"
    uid: 82cca4d2-990f-411a-a171-1a92d78e501c
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:22Z"
  message: Created Secret/kubelet-client -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:35Z"
    name: kube-apiserver-operator.179e33a299faf92a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7520"
    uid: 6d808277-826d-4026-abd1-2af562c441df
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:22Z"
  message: Created Secret/service-network-serving-certkey -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:35Z"
    name: kube-apiserver-operator.179e33a2a55cdb79
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7543"
    uid: ec481d55-3d6d-4f6f-b3c5-790827b09111
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: Created Secret/localhost-serving-cert-certkey -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:35Z"
    name: kube-apiserver-operator.179e33a2b1454019
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7554"
    uid: ede5a89a-437b-42b8-ad79-d42e46cd6a69
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: Created ConfigMap/localhost-recovery-serving-ca -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:36Z"
    name: kube-apiserver-operator.179e33a2bd1f103f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7575"
    uid: c9653df8-1de2-457c-8e0e-6aeebb0af324
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: '"localhost-recovery-serving-certkey" in "openshift-kube-apiserver" requires
    a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:36Z"
    name: kube-apiserver-operator.179e33a2bd246eee
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7580"
    uid: d4912563-f015-4c6d-89c1-b7a64c594bfa
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: configmaps "kube-control-plane-signer-ca" already exists
  metadata:
    creationTimestamp: "2023-12-06T09:21:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:23Z"
    name: kube-apiserver-operator.179e33a2c3760cf2
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7011"
    uid: dff3ca27-6ad2-446c-bd67-adf4d6a60927
  reason: RotationError
  reportingComponent: kube-apiserver-operator-cert-rotation-controller-cert-rotation-controller-KubeControllerManagerClient-certrotationcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller-cert-rotation-controller-KubeControllerManagerClient-certrotationcontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: '"kube-controller-manager-client-cert-key" in "openshift-config-managed"
    requires a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:36Z"
    name: kube-apiserver-operator.179e33a2c3800f32
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7591"
    uid: 2ad76274-ac8d-4575-82f5-e24dd458f473
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: 'configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0'
  metadata:
    creationTimestamp: "2023-12-06T09:21:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:24Z"
    name: kube-apiserver-operator.179e33a2c3939c5b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7020"
    uid: 4268139c-6de9-4177-ac6d-3ff444892e01
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found" to
    "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists"'
  metadata:
    creationTimestamp: "2023-12-06T09:21:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:24Z"
    name: kube-apiserver-operator.179e33a2c42c2d18
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7025"
    uid: d1828d07-b0fc-4ac9-aa26-c9b81269b3c5
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: Created ConfigMap/aggregator-client-ca -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:24Z"
    name: kube-apiserver-operator.179e33a2d516c07e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7039"
    uid: 09df6671-c563-4884-b367-663bb770f3a9
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: Created ConfigMap/node-system-admin-ca -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:36Z"
    name: kube-apiserver-operator.179e33a2e119b2f0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7604"
    uid: a88f839f-7abc-4007-be92-99bde666d66d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:23Z"
  message: '"node-system-admin-client" in "openshift-kube-apiserver-operator" requires
    a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:36Z"
    name: kube-apiserver-operator.179e33a2e11b0b67
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7610"
    uid: aae13c11-66b9-4a64-a648-3cad37052e8c
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:24Z"
  message: Created ConfigMap/check-endpoints-kubeconfig -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:28Z"
    name: kube-apiserver-operator.179e33a2ecd6c8cf
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7183"
    uid: 88bd5df5-4bd0-4b41-bae7-8a9dab7b19f1
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:24Z"
  message: Created RoleBinding.rbac.authorization.k8s.io/system:openshift:controller:kube-apiserver-check-endpoints
    -n kube-system because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:29Z"
    name: kube-apiserver-operator.179e33a2ed31935f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7223"
    uid: e4fd9962-697e-4050-87d7-52d82d6b9fff
  reason: RoleBindingCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:24Z"
  message: Created RoleBinding.rbac.authorization.k8s.io/system:openshift:controller:check-endpoints
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:29Z"
    name: kube-apiserver-operator.179e33a2edba1094
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7239"
    uid: 1389efe8-41fd-41e6-85f0-77ba676ede2f
  reason: RoleBindingCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:24Z"
  message: Created ConfigMap/kube-apiserver-pod -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:29Z"
    name: kube-apiserver-operator.179e33a310b75536
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7226"
    uid: dc3129ef-95cf-41e7-8beb-b272e4aa359e
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:25Z"
  message: Created ConfigMap/bound-sa-token-signing-certs -n openshift-config-managed
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:25Z"
    name: kube-apiserver-operator.179e33a32880ca8f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7071"
    uid: 1d35689d-0e17-43e6-8203-417f43e79ed5
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:25Z"
  message: Created ConfigMap/control-plane-node-kubeconfig -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:30Z"
    name: kube-apiserver-operator.179e33a3349bff1f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7316"
    uid: c8a85deb-0e8f-4462-af86-280c6c3b7ed8
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:25Z"
  message: Created RoleBinding.rbac.authorization.k8s.io/authentication-reader-for-authenticated-users
    -n kube-system because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:30Z"
    name: kube-apiserver-operator.179e33a3354ce94a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7367"
    uid: 3f4d7953-63d4-4d19-b4a3-e4b9d9e6c7f6
  reason: RoleBindingCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:25Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:operator:kube-apiserver-recovery
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:31Z"
    name: kube-apiserver-operator.179e33a335a5a456
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7376"
    uid: fe0637e8-838c-4fad-b83c-7bd4952cf45b
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:25Z"
  message: Created Secret/localhost-recovery-serving-certkey -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:37Z"
    name: kube-apiserver-operator.179e33a34c4547b3
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7623"
    uid: 50a7f9bc-d136-400c-9b70-2a4714a56310
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:26Z"
  message: Created Secret/kube-controller-manager-client-cert-key -n openshift-config-managed
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:37Z"
    name: kube-apiserver-operator.179e33a3641d006c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7639"
    uid: 59be7286-c40e-49eb-9fd5-19d9ca735638
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:26Z"
  message: Created Secret/etcd-client -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:26Z"
    name: kube-apiserver-operator.179e33a370033207
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7122"
    uid: f8e7a076-07d1-4810-9076-b393f54f6472
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:26Z"
  message: Created Secret/node-system-admin-client -n openshift-kube-apiserver-operator
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:37Z"
    name: kube-apiserver-operator.179e33a387ecb91b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7650"
    uid: 6fe94cac-0281-4004-a47c-7926cb7a5cc3
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:26Z"
  message: Created ConfigMap/client-ca -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:29Z"
    name: kube-apiserver-operator.179e33a393fb35ce
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7263"
    uid: 0c936d97-d789-4b56-876e-acd32c31bee5
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:27Z"
  message: Created ServiceAccount/localhost-recovery-client -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:31Z"
    name: kube-apiserver-operator.179e33a39fec42f8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7382"
    uid: ad5199a0-eb7d-4088-9fa5-06a924e27b37
  reason: ServiceAccountCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:27Z"
  message: Created Secret/localhost-recovery-client-token -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:32Z"
    name: kube-apiserver-operator.179e33a3b77fc488
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7393"
    uid: ee33a511-3ce9-4d42-b275-d3982b40d4d1
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:27Z"
  message: Created StorageVersionMigration.migration.k8s.io/flowcontrol-flowschema-storage-version-migration
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:32Z"
    name: kube-apiserver-operator.179e33a3b87d8403
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7417"
    uid: adb66792-84dd-4aea-9c87-20b00b3d9364
  reason: StorageVersionMigrationCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:27Z"
  message: Created StorageVersionMigration.migration.k8s.io/flowcontrol-prioritylevel-storage-version-migration
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:32Z"
    name: kube-apiserver-operator.179e33a3b972d7da
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7443"
    uid: 84fbf197-2543-41ac-89ad-77f221517187
  reason: StorageVersionMigrationCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 7
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:28Z"
  message: Created PrometheusRule.monitoring.coreos.com/v1 because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:35Z"
    name: kube-apiserver-operator.179e33a3ba2332db
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7547"
    uid: f558fe8b-f3ed-4a96-a2da-1225a9f2b462
  reason: PrometheusRuleCreated
  reportingComponent: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-kubeapiserverstaticresources-kubeapiserverstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:27Z"
  message: Created ConfigMap/kube-apiserver-server-ca -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:30Z"
    name: kube-apiserver-operator.179e33a3c370f746
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7318"
    uid: ef82b3aa-f567-46fa-87ca-17fe52dcb7eb
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:27Z"
  message: 'secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0'
  metadata:
    creationTimestamp: "2023-12-06T09:21:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:28Z"
    name: kube-apiserver-operator.179e33a3c9ce08c4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7188"
    uid: 2c1741cc-08d2-4570-b311-e0285541e18e
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:27Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: aggregator-client,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists" to "NodeControllerDegraded:
    The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists"'
  metadata:
    creationTimestamp: "2023-12-06T09:21:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:28Z"
    name: kube-apiserver-operator.179e33a3ca807708
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7209"
    uid: c8361abb-d778-46ea-83b2-846d6daf4725
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:33Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:33Z"
  message: '"internal-loadbalancer-serving-certkey" in "openshift-kube-apiserver"
    requires a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:37Z"
    name: kube-apiserver-operator.179e33a52f2fd7d5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7658"
    uid: 8fc59289-e064-4170-a046-a1758223099a
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:33Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:33Z"
  message: Created Secret/internal-loadbalancer-serving-certkey -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:37Z"
    name: kube-apiserver-operator.179e33a537373591
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7659"
    uid: 053f0271-971a-4a31-9fe6-68c2d00c1c18
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:34Z"
  message: '"kube-scheduler-client-cert-key" in "openshift-config-managed" requires
    a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:38Z"
    name: kube-apiserver-operator.179e33a56ada27aa
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7662"
    uid: 6e547bb3-5bc6-4794-8aa6-2d4357020e52
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:34Z"
  message: Created Secret/kube-scheduler-client-cert-key -n openshift-config-managed
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:38Z"
    name: kube-apiserver-operator.179e33a5717a3e92
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7668"
    uid: 1035d1cd-e5ee-4039-9c43-613fd7293723
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:35Z"
  message: '"control-plane-node-admin-client-cert-key" in "openshift-kube-apiserver"
    requires a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2023-12-06T09:21:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:38Z"
    name: kube-apiserver-operator.179e33a582a9af77
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7681"
    uid: fa6e76a0-1b52-40ad-b8f9-d8b0387d7a20
  reason: TargetUpdateRequired
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:35Z"
  message: Created Secret/control-plane-node-admin-client-cert-key -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:38Z"
    name: kube-apiserver-operator.179e33a59442df23
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "7689"
    uid: 259e5c16-31dd-46ac-8c75-d3e96cdf5b80
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-cert-rotation-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-cert-rotation-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:49Z"
  message: Created ConfigMap/kube-apiserver-client-ca -n openshift-config-managed
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:49Z"
    name: kube-apiserver-operator.179e33a8c55b9e0f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "8280"
    uid: 91dd2ec9-fb48-428f-b16b-6d7270ed86f2
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:49Z"
  message: Created ConfigMap/kube-apiserver-server-ca -n openshift-config-managed
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:49Z"
    name: kube-apiserver-operator.179e33a8c5c42a68
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "8281"
    uid: d77c3295-cc9c-4069-bd19-fa373df3d9c5
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:50Z"
  message: Created Secret/node-kubeconfigs -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:21:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:50Z"
    name: kube-apiserver-operator.179e33a901525368
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "8345"
    uid: 815bd862-dbc8-451a-a95e-84a0f666bdcc
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-node-kubeconfig-controller-nodekubeconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-node-kubeconfig-controller-nodekubeconfigcontroller
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:34Z"
  message: 'configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0'
  metadata:
    creationTimestamp: "2023-12-06T09:21:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:34Z"
    name: kube-apiserver-operator.179e33a9305d2f6d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "10906"
    uid: 69e7d575-5eb1-4aef-a89f-697d0651bb03
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:55Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:55Z"
  message: |-
    Updated ConfigMap/client-ca -n openshift-kube-apiserver:
    cause by changes in data.ca-bundle.crt
  metadata:
    creationTimestamp: "2023-12-06T09:21:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:55Z"
    name: kube-apiserver-operator.179e33aa2bb27916
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "8627"
    uid: 2b4ffe49-60ca-4be7-8202-6ceba77923f8
  reason: ConfigMapUpdated
  reportingComponent: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:21:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:21:56Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists" to "NodeControllerDegraded:
    The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:21:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:21:56Z"
    name: kube-apiserver-operator.179e33aa7ef83515
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "8712"
    uid: ac89432b-f555-44f9-85e8-ce3d77268f3d
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:01Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"
    to "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:22:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:01Z"
    name: kube-apiserver-operator.179e33abb4ff4783
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9082"
    uid: 7f7ceefe-f1b4-4a1b-8145-5fbc7f5ab646
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:07Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"
    to "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:22:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:07Z"
    name: kube-apiserver-operator.179e33acf6ceeaba
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9287"
    uid: a711cb1a-d044-4be3-a7ff-0075c896e715
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:10Z"
  message: CloudProvider config file changed to /etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf
  metadata:
    creationTimestamp: "2023-12-06T09:22:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:10Z"
    name: kube-apiserver-operator.179e33adc09fa2e7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9427"
    uid: ae526df1-9816-40bf-8b5e-eec582fa2387
  reason: ObserveCloudProviderNamesChanges
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:10Z"
  message: "Writing updated observed config:   map[string]any{\n  \t\"admission\":
    map[string]any{\"pluginConfig\": map[string]any{\"PodSecurity\": map[string]any{\"configuration\":
    map[string]any{\"defaults\": map[string]any{\"audit\": string(\"restricted\"),
    \"audit-version\": string(\"latest\"), \"enforce\": string(\"restricted\"), \"enforce-version\":
    string(\"latest\"), ...}}}, \"network.openshift.io/ExternalIPRanger\": map[string]any{\"configuration\":
    map[string]any{\"allowIngressIP\": bool(false), \"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"ExternalIPRangerAdmissionConfig\")}}, \"network.openshift.io/RestrictedEndpointsAdmission\":
    map[string]any{\"configuration\": map[string]any{\"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"RestrictedEndpointsAdmissionConfig\"), \"restrictedCIDRs\":
    []any{string(\"10.128.0.0/14\"), string(\"172.30.0.0/16\")}}}}},\n  \t\"apiServerArguments\":
    map[string]any{\n  \t\t\"api-audiences\": []any{string(\"https://kubernetes.default.svc\")},\n-
    \t\t\"cloud-config\":  []any{string(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/config\")},\n+
    \t\t\"cloud-config\": []any{\n+ \t\t\tstring(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf\"),\n+
    \t\t},\n  \t\t\"cloud-provider\": []any{string(\"external\")},\n  \t\t\"etcd-servers\":
    \  []any{string(\"https://localhost:2379\")},\n  \t\t... // 5 identical entries\n
    \ \t},\n  \t\"corsAllowedOrigins\":          []any{string(`//127\\.0\\.0\\.1(:|$)`),
    string(\"//localhost(:|$)\")},\n  \t\"gracefulTerminationDuration\": string(\"194\"),\n
    \ \t... // 2 identical entries\n  }\n"
  metadata:
    creationTimestamp: "2023-12-06T09:22:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:10Z"
    name: kube-apiserver-operator.179e33adc0ae0bbe
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9430"
    uid: dde3867e-d0bf-412a-836d-b2ad1a1a3fc3
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:10Z"
  message: |-
    Updated ConfigMap/cloud-config -n openshift-kube-apiserver:
    cause by changes in data.cloud.conf,data.config
  metadata:
    creationTimestamp: "2023-12-06T09:22:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:10Z"
    name: kube-apiserver-operator.179e33adc0cc5479
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9429"
    uid: 8f9df11d-37ee-4ec0-8720-94f4bb7ad179
  reason: ConfigMapUpdated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:10Z"
  message: Created ConfigMap/kubelet-serving-ca -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:10Z"
    name: kube-apiserver-operator.179e33adc102fcf7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9432"
    uid: 559e14d1-0cb4-48c5-a826-266ce8ae320f
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:10Z"
  message: |-
    Updated ConfigMap/kube-apiserver-client-ca -n openshift-config-managed:
    cause by changes in data.ca-bundle.crt
  metadata:
    creationTimestamp: "2023-12-06T09:22:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:10Z"
    name: kube-apiserver-operator.179e33adc134fcbc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9434"
    uid: 5673d300-b53a-41ad-b023-45250b26c767
  reason: ConfigMapUpdated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:10Z"
  message: Created ConfigMap/kubelet-serving-ca -n openshift-config-managed because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:10Z"
    name: kube-apiserver-operator.179e33adc1927889
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "9435"
    uid: eca9ae49-dd94-4a67-8bb1-9627ed6b57b1
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:32Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:32Z"
  message: 'Failed to write observed config: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io
    "cluster": the object has been modified; please apply your changes to the latest
    version and try again'
  metadata:
    creationTimestamp: "2023-12-06T09:22:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:32Z"
    name: kube-apiserver-operator.179e33b2c821ea5b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "10821"
    uid: 127e189e-2f32-4d89-8f2e-4cc8b24a7c8e
  reason: ObservedConfigWriteError
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:37Z"
  message: FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform",
    "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProvider",
    "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "ExternalCloudProviderGCP",
    "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy",
    "AutomatedEtcdBackup", "CSIDriverSharedResource", "ClusterAPIInstall", "DNSNameResolver",
    "DisableKubeletCloudCredentialProviders", "DynamicResourceAllocation", "EventedPLEG",
    "GCPClusterHostedDNS", "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "InstallAlternateInfrastructureAWS",
    "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack",
    "MachineConfigNodes", "ManagedBootImages", "MaxUnavailableStatefulSet", "MetricsServer",
    "MixedCPUsAllocation", "NetworkLiveMigration", "NodeSwap", "RouteExternalCertificate",
    "SigstoreImageVerification", "VSphereControlPlaneMachineSet", "VSphereStaticIPs",
    "ValidatingAdmissionPolicy"}}
  metadata:
    creationTimestamp: "2023-12-06T09:22:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:37Z"
    name: kube-apiserver-operator.179e33b421caa6ae
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11054"
    uid: 8629d8c4-4b3e-49e5-9157-e4e9973fe3fa
  reason: FeatureGatesInitialized
  reportingComponent: kube-apiserver-operator
  reportingInstance: ""
  source:
    component: kube-apiserver-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:38Z"
  message: Controller "auditPolicyController" resync interval is set to 10s which
    might lead to client request throttling
  metadata:
    creationTimestamp: "2023-12-06T09:22:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:38Z"
    name: kube-apiserver-operator.179e33b4296978f6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11058"
    uid: 5da44c17-d415-464c-aed3-5ac8a3d17c98
  reason: FastControllerResync
  reportingComponent: kube-apiserver-operator-audit-policy-controller-auditpolicycontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-audit-policy-controller-auditpolicycontroller
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:15Z"
  message: new revision 2 triggered by "configmap \"kube-apiserver-pod-1\" not found"
  metadata:
    creationTimestamp: "2023-12-06T09:22:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:15Z"
    name: kube-apiserver-operator.179e33b42c197609
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12102"
    uid: a956c4d3-f3e4-4244-a96f-07e7dff70262
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 20
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:17Z"
  message: 'configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1'
  metadata:
    creationTimestamp: "2023-12-06T09:22:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:17Z"
    name: kube-apiserver-operator.179e33b447431161
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12150"
    uid: 820c938c-db2a-4ad1-9e5a-d0827b17fa85
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:38Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-106-212.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:18:38 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?), node \"ip-10-0-94-160.us-west-1.compute.internal\"
    not ready since 2023-12-06 09:19:02 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nInstallerControllerDegraded: missing required
    resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"
    to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:22:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:38Z"
    name: kube-apiserver-operator.179e33b45e7162f7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11112"
    uid: bb6077a4-71fa-4ba1-a904-0026919b6942
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:39Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"
    to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:22:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:39Z"
    name: kube-apiserver-operator.179e33b469a3b84b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11127"
    uid: df6540b9-f14a-4fb2-90f8-13fd92c42eff
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:39Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"
    to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:22:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:39Z"
    name: kube-apiserver-operator.179e33b4844c8ddd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11168"
    uid: 2ef8689a-a3d9-4678-a0e0-af978675ca31
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:40Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"
    to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:22:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:40Z"
    name: kube-apiserver-operator.179e33b4a8153756
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11175"
    uid: 45d668a7-0ddc-4b4e-94af-f93c7902f0ef
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:41Z"
  message: Created ConfigMap/revision-status-2 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:41Z"
    name: kube-apiserver-operator.179e33b4ede02ca3
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11199"
    uid: b8017988-b4b1-448f-b554-387a1882e216
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:42Z"
  message: Created ConfigMap/kube-apiserver-pod-2 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:42Z"
    name: kube-apiserver-operator.179e33b54164dd75
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11256"
    uid: 66ba0948-c79f-4308-9229-da1bb759119c
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:43Z"
  message: Created ConfigMap/config-2 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:43Z"
    name: kube-apiserver-operator.179e33b57113286c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11273"
    uid: 6468252f-9d20-435f-898e-a99e385b498f
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:44Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-2 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:44Z"
    name: kube-apiserver-operator.179e33b5a097fedd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11298"
    uid: 66f2dfb3-3117-4710-82dc-c131545c4936
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:44Z"
  message: Created ConfigMap/cloud-config-2 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:44Z"
    name: kube-apiserver-operator.179e33b5c484eda5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11307"
    uid: 3d830baf-9128-467b-8e57-233997b4c4bc
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:45Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-2 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:45Z"
    name: kube-apiserver-operator.179e33b5e833d369
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11319"
    uid: 16af0728-765a-49a4-bada-298c76383e0a
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:46Z"
  message: Created ConfigMap/etcd-serving-ca-2 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:46Z"
    name: kube-apiserver-operator.179e33b60bf0ae3b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11333"
    uid: cb589c8f-df3d-473a-9110-898cd0dd99c9
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:46Z"
  message: Created ConfigMap/kube-apiserver-server-ca-2 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:46Z"
    name: kube-apiserver-operator.179e33b62fbe4025
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11338"
    uid: 61be3538-ec6b-441c-8573-76819d4b812d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:47Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:47Z"
  message: Created ConfigMap/kubelet-serving-ca-2 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:47Z"
    name: kube-apiserver-operator.179e33b65370e292
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11348"
    uid: 8176e7f9-b205-4270-94e6-2ec07168e90d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:48Z"
  message: Created ConfigMap/sa-token-signing-certs-2 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:48Z"
    name: kube-apiserver-operator.179e33b6833175da
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11355"
    uid: c7eb5daa-559b-4277-adef-ace684a6f7d5
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:48Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-2 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:48Z"
    name: kube-apiserver-operator.179e33b6b2da9082
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11370"
    uid: f2a2791c-3431-41df-b50a-048c9d0d7afc
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:49Z"
  message: Created Secret/etcd-client-2 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:49Z"
    name: kube-apiserver-operator.179e33b6e294da18
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11395"
    uid: 8d72d1f6-f15f-43d6-8a2d-434427b76391
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:50Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig,
    secrets: control-plane-node-admin-client-cert-key,internal-loadbalancer-serving-certkey,node-kubeconfigs,
    configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0,
    secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"
    to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]",Progressing
    changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision
    0; 0 nodes have achieved new revision 1"),Available message changed from "StaticPodsAvailable:
    0 nodes are active; 3 nodes are at revision 0" to "StaticPodsAvailable: 0 nodes
    are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1"'
  metadata:
    creationTimestamp: "2023-12-06T09:22:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:50Z"
    name: kube-apiserver-operator.179e33b71446e819
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11440"
    uid: 2abe5448-0f55-47ed-8a49-ccb3233c0071
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:51Z"
  message: Created Secret/localhost-recovery-serving-certkey-2 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:51Z"
    name: kube-apiserver-operator.179e33b735f9ef8b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11467"
    uid: 0b90d1de-da9c-45ed-991f-8a91251ec948
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:22:51Z"
  message: Created Secret/localhost-recovery-client-token-2 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:22:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:22:51Z"
    name: kube-apiserver-operator.179e33b765bd954a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11491"
    uid: ec6cabe1-d787-4685-a5d3-c600338723a7
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:08Z"
  message: authentication-token webhook configuration status changed from false to
    true
  metadata:
    creationTimestamp: "2023-12-06T09:22:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:09Z"
    name: kube-apiserver-operator.179e33b93860576a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11928"
    uid: 9ff702fa-aade-4e84-9bab-c1f7a5917d74
  reason: ObserveWebhookTokenAuthenticator
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 10
  eventTime: null
  firstTimestamp: "2023-12-06T09:22:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:13Z"
  message: 'configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found'
  metadata:
    creationTimestamp: "2023-12-06T09:22:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:13Z"
    name: kube-apiserver-operator.179e33b93861f145
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12003"
    uid: 342a5df7-1abf-4a9b-9b8a-0e30740a4759
  reason: ObserveStorageFailed
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:00Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"
    to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:00Z"
    name: kube-apiserver-operator.179e33b94458176c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11705"
    uid: c5c1061e-f2be-423d-ab05-979104c3e794
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:00Z"
  message: Created Secret/webhook-authenticator -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:00Z"
    name: kube-apiserver-operator.179e33b94e685ae5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11710"
    uid: b4062f44-3cd7-4fe8-9691-f2c7da59e262
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:08Z"
  message: CloudProvider config file changed to /etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf
  metadata:
    creationTimestamp: "2023-12-06T09:23:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:08Z"
    name: kube-apiserver-operator.179e33b94ec1b054
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11925"
    uid: 7b933cca-8c3d-4197-a361-0fd4d2891392
  reason: ObserveCloudProviderNamesChanges
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:08Z"
  message: "Writing updated observed config: map[string]any{\n\t\"admission\":
    map[string]any{\"pluginConfig\": map[string]any{\"PodSecurity\": map[string]any{\"configuration\":
    map[string]any{\"defaults\": map[string]any{\"audit\": string(\"restricted\"),
    \"audit-version\": string(\"latest\"), \"enforce\": string(\"restricted\"), \"enforce-version\":
    string(\"latest\"), ...}}}, \"network.openshift.io/ExternalIPRanger\": map[string]any{\"configuration\":
    map[string]any{\"allowIngressIP\": bool(false), \"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"ExternalIPRangerAdmissionConfig\")}}, \"network.openshift.io/RestrictedEndpointsAdmission\":
    map[string]any{\"configuration\": map[string]any{\"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"RestrictedEndpointsAdmissionConfig\"), \"restrictedCIDRs\":
    []any{string(\"10.128.0.0/14\"), string(\"172.30.0.0/16\")}}}}},\n\t\"apiServerArguments\":
    map[string]any{\n\t\t\"api-audiences\": []any{string(\"https://kubernetes.default.svc\")},\n+\t\t\"authentication-token-webhook-config-file\":
    []any{\n+\t\t\tstring(\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"),\n+\t\t},\n+\t\t\"authentication-token-webhook-version\":
    []any{string(\"v1\")},\n-\t\t\"cloud-config\":                         []any{string(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/config\")},\n+\t\t\"cloud-config\":
    []any{\n+\t\t\tstring(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf\"),\n+\t\t},\n\t\t\"cloud-provider\":
    []any{string(\"external\")},\n\t\t\"etcd-servers\":   []any{string(\"https://localhost:2379\")},\n\t\t...
    // 5 identical entries\n\t},\n\t\"corsAllowedOrigins\":          []any{string(`//127\\.0\\.0\\.1(:|$)`),
    string(\"//localhost(:|$)\")},\n\t\"gracefulTerminationDuration\": string(\"194\"),\n\t...
    // 2 identical entries\n}\n"
  metadata:
    creationTimestamp: "2023-12-06T09:23:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:09Z"
    name: kube-apiserver-operator.179e33b94ef138e0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11929"
    uid: 0cc094ad-4ba4-498e-9a15-f6983918b398
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:02Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"
    to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nConfigObservationDegraded:
    configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nCertRotation_KubeControllerManagerClient_Degraded:
    configmaps \"kube-control-plane-signer-ca\" already exists\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:02Z"
    name: kube-apiserver-operator.179e33b9ebd4f7f8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11776"
    uid: 07de4c87-c7f0-4270-89d8-09a078a32c30
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 6
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:38Z"
  message: |-
    Updated ConfigMap/config -n openshift-kube-apiserver:
    cause by changes in data.config.yaml
  metadata:
    creationTimestamp: "2023-12-06T09:23:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:38Z"
    name: kube-apiserver-operator.179e33bb72c68c33
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31236"
    uid: a5f2c478-ea33-42ef-b3c7-e4488c7730df
  reason: ConfigMapUpdated
  reportingComponent: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-target-config-controller-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:09Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded changed from
    False to True ("CertRotation_KubeControllerManagerClient_Degraded: configmaps
    \"kube-control-plane-signer-ca\" already exists\nConfigObservationDegraded: configmaps
    openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found")'
  metadata:
    creationTimestamp: "2023-12-06T09:23:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:09Z"
    name: kube-apiserver-operator.179e33bb9089cbd7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "11941"
    uid: 04975f53-4eb8-45f5-9f41-fe2fb3723513
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:13Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:28Z"
  message: Updated storage urls to https://10.0.106.212:2379,https://localhost:2379
  metadata:
    creationTimestamp: "2023-12-06T09:23:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:28Z"
    name: kube-apiserver-operator.179e33bc7746b5fc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12766"
    uid: 5c08d681-2595-4e44-8a9a-450036739551
  reason: ObserveStorageUpdated
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:13Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:28Z"
  message: "Writing updated observed config: map[string]any{\n\t\"admission\":
    map[string]any{\"pluginConfig\": map[string]any{\"PodSecurity\": map[string]any{\"configuration\":
    map[string]any{\"defaults\": map[string]any{\"audit\": string(\"restricted\"),
    \"audit-version\": string(\"latest\"), \"enforce\": string(\"restricted\"), \"enforce-version\":
    string(\"latest\"), ...}}}, \"network.openshift.io/ExternalIPRanger\": map[string]any{\"configuration\":
    map[string]any{\"allowIngressIP\": bool(false), \"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"ExternalIPRangerAdmissionConfig\")}}, \"network.openshift.io/RestrictedEndpointsAdmission\":
    map[string]any{\"configuration\": map[string]any{\"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"RestrictedEndpointsAdmissionConfig\"), \"restrictedCIDRs\":
    []any{string(\"10.128.0.0/14\"), string(\"172.30.0.0/16\")}}}}},\n\t\"apiServerArguments\":
    map[string]any{\n\t\t... // 3 identical entries\n\t\t\"cloud-config\":   []any{string(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo\"...)},\n\t\t\"cloud-provider\":
    []any{string(\"external\")},\n\t\t\"etcd-servers\": []any{\n+\t\t\tstring(\"https://10.0.106.212:2379\"),\n\t\t\tstring(\"https://localhost:2379\"),\n\t\t},\n\t\t\"feature-gates\":
    \                        []any{string(\"AdminNetworkPolicy=false\"), string(\"AlibabaPlatform=true\"),
    string(\"AutomatedEtcdBackup=false\"), string(\"AzureWorkloadIdentity=true\"),
    ...},\n\t\t\"send-retry-after-while-not-ready-once\": []any{string(\"false\")},\n\t\t...
    // 3 identical entries\n\t},\n\t\"corsAllowedOrigins\":          []any{string(`//127\\.0\\.0\\.1(:|$)`),
    string(\"//localhost(:|$)\")},\n\t\"gracefulTerminationDuration\": string(\"194\"),\n\t...
    // 2 identical entries\n}\n"
  metadata:
    creationTimestamp: "2023-12-06T09:23:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:28Z"
    name: kube-apiserver-operator.179e33bc77542125
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12774"
    uid: c4e084d7-2d48-487b-8065-42840667bf95
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:15Z"
  message: |-
    Updated ConfigMap/config-2 -n openshift-kube-apiserver:
    cause by changes in data.config.yaml
  metadata:
    creationTimestamp: "2023-12-06T09:23:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:15Z"
    name: kube-apiserver-operator.179e33bcfc421da4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12113"
    uid: e446264b-9e2c-4bae-aa82-65cfab752212
  reason: ConfigMapUpdated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:17Z"
  message: Created Secret/webhook-authenticator-2 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:17Z"
    name: kube-apiserver-operator.179e33bd4ffb977e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12156"
    uid: 36ee0ed4-8296-4975-b58a-aeca39f67a13
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:19Z"
  message: Revision 2 created because configmap "kube-apiserver-pod-1" not found
  metadata:
    creationTimestamp: "2023-12-06T09:23:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:19Z"
    name: kube-apiserver-operator.179e33bdd48e3abf
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12281"
    uid: 55a448d2-9c07-48a3-8424-c041f39a0655
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:22Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "CertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\"
    already exists\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints:
    no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on
    node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal,
    Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found" to
    "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd
    endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal]\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:22Z"
    name: kube-apiserver-operator.179e33be645b1210
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12349"
    uid: a0c98fae-2abd-4215-896b-8c1cee2e9388
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:22Z"
  message: 'Failed to write observed config: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io
    "cluster": the object has been modified; please apply your changes to the latest
    version and try again'
  metadata:
    creationTimestamp: "2023-12-06T09:23:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:22Z"
    name: kube-apiserver-operator.179e33be86c4ca04
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12380"
    uid: 2922f58e-cc40-4a16-9f48-4e6179ad4590
  reason: ObservedConfigWriteError
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:23Z"
  message: Updating node "ip-10-0-106-212.us-west-1.compute.internal" from revision
    0 to 2 because node ip-10-0-106-212.us-west-1.compute.internal static pod not
    found
  metadata:
    creationTimestamp: "2023-12-06T09:23:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:23Z"
    name: kube-apiserver-operator.179e33bed7e33d7e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12403"
    uid: ad8f47b2-890d-4e0a-8d19-f3b817a4dd9c
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:24Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have
    achieved new revision 1" to "NodeInstallerProgressing: 3 nodes are at revision
    0; 0 nodes have achieved new revision 2",Available message changed from "StaticPodsAvailable:
    0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision
    1" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes
    have achieved new revision 2"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:24Z"
    name: kube-apiserver-operator.179e33bedc75ec55
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12408"
    uid: 68a0813e-d274-4400-8668-dc468c3cce96
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:28Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:28Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no
    etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node
    ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal,
    Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found" to
    "ConfigObservationDegraded: error writing updated observed config: Operation cannot
    be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has
    been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:28Z"
    name: kube-apiserver-operator.179e33bfcb0dc384
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "12769"
    uid: 8adf4593-b1a3-484d-9e4d-c7d63358a28b
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:31Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:31Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]\nInstallerControllerDegraded:
    missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1,
    secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found" to
    "ConfigObservationDegraded: error writing updated observed config: Operation cannot
    be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has
    been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:31Z"
    name: kube-apiserver-operator.179e33c0a2ffc6e9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "13593"
    uid: efdebdb7-291d-4baa-9130-0aaeec457366
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:33Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:55Z"
  message: new revision 3 triggered by "required configmap/config has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:23:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:55Z"
    name: kube-apiserver-operator.179e33c109c132d1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15547"
    uid: 69d769c1-59fc-496a-a546-7e2567b0f0f8
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:34Z"
  message: Created ConfigMap/revision-status-3 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:34Z"
    name: kube-apiserver-operator.179e33c1392e4bfe
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14134"
    uid: be9a665a-5906-4e76-8c21-b48d323ad1a0
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:35Z"
  message: Created ConfigMap/kube-apiserver-pod-3 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:35Z"
    name: kube-apiserver-operator.179e33c1812098c2
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14250"
    uid: bb63d238-2809-4d5a-b2ea-c11d2253fdd1
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:36Z"
  message: Created Pod/installer-2-ip-10-0-106-212.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:36Z"
    name: kube-apiserver-operator.179e33c1b07956cc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14326"
    uid: 3c1fbf62-88ab-4421-9dde-98fcb0926d3b
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:36Z"
  message: Created ConfigMap/config-3 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:36Z"
    name: kube-apiserver-operator.179e33c1d42599a9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14392"
    uid: 8b0bf554-b549-4308-9d86-694b7f8a87fa
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:37Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]\nNodeKubeconfigControllerDegraded:
    \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found" to
    "ConfigObservationDegraded: error writing updated observed config: Operation cannot
    be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has
    been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:37Z"
    name: kube-apiserver-operator.179e33c1f9b720f5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14447"
    uid: 9b17333b-69d0-4bfc-8331-9a0cfc6c70e7
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:38Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-3 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:38Z"
    name: kube-apiserver-operator.179e33c23389e69c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14542"
    uid: d3774cd5-fdf7-4555-9288-a610d82b8fcb
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:38Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"
    to "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:38Z"
    name: kube-apiserver-operator.179e33c235853dae
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14547"
    uid: 82634c8f-2973-4872-9d00-5106894b56d2
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:40Z"
  message: Created ConfigMap/cloud-config-3 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:40Z"
    name: kube-apiserver-operator.179e33c29ea2d97a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14702"
    uid: 57fea93a-a0be-4f46-a180-e5b8f0fd1a58
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:40Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"
    to "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:40Z"
    name: kube-apiserver-operator.179e33c2c48ad254
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14748"
    uid: 47197527-0c37-43ac-939a-a08abb19cfcd
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:41Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"
    to "ConfigObservationDegraded: error writing updated observed config: Operation
    cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object
    has been modified; please apply your changes to the latest version and try again\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:41Z"
    name: kube-apiserver-operator.179e33c2dc56d4c7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14776"
    uid: 60a44bbd-9b05-419d-b3cb-ebcdc8e5d7d6
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:41Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded changed from
    True to False ("NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]")'
  metadata:
    creationTimestamp: "2023-12-06T09:23:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:41Z"
    name: kube-apiserver-operator.179e33c2f7ea07db
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14810"
    uid: 37967072-34c3-4a0d-a1d8-79b53d0782d0
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:41Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-3 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:41Z"
    name: kube-apiserver-operator.179e33c309f49330
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14830"
    uid: d9a7773f-3847-44f9-9049-4da0e2c71582
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:43Z"
  message: Created ConfigMap/etcd-serving-ca-3 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:43Z"
    name: kube-apiserver-operator.179e33c3694371fd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "14936"
    uid: 989db191-a9f9-4c65-bab6-70c819d276e7
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:45Z"
  message: Created ConfigMap/kube-apiserver-server-ca-3 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:45Z"
    name: kube-apiserver-operator.179e33c3c924c76e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15089"
    uid: fde78818-2cc9-487b-9a59-fcf14617dfd9
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:46Z"
  message: Created ConfigMap/kubelet-serving-ca-3 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:46Z"
    name: kube-apiserver-operator.179e33c42827e0a8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15205"
    uid: 33ce2ded-7efe-4e23-9c05-650af7dfa649
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:48Z"
  message: Created ConfigMap/sa-token-signing-certs-3 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:48Z"
    name: kube-apiserver-operator.179e33c47ba07a74
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15316"
    uid: a543bea4-5f0b-4901-b692-d8ed34e5fb92
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:49Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-3 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:49Z"
    name: kube-apiserver-operator.179e33c4cf151088
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15355"
    uid: 1e2a56a8-b3c7-4ab1-8dd1-9deabd733a91
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:50Z"
  message: Created Secret/etcd-client-3 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:50Z"
    name: kube-apiserver-operator.179e33c516ae2786
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15389"
    uid: a82df11a-f2a8-4b5f-b376-3ddf8b62193f
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:51Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded changed from
    False to True ("GuardControllerDegraded: [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]")'
  metadata:
    creationTimestamp: "2023-12-06T09:23:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:51Z"
    name: kube-apiserver-operator.179e33c529361317
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15406"
    uid: 4dd9a547-2722-420b-bb14-762104cd933d
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:52Z"
  message: Created Secret/localhost-recovery-serving-certkey-3 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:52Z"
    name: kube-apiserver-operator.179e33c599b103df
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15463"
    uid: fb3807f6-859a-40f2-8b2e-7357f97ba26f
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 5
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:23Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-106-212.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:23Z"
    name: kube-apiserver-operator.179e33c5a4f7fdbc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15996"
    uid: 89d755ed-51d6-445b-a34c-560a6f915c21
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:53Z"
  message: Created Secret/localhost-recovery-client-token-3 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:53Z"
    name: kube-apiserver-operator.179e33c5bd946e69
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15490"
    uid: 9c5f48d5-6ff0-4168-9fb4-e77f2619147d
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 4
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:25Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:25Z"
    name: kube-apiserver-operator.179e33c5f26f209f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16025"
    uid: b9ea5a58-39da-4040-9549-1a84023970b9
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:55Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:07Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:07Z"
    name: kube-apiserver-operator.179e33c619c645c9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15754"
    uid: 73f837aa-1276-4802-b4b2-ed95e62085c3
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:55Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:55Z"
  message: Created Secret/webhook-authenticator-3 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:23:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:55Z"
    name: kube-apiserver-operator.179e33c61cc1a7ac
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15544"
    uid: 07e145b7-44d3-4aa7-8dff-9c74807ba0a4
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:55Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:55Z"
  message: Revision 3 created because required configmap/config has changed
  metadata:
    creationTimestamp: "2023-12-06T09:23:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:55Z"
    name: kube-apiserver-operator.179e33c61d76b268
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15546"
    uid: 8ba7e15f-a494-44ac-99b0-63f0e467121a
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 4
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:55Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:15Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal,
    Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:15Z"
    name: kube-apiserver-operator.179e33c62d3d06d7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15888"
    uid: c2d2cc5c-5302-49a4-bf90-685d5b997fbc
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:56Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 3"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:56Z"
    name: kube-apiserver-operator.179e33c685a07fd0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15575"
    uid: debae29d-b1d1-4547-afe8-f3884b7ac6be
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:23:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:23:57Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 3" to "GuardControllerDegraded: [Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:23:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:23:57Z"
    name: kube-apiserver-operator.179e33c68a0912ee
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15578"
    uid: c3a13297-39c4-4989-9213-4dd27def5693
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:00Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have
    achieved new revision 2" to "NodeInstallerProgressing: 3 nodes are at revision
    0; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable:
    0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision
    2" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes
    have achieved new revision 3"'
  metadata:
    creationTimestamp: "2023-12-06T09:24:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:00Z"
    name: kube-apiserver-operator.179e33c73cd3455e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15645"
    uid: 006483c6-4597-4c2e-bf52-1ac585eb0ce5
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:15Z"
  message: Created Pod/installer-3-ip-10-0-106-212.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:15Z"
    name: kube-apiserver-operator.179e33cadd201876
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15880"
    uid: 846170a8-85e5-4d08-a542-0967513fcc31
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:15Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:24:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:15Z"
    name: kube-apiserver-operator.179e33cadf145c18
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "15885"
    uid: d91f951f-47c5-4fb1-ae6b-75f666cc8596
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:49Z"
  message: Updated storage urls to https://10.0.106.212:2379,https://10.0.21.63:2379,https://localhost:2379
  metadata:
    creationTimestamp: "2023-12-06T09:24:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:49Z"
    name: kube-apiserver-operator.179e33d2b2a4676b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16279"
    uid: 9cb9ed6f-3f4d-4c86-880d-bfc383e0ca52
  reason: ObserveStorageUpdated
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:49Z"
  message: "Writing updated observed config: map[string]any{\n\t\"admission\":
    map[string]any{\"pluginConfig\": map[string]any{\"PodSecurity\": map[string]any{\"configuration\":
    map[string]any{\"defaults\": map[string]any{\"audit\": string(\"restricted\"),
    \"audit-version\": string(\"latest\"), \"enforce\": string(\"restricted\"), \"enforce-version\":
    string(\"latest\"), ...}}}, \"network.openshift.io/ExternalIPRanger\": map[string]any{\"configuration\":
    map[string]any{\"allowIngressIP\": bool(false), \"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"ExternalIPRangerAdmissionConfig\")}}, \"network.openshift.io/RestrictedEndpointsAdmission\":
    map[string]any{\"configuration\": map[string]any{\"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"RestrictedEndpointsAdmissionConfig\"), \"restrictedCIDRs\":
    []any{string(\"10.128.0.0/14\"), string(\"172.30.0.0/16\")}}}}},\n\t\"apiServerArguments\":
    map[string]any{\n\t\t... // 3 identical entries\n\t\t\"cloud-config\":   []any{string(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo\"...)},\n\t\t\"cloud-provider\":
    []any{string(\"external\")},\n\t\t\"etcd-servers\": []any{\n\t\t\tstring(\"https://10.0.106.212:2379\"),\n+\t\t\tstring(\"https://10.0.21.63:2379\"),\n\t\t\tstring(\"https://localhost:2379\"),\n\t\t},\n\t\t\"feature-gates\":
    \                        []any{string(\"AdminNetworkPolicy=false\"), string(\"AlibabaPlatform=true\"),
    string(\"AutomatedEtcdBackup=false\"), string(\"AzureWorkloadIdentity=true\"),
    ...},\n\t\t\"send-retry-after-while-not-ready-once\": []any{string(\"false\")},\n\t\t...
    // 3 identical entries\n\t},\n\t\"corsAllowedOrigins\":          []any{string(`//127\\.0\\.0\\.1(:|$)`),
    string(\"//localhost(:|$)\")},\n\t\"gracefulTerminationDuration\": string(\"194\"),\n\t...
    // 2 identical entries\n}\n"
  metadata:
    creationTimestamp: "2023-12-06T09:24:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:49Z"
    name: kube-apiserver-operator.179e33d2b2ba8dac
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16283"
    uid: 3b9aef03-673a-481d-8cb3-136b98281fe3
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:16Z"
  message: new revision 4 triggered by "required configmap/config has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:24:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:16Z"
    name: kube-apiserver-operator.179e33d2c043886b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "17092"
    uid: e6ff5d64-cc8c-4829-83e7-e5d3e24394ee
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:50Z"
  message: Created ConfigMap/revision-status-4 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:50Z"
    name: kube-apiserver-operator.179e33d3077e44a2
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16314"
    uid: 8859501a-43f9-4d48-8b31-c89a4b5f63ea
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:51Z"
  message: Created ConfigMap/kube-apiserver-pod-4 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:51Z"
    name: kube-apiserver-operator.179e33d337271cb8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16320"
    uid: d2c850ac-1309-42ff-86d9-af43d00b9d16
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:52Z"
  message: Created ConfigMap/config-4 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:52Z"
    name: kube-apiserver-operator.179e33d37ead4eef
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16366"
    uid: b66dd9a2-df8e-48c9-bf7a-59077b5470d1
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:53Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-106-212.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing PodIP in operand kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:24:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:53Z"
    name: kube-apiserver-operator.179e33d3b5c4a4bc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16388"
    uid: f3633c8c-3474-4b90-924d-a7aef1ff3340
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:53Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-4 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:53Z"
    name: kube-apiserver-operator.179e33d3ba667f97
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16391"
    uid: 1b336c29-a45c-43d5-b350-c5081bd1d164
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:53Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    on node ip-10-0-106-212.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal
    on node ip-10-0-106-212.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:24:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:53Z"
    name: kube-apiserver-operator.179e33d3c4cf9ad6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16399"
    uid: 9acaa883-0394-4300-a867-e0eb5595722b
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:55Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:55Z"
  message: Created ConfigMap/cloud-config-4 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:55Z"
    name: kube-apiserver-operator.179e33d431bdfea9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16445"
    uid: 82a749cb-75d0-45cc-8039-0cd7fd73c65b
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:57Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-4 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:57Z"
    name: kube-apiserver-operator.179e33d4b62a614a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16521"
    uid: eddf06d7-5f28-443f-8b5e-cf8f3ce7e657
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:59Z"
  message: clusteroperator/kube-apiserver version "kube-apiserver" changed from ""
    to "1.28.4"
  metadata:
    creationTimestamp: "2023-12-06T09:24:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:59Z"
    name: kube-apiserver-operator.179e33d514ab89fd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16590"
    uid: 4379ffe5-758a-41f6-a277-80ba7774707a
  reason: OperatorVersionChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:59Z"
  message: clusteroperator/kube-apiserver version "operator" changed from "" to "4.15.0-0.ci.test-2023-12-06-090630-ci-op-2j285qtr-latest"
  metadata:
    creationTimestamp: "2023-12-06T09:24:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:59Z"
    name: kube-apiserver-operator.179e33d514abbccf
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16592"
    uid: 1b1d0264-4189-4b32-8b2c-66f9b8dce312
  reason: OperatorVersionChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:59Z"
  message: 'Status for clusteroperator/kube-apiserver changed: status.versions changed
    from [{"raw-internal" "4.15.0-0.ci.test-2023-12-06-090630-ci-op-2j285qtr-latest"}]
    to [{"raw-internal" "4.15.0-0.ci.test-2023-12-06-090630-ci-op-2j285qtr-latest"}
    {"kube-apiserver" "1.28.4"} {"operator" "4.15.0-0.ci.test-2023-12-06-090630-ci-op-2j285qtr-latest"}]'
  metadata:
    creationTimestamp: "2023-12-06T09:24:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:59Z"
    name: kube-apiserver-operator.179e33d5152ffcf0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16588"
    uid: 8bd42754-4202-476d-802c-5f25f7b91124
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:24:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:24:59Z"
  message: Created ConfigMap/etcd-serving-ca-4 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:24:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:24:59Z"
    name: kube-apiserver-operator.179e33d52bcc1f8c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16602"
    uid: 17ea7147-0b0e-47e4-a715-1bc717e9623a
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:00Z"
  message: Created Pod/kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:00Z"
    name: kube-apiserver-operator.179e33d537d6ecdf
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16607"
    uid: 24627dc2-462c-49bd-944e-5ebeb439590b
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:00Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing PodIP
    in operand kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal on node ip-10-0-106-212.us-west-1.compute.internal]"
    to "GuardControllerDegraded: [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:25:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:00Z"
    name: kube-apiserver-operator.179e33d5396ae64c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16612"
    uid: 455e1ae3-a425-4f79-849f-3db505b8133d
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:01Z"
  message: Created ConfigMap/kube-apiserver-server-ca-4 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:01Z"
    name: kube-apiserver-operator.179e33d58b7f325f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16667"
    uid: 42193502-e85f-4fbe-85f1-1c4292cef86f
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:03Z"
  message: Created ConfigMap/kubelet-serving-ca-4 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:03Z"
    name: kube-apiserver-operator.179e33d60e662889
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16703"
    uid: bec52447-8d21-4907-9ef7-3e311fadddbf
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:05Z"
  message: Created ConfigMap/sa-token-signing-certs-4 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:05Z"
    name: kube-apiserver-operator.179e33d6858d3c3b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16738"
    uid: 56266294-a75e-4b30-82ad-9535a74d12f9
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:06Z"
  message: Updated Pod/kube-apiserver-guard-ip-10-0-106-212.us-west-1.compute.internal
    -n openshift-kube-apiserver because it changed
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:06Z"
    name: kube-apiserver-operator.179e33d69e0d0bc5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16759"
    uid: ffeb4a45-ebaf-4432-81c0-96c59d79a200
  reason: PodUpdated
  reportingComponent: kube-apiserver-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 8
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:21Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:25:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:21Z"
    name: kube-apiserver-operator.179e33d6a4e24394
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "20989"
    uid: 9144cf5b-042a-4f25-81f8-8102479791a5
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:07Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-4 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:07Z"
    name: kube-apiserver-operator.179e33d6f0beff16
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16799"
    uid: dce49ee1-f4fe-4c63-8cac-ce1f946cb6ac
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:09Z"
  message: Created Secret/etcd-client-4 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:09Z"
    name: kube-apiserver-operator.179e33d773fbe6b7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16850"
    uid: 4ce37bce-1d77-4a6e-87e6-985128f9e8bd
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:13Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:13Z"
  message: Created Secret/localhost-recovery-serving-certkey-4 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:13Z"
    name: kube-apiserver-operator.179e33d8568c89bf
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16951"
    uid: b4278c51-d037-4674-9698-ba3390472a7b
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:14Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:14Z"
  message: Created Secret/localhost-recovery-client-token-4 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:14Z"
    name: kube-apiserver-operator.179e33d89e9e8367
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "16991"
    uid: f50acfb0-678e-48c4-a7b1-d0d9f3309ef1
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:16Z"
  message: Created Secret/webhook-authenticator-4 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:16Z"
    name: kube-apiserver-operator.179e33d9094533ee
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "17089"
    uid: d22efe4c-ce86-432b-84df-282e1dfe2c6f
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:16Z"
  message: Revision 4 created because required configmap/config has changed
  metadata:
    creationTimestamp: "2023-12-06T09:25:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:16Z"
    name: kube-apiserver-operator.179e33d90a04c3e6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "17091"
    uid: c57b3936-99d1-44cb-9bd9-e5942e6dd42f
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:18Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal]\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 4"'
  metadata:
    creationTimestamp: "2023-12-06T09:25:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:18Z"
    name: kube-apiserver-operator.179e33d9829d2c96
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "17400"
    uid: 84c34999-ea93-4e09-8a0d-28a89882bb0d
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:18Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 4" to "GuardControllerDegraded: [Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:25:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:18Z"
    name: kube-apiserver-operator.179e33d983c5cd9a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "17403"
    uid: a5c1aa9b-38f7-4e4b-95ac-9033c44b8afd
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:24Z"
  message: Updated node "ip-10-0-106-212.us-west-1.compute.internal" from revision
    0 to 3 because static pod is ready
  metadata:
    creationTimestamp: "2023-12-06T09:25:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:24Z"
    name: kube-apiserver-operator.179e33dae69f6a52
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "17677"
    uid: b006eb1a-8c1b-4661-88b5-b77d83ab25c1
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:24Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have
    achieved new revision 3" to "NodeInstallerProgressing: 2 nodes are at revision
    0; 1 nodes are at revision 3; 0 nodes have achieved new revision 4",Available
    changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes
    are at revision 0; 1 nodes are at revision 3; 0 nodes have achieved new revision
    4")'
  metadata:
    creationTimestamp: "2023-12-06T09:25:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:24Z"
    name: kube-apiserver-operator.179e33dae76187b3
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "17679"
    uid: d4a32452-c4f5-47b4-a09e-cd441742d39b
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 7
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:16Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:25:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:16Z"
    name: kube-apiserver-operator.179e33ddf974bb2c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "20880"
    uid: 7b9d145f-be1e-451c-90c7-65064ee9ad22
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:53Z"
  message: Updating node "ip-10-0-21-63.us-west-1.compute.internal" from revision
    0 to 4 because node ip-10-0-21-63.us-west-1.compute.internal static pod not found
  metadata:
    creationTimestamp: "2023-12-06T09:25:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:53Z"
    name: kube-apiserver-operator.179e33e18d42f487
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "18539"
    uid: 3ae4b35a-88a9-4a5a-8b0d-6b288b9022a2
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:56Z"
  message: Updated storage urls to https://10.0.106.212:2379,https://10.0.21.63:2379,https://10.0.94.160:2379,https://localhost:2379
  metadata:
    creationTimestamp: "2023-12-06T09:25:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:56Z"
    name: kube-apiserver-operator.179e33e2728229b1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "18637"
    uid: 7fd72cf2-1c05-464b-ae23-5ec0f2902307
  reason: ObserveStorageUpdated
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:56Z"
  message: "Writing updated observed config: map[string]any{\n\t\"admission\":
    map[string]any{\"pluginConfig\": map[string]any{\"PodSecurity\": map[string]any{\"configuration\":
    map[string]any{\"defaults\": map[string]any{\"audit\": string(\"restricted\"),
    \"audit-version\": string(\"latest\"), \"enforce\": string(\"restricted\"), \"enforce-version\":
    string(\"latest\"), ...}}}, \"network.openshift.io/ExternalIPRanger\": map[string]any{\"configuration\":
    map[string]any{\"allowIngressIP\": bool(false), \"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"ExternalIPRangerAdmissionConfig\")}}, \"network.openshift.io/RestrictedEndpointsAdmission\":
    map[string]any{\"configuration\": map[string]any{\"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"RestrictedEndpointsAdmissionConfig\"), \"restrictedCIDRs\":
    []any{string(\"10.128.0.0/14\"), string(\"172.30.0.0/16\")}}}}},\n\t\"apiServerArguments\":
    map[string]any{\n\t\t... // 3 identical entries\n\t\t\"cloud-config\":   []any{string(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo\"...)},\n\t\t\"cloud-provider\":
    []any{string(\"external\")},\n\t\t\"etcd-servers\": []any{\n\t\t\tstring(\"https://10.0.106.212:2379\"),\n\t\t\tstring(\"https://10.0.21.63:2379\"),\n+\t\t\tstring(\"https://10.0.94.160:2379\"),\n\t\t\tstring(\"https://localhost:2379\"),\n\t\t},\n\t\t\"feature-gates\":
    \                        []any{string(\"AdminNetworkPolicy=false\"), string(\"AlibabaPlatform=true\"),
    string(\"AutomatedEtcdBackup=false\"), string(\"AzureWorkloadIdentity=true\"),
    ...},\n\t\t\"send-retry-after-while-not-ready-once\": []any{string(\"false\")},\n\t\t...
    // 3 identical entries\n\t},\n\t\"corsAllowedOrigins\":          []any{string(`//127\\.0\\.0\\.1(:|$)`),
    string(\"//localhost(:|$)\")},\n\t\"gracefulTerminationDuration\": string(\"194\"),\n\t...
    // 2 identical entries\n}\n"
  metadata:
    creationTimestamp: "2023-12-06T09:25:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:56Z"
    name: kube-apiserver-operator.179e33e27304fef3
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "18640"
    uid: 807b9c55-195b-4869-89e7-05917ecd79c2
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:25:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:25:57Z"
  message: Created Pod/installer-4-ip-10-0-21-63.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:25:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:25:57Z"
    name: kube-apiserver-operator.179e33e2a8d24acb
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "18712"
    uid: 67682354-814d-413e-a8d1-c449019acd5f
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:24Z"
  message: new revision 5 triggered by "required configmap/config has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:26:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:24Z"
    name: kube-apiserver-operator.179e33e41a73666a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19717"
    uid: d36a7d30-1682-427e-9740-0b1ad111af0e
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:05Z"
  message: Created ConfigMap/revision-status-5 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:05Z"
    name: kube-apiserver-operator.179e33e479727bfb
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "18946"
    uid: 2f013f65-b27a-4c54-8582-6b8c5a002abe
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:06Z"
  message: Created ConfigMap/kube-apiserver-pod-5 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:06Z"
    name: kube-apiserver-operator.179e33e4b508b942
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19012"
    uid: 8af59335-857e-4f6b-b3dc-77e0148d275a
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:07Z"
  message: Created ConfigMap/config-5 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:07Z"
    name: kube-apiserver-operator.179e33e4fc98ab7d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19029"
    uid: 0f0404e9-6669-4f4a-84ee-14448a19e225
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:08Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-5 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:08Z"
    name: kube-apiserver-operator.179e33e5440c21d4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19092"
    uid: cc8090e7-36aa-49ff-9fab-bdb1cdba6f66
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:10Z"
  message: Created ConfigMap/cloud-config-5 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:10Z"
    name: kube-apiserver-operator.179e33e58b90b932
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19129"
    uid: af6bfcb5-34e2-40d1-a21f-c231a997ae9a
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:11Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:11Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-5 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:11Z"
    name: kube-apiserver-operator.179e33e5d36cff95
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19164"
    uid: 829386ea-5958-480b-a51e-66fb47f43c19
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:12Z"
  message: Created ConfigMap/etcd-serving-ca-5 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:12Z"
    name: kube-apiserver-operator.179e33e61a98bb7c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19192"
    uid: f8e19c43-ef44-41cf-9d29-b1c1b364efcd
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:13Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:13Z"
  message: Created ConfigMap/kube-apiserver-server-ca-5 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:13Z"
    name: kube-apiserver-operator.179e33e66227bffc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19261"
    uid: 05139d87-d651-43db-95d4-a905cfc86ef6
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:14Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:14Z"
  message: Created ConfigMap/kubelet-serving-ca-5 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:14Z"
    name: kube-apiserver-operator.179e33e6a9c56ff5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19305"
    uid: 22a454de-4ce4-4a39-9c59-d039726ca117
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:16Z"
  message: Created ConfigMap/sa-token-signing-certs-5 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:16Z"
    name: kube-apiserver-operator.179e33e6f12faf42
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19329"
    uid: 954b50e1-bf9b-4223-9342-43182ac00e8d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:17Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-5 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:17Z"
    name: kube-apiserver-operator.179e33e738baa9f1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19354"
    uid: e7424d65-ee5a-4d93-bf07-4c1f3317eb03
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:18Z"
  message: Created Secret/etcd-client-5 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:18Z"
    name: kube-apiserver-operator.179e33e7804e02e6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19383"
    uid: 8e7d022a-5967-4648-ace7-b6803ff900dd
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:21Z"
  message: Created Secret/localhost-recovery-serving-certkey-5 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:21Z"
    name: kube-apiserver-operator.179e33e834def52d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19550"
    uid: 39c1ac33-7b99-408d-a967-0c705074d978
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:23Z"
  message: Created Secret/localhost-recovery-client-token-5 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:23Z"
    name: kube-apiserver-operator.179e33e892755462
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19654"
    uid: 66404053-a273-44c4-b0c4-03429d2250cb
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:24Z"
  message: Created Secret/webhook-authenticator-5 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:24Z"
    name: kube-apiserver-operator.179e33e8fdc5e80b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19713"
    uid: e43dbffb-b8b4-47b9-895d-eeeb5f14ee43
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:24Z"
  message: Revision 5 created because required configmap/config has changed
  metadata:
    creationTimestamp: "2023-12-06T09:26:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:24Z"
    name: kube-apiserver-operator.179e33e8fe7fa1ed
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19716"
    uid: 3e5f76b4-5d13-4f04-808d-c74834ffd617
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:26Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand
    on node ip-10-0-21-63.us-west-1.compute.internal]\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 5"'
  metadata:
    creationTimestamp: "2023-12-06T09:26:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:26Z"
    name: kube-apiserver-operator.179e33e95ef03417
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19776"
    uid: e8c510bd-2026-459c-95a3-5a5c84963b7f
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:26Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-94-160.us-west-1.compute.internal,
    Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 5" to "GuardControllerDegraded: [Missing operand
    on node ip-10-0-94-160.us-west-1.compute.internal, Missing operand on node ip-10-0-21-63.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:26:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:26Z"
    name: kube-apiserver-operator.179e33e9601836d3
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19778"
    uid: 55609e20-95c5-4135-950c-de0391805168
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:27Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 nodes are
    at revision 3; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing:
    2 nodes are at revision 0; 1 nodes are at revision 3; 0 nodes have achieved new
    revision 5",Available message changed from "StaticPodsAvailable: 1 nodes are active;
    2 nodes are at revision 0; 1 nodes are at revision 3; 0 nodes have achieved new
    revision 4" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision
    0; 1 nodes are at revision 3; 0 nodes have achieved new revision 5"'
  metadata:
    creationTimestamp: "2023-12-06T09:26:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:27Z"
    name: kube-apiserver-operator.179e33e98f252c16
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "19792"
    uid: ef0d85fc-38a6-4034-85ba-e087fe4dcaa3
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:26:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:26:46Z"
  message: Created Pod/installer-5-ip-10-0-21-63.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:26:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:26:46Z"
    name: kube-apiserver-operator.179e33ee0599e56b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "20340"
    uid: 7a4c7c8a-d7f9-43d0-9fc4-c99d4e416a90
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:28Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:28Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing operand on node ip-10-0-21-63.us-west-1.compute.internal,
    Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]" to "GuardControllerDegraded:
    [Missing PodIP in operand kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"'
  metadata:
    creationTimestamp: "2023-12-06T09:27:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:28Z"
    name: kube-apiserver-operator.179e33f7ac4ea8c9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "21112"
    uid: be2fecb6-bcbe-4bad-8feb-18ce630ccc0b
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:34Z"
  message: Created Pod/kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:27:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:34Z"
    name: kube-apiserver-operator.179e33f949b38bdd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "21218"
    uid: 84303a02-7e33-4dd0-b34d-1b4474430ea3
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:35Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-21-63.us-west-1.compute.internal
    on node ip-10-0-21-63.us-west-1.compute.internal, Missing operand on node ip-10-0-94-160.us-west-1.compute.internal]"
    to "GuardControllerDegraded: Missing operand on node ip-10-0-94-160.us-west-1.compute.internal"'
  metadata:
    creationTimestamp: "2023-12-06T09:27:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:35Z"
    name: kube-apiserver-operator.179e33f94ca12c88
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "21223"
    uid: c8e88c8f-1e2b-44ea-a405-46b2d90b40f5
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:42Z"
  message: Updated Pod/kube-apiserver-guard-ip-10-0-21-63.us-west-1.compute.internal
    -n openshift-kube-apiserver because it changed
  metadata:
    creationTimestamp: "2023-12-06T09:27:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:42Z"
    name: kube-apiserver-operator.179e33faf6fb2f81
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "21380"
    uid: c230886d-65c4-41e8-9c84-1a2575d19e4d
  reason: PodUpdated
  reportingComponent: kube-apiserver-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:47Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:47Z"
  message: Updated node "ip-10-0-21-63.us-west-1.compute.internal" from revision 0
    to 5 because static pod is ready
  metadata:
    creationTimestamp: "2023-12-06T09:27:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:47Z"
    name: kube-apiserver-operator.179e33fc5134c999
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "21556"
    uid: b229e6e2-66ea-43a6-8acf-f9b6cd893d8e
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:27:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:27:48Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 nodes are
    at revision 3; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing:
    1 nodes are at revision 0; 1 nodes are at revision 3; 1 nodes are at revision
    5",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2
    nodes are at revision 0; 1 nodes are at revision 3; 0 nodes have achieved new
    revision 5" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision
    0; 1 nodes are at revision 3; 1 nodes are at revision 5"'
  metadata:
    creationTimestamp: "2023-12-06T09:27:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:27:48Z"
    name: kube-apiserver-operator.179e33fc52a2401b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "21558"
    uid: e80f416e-23ae-4716-aa01-77f60ea6084d
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:28:15Z"
  message: Updating node "ip-10-0-94-160.us-west-1.compute.internal" from revision
    0 to 5 because node ip-10-0-94-160.us-west-1.compute.internal static pod not found
  metadata:
    creationTimestamp: "2023-12-06T09:28:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:28:15Z"
    name: kube-apiserver-operator.179e3402c0e91ab1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "22176"
    uid: 6a3a945e-d09d-4c50-a769-6adf062e4ec0
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:20Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:28:20Z"
  message: Created Pod/installer-5-ip-10-0-94-160.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:28:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:28:20Z"
    name: kube-apiserver-operator.179e3403d6acc6c4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "22241"
    uid: 70c849f8-5c92-40bb-87b6-a1776aa375ce
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:28:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:28:58Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "GuardControllerDegraded: Missing operand on node ip-10-0-94-160.us-west-1.compute.internal"
    to "GuardControllerDegraded: Missing PodIP in operand kube-apiserver-ip-10-0-94-160.us-west-1.compute.internal
    on node ip-10-0-94-160.us-west-1.compute.internal"'
  metadata:
    creationTimestamp: "2023-12-06T09:28:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:28:58Z"
    name: kube-apiserver-operator.179e340cd7aec89b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "22742"
    uid: 7eb4c8a3-d01a-41aa-8ac0-0f275f8c8814
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:07Z"
  message: Created Pod/kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:29:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:07Z"
    name: kube-apiserver-operator.179e340ed6e84c42
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "22879"
    uid: d7f33d0e-fa8f-4834-8366-3405ad63768d
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:07Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded changed from
    True to False ("NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded:
    pod/kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal container \"kube-apiserver\"
    started at 2023-12-06 09:25:05 +0000 UTC is still not ready")'
  metadata:
    creationTimestamp: "2023-12-06T09:29:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:07Z"
    name: kube-apiserver-operator.179e340ed8c460b6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "22885"
    uid: 72c12e93-10c7-4efb-96fc-a1219bb537fb
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:14Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:14Z"
  message: Updated Pod/kube-apiserver-guard-ip-10-0-94-160.us-west-1.compute.internal
    -n openshift-kube-apiserver because it changed
  metadata:
    creationTimestamp: "2023-12-06T09:29:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:14Z"
    name: kube-apiserver-operator.179e341060539373
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "22986"
    uid: 8c6c6bb6-ac61-473c-8379-43f2bd2fdb25
  reason: PodUpdated
  reportingComponent: kube-apiserver-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:18Z"
  message: Updated node "ip-10-0-94-160.us-west-1.compute.internal" from revision
    0 to 5 because static pod is ready
  metadata:
    creationTimestamp: "2023-12-06T09:29:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:18Z"
    name: kube-apiserver-operator.179e34117edbcb92
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "23056"
    uid: 6f4fcfff-7eff-4aa7-8f83-a8236a3bb6a3
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:18Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are
    at revision 3; 1 nodes are at revision 5" to "NodeInstallerProgressing: 1 nodes
    are at revision 3; 2 nodes are at revision 5",Available message changed from "StaticPodsAvailable:
    2 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 3; 1 nodes
    are at revision 5" to "StaticPodsAvailable: 3 nodes are active; 1 nodes are at
    revision 3; 2 nodes are at revision 5"'
  metadata:
    creationTimestamp: "2023-12-06T09:29:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:18Z"
    name: kube-apiserver-operator.179e34117fc91365
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "23058"
    uid: f3c0718d-6d6b-46d4-b641-574e551b0c13
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:48Z"
  message: Updating node "ip-10-0-106-212.us-west-1.compute.internal" from revision
    3 to 5 because node ip-10-0-106-212.us-west-1.compute.internal with revision 3
    is the oldest not ready
  metadata:
    creationTimestamp: "2023-12-06T09:29:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:48Z"
    name: kube-apiserver-operator.179e341844e24266
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "23503"
    uid: 5cb0bdb6-df8d-44b3-b209-41c5cc418b18
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:51Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded:
    pod/kube-apiserver-ip-10-0-106-212.us-west-1.compute.internal container \"kube-apiserver\"
    started at 2023-12-06 09:25:05 +0000 UTC is still not ready" to "NodeControllerDegraded:
    All master nodes are ready"'
  metadata:
    creationTimestamp: "2023-12-06T09:29:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:51Z"
    name: kube-apiserver-operator.179e34192f27a26e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "23566"
    uid: 2623640b-fcd1-48ae-96cd-373764ac64da
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:29:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:29:52Z"
  message: Created Pod/installer-5-ip-10-0-106-212.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:29:52Z"
    name: kube-apiserver-operator.179e341939aa262e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "23569"
    uid: 313424ff-7e8a-4cfe-8e86-8e19fb0612e1
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:33:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:33:45Z"
  message: Updated node "ip-10-0-106-212.us-west-1.compute.internal" from revision
    3 to 5 because static pod is ready
  metadata:
    creationTimestamp: "2023-12-06T09:33:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:33:45Z"
    name: kube-apiserver-operator.179e344f769297db
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "26479"
    uid: 9f6c914e-d8b2-44a4-b646-88ac5eefdbbf
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:33:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:33:45Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing changed
    from True to False ("NodeInstallerProgressing: 3 nodes are at revision 5"),Available
    message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at
    revision 3; 2 nodes are at revision 5" to "StaticPodsAvailable: 3 nodes are active;
    3 nodes are at revision 5"'
  metadata:
    creationTimestamp: "2023-12-06T09:33:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:33:45Z"
    name: kube-apiserver-operator.179e344f77598c5f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "26481"
    uid: ef59eba7-7261-4a57-9f2e-7e0b0707ccd0
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:34:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:34:58Z"
  message: "Writing updated observed config: map[string]any{\n\t\"admission\":
    \         map[string]any{\"pluginConfig\": map[string]any{\"PodSecurity\": map[string]any{\"configuration\":
    map[string]any{\"defaults\": map[string]any{\"audit\": string(\"restricted\"),
    \"audit-version\": string(\"latest\"), \"enforce\": string(\"restricted\"), \"enforce-version\":
    string(\"latest\"), ...}}}, \"network.openshift.io/ExternalIPRanger\": map[string]any{\"configuration\":
    map[string]any{\"allowIngressIP\": bool(false), \"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"ExternalIPRangerAdmissionConfig\")}}, \"network.openshift.io/RestrictedEndpointsAdmission\":
    map[string]any{\"configuration\": map[string]any{\"apiVersion\": string(\"network.openshift.io/v1\"),
    \"kind\": string(\"RestrictedEndpointsAdmissionConfig\"), \"restrictedCIDRs\":
    []any{string(\"10.128.0.0/14\"), string(\"172.30.0.0/16\")}}}}},\n\t\"apiServerArguments\":
    map[string]any{\"api-audiences\": []any{string(\"https://kubernetes.default.svc\")},
    \"authentication-token-webhook-config-file\": []any{string(\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat\"...)},
    \"authentication-token-webhook-version\": []any{string(\"v1\")}, \"cloud-config\":
    []any{string(\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo\"...)},
    ...},\n+\t\"authConfig\": map[string]any{\n+\t\t\"oauthMetadataFile\": string(\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"),\n+\t},\n\t\"corsAllowedOrigins\":
    \         []any{string(`//127\\.0\\.0\\.1(:|$)`), string(\"//localhost(:|$)\")},\n\t\"gracefulTerminationDuration\":
    string(\"194\"),\n\t... // 2 identical entries\n}\n"
  metadata:
    creationTimestamp: "2023-12-06T09:34:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:34:58Z"
    name: kube-apiserver-operator.179e34608c2c4195
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27247"
    uid: 9affe599-442a-4a5e-9560-bb68b3f75fc7
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:00Z"
  message: new revision 6 triggered by "required configmap/config has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:35:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:00Z"
    name: kube-apiserver-operator.179e3460f150f4a0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27289"
    uid: 7605b25f-16e6-44bc-8e1e-39f688fe58f2
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:00Z"
  message: Created ConfigMap/oauth-metadata -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:00Z"
    name: kube-apiserver-operator.179e346120b498be
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27305"
    uid: 194ae921-85ec-44fa-b850-e7b559306d6d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:01Z"
  message: Created ConfigMap/revision-status-6 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:01Z"
    name: kube-apiserver-operator.179e3461504bf6f7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27315"
    uid: 064182c0-9abb-481c-89c6-e692b2e2bcd1
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:03Z"
  message: Created ConfigMap/kube-apiserver-pod-6 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:03Z"
    name: kube-apiserver-operator.179e3461a3d9c5e5
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27331"
    uid: 7665de5c-637c-459e-bdf3-cd075520e6a8
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:04Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:04Z"
  message: Created ConfigMap/config-6 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:04Z"
    name: kube-apiserver-operator.179e3461f74fe6d7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27377"
    uid: 8c94a10a-a56f-47b7-bee8-dbb5720d0824
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:05Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-6 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:05Z"
    name: kube-apiserver-operator.179e34624a96a275
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27401"
    uid: 8b39457a-e412-4d61-96f1-631afd328c38
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:07Z"
  message: Created ConfigMap/oauth-metadata-6 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:07Z"
    name: kube-apiserver-operator.179e34629e2298cc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27415"
    uid: 29951ad0-89a1-49dc-b2c7-aa5286adc409
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:08Z"
  message: Created ConfigMap/cloud-config-6 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:08Z"
    name: kube-apiserver-operator.179e3462f1801b54
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27480"
    uid: 9e8b13e7-c436-4cf7-b0f3-2b13d70bdd69
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:10Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-6 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:10Z"
    name: kube-apiserver-operator.179e346344f752e1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27536"
    uid: a2682a99-1fec-45a2-b6d8-96fb2ed80d3f
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:11Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:11Z"
  message: Created ConfigMap/etcd-serving-ca-6 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:11Z"
    name: kube-apiserver-operator.179e34638d021cad
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27585"
    uid: 0220c83f-999a-4221-a0b0-03db27db6b96
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:12Z"
  message: Created ConfigMap/kube-apiserver-server-ca-6 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:12Z"
    name: kube-apiserver-operator.179e3463d41e0beb
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27593"
    uid: 971a1e16-dc41-4a13-8dff-8987ed801533
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:13Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:13Z"
  message: Created ConfigMap/kubelet-serving-ca-6 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:13Z"
    name: kube-apiserver-operator.179e34641b95b1da
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27603"
    uid: cd8a0a21-c217-4be4-a1fa-c591cf286ece
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:14Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:14Z"
  message: Created ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:14Z"
    name: kube-apiserver-operator.179e34646312e484
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27609"
    uid: b8a78c9c-d27e-4fbb-b843-1815845d5e1d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:16Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-6 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:16Z"
    name: kube-apiserver-operator.179e3464aa971313
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27636"
    uid: ddbff62f-43f2-4a25-baa1-e142c2a73709
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:17Z"
  message: Created Secret/etcd-client-6 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:17Z"
    name: kube-apiserver-operator.179e3464f22f226d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27647"
    uid: 0134a14e-c07b-46ff-ae7c-289222c6deb1
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:19Z"
  message: Created Secret/localhost-recovery-serving-certkey-6 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:19Z"
    name: kube-apiserver-operator.179e3465815f4365
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27664"
    uid: 0bae12fc-002d-4b7d-bb48-e3acf7e9fd87
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:20Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:20Z"
  message: Created Secret/localhost-recovery-client-token-6 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:20Z"
    name: kube-apiserver-operator.179e3465b1116286
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27683"
    uid: a100bd2b-7bef-480c-a8da-3178d60b4575
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:21Z"
  message: Created Secret/webhook-authenticator-6 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:21Z"
    name: kube-apiserver-operator.179e3465ec7d4a0a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27703"
    uid: 603f38fe-bb01-4abf-b821-04cd27a53b9c
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:21Z"
  message: Revision 6 created because required configmap/config has changed
  metadata:
    creationTimestamp: "2023-12-06T09:35:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:21Z"
    name: kube-apiserver-operator.179e3465ed3be8a0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27705"
    uid: c5d7172e-cdf9-4877-8aca-7b145ad3e883
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:29Z"
  message: Updating node "ip-10-0-106-212.us-west-1.compute.internal" from revision
    5 to 6 because node ip-10-0-106-212.us-west-1.compute.internal with revision 5
    is the oldest
  metadata:
    creationTimestamp: "2023-12-06T09:35:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:29Z"
    name: kube-apiserver-operator.179e3467c9d24d24
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27786"
    uid: e466c06e-8f56-4a35-a9da-7f63ed8b87b3
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:29Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing changed
    from False to True ("NodeInstallerProgressing: 3 nodes are at revision 5; 0 nodes
    have achieved new revision 6"),Available message changed from "StaticPodsAvailable:
    3 nodes are active; 3 nodes are at revision 5" to "StaticPodsAvailable: 3 nodes
    are active; 3 nodes are at revision 5; 0 nodes have achieved new revision 6"'
  metadata:
    creationTimestamp: "2023-12-06T09:35:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:29Z"
    name: kube-apiserver-operator.179e3467ca705826
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27788"
    uid: 40ec913b-679b-4261-a48f-56b37f45a2b4
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:35:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:35:34Z"
  message: Created Pod/installer-6-ip-10-0-106-212.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:35:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:35:34Z"
    name: kube-apiserver-operator.179e3468e7b20ee3
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "27854"
    uid: d35063a6-9b87-4378-a187-b4052eced11c
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:16Z"
  message: new revision 7 triggered by "required secret/localhost-recovery-client-token
    has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:37:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:16Z"
    name: kube-apiserver-operator.179e3480b904cd36
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29233"
    uid: 4fa18a6c-a9c2-4914-966b-e3b87372cfb6
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:16Z"
  message: Created ConfigMap/revision-status-7 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:16Z"
    name: kube-apiserver-operator.179e3480c2d70706
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29265"
    uid: 1f43b4a9-0466-4249-aa31-024ec84c8f41
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:16Z"
  message: Created ConfigMap/kube-apiserver-pod-7 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:16Z"
    name: kube-apiserver-operator.179e3480c6a12a5a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29280"
    uid: f73e150f-abb9-4a14-ab93-1a139a706dd8
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:17Z"
  message: Created ConfigMap/config-7 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:17Z"
    name: kube-apiserver-operator.179e34810232f2ec
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29384"
    uid: a7193a38-a2e1-4243-aab6-6ad4cb5f0fd6
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:19Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-7 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:19Z"
    name: kube-apiserver-operator.179e348149656a23
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29417"
    uid: 50f0916a-6ddd-44c4-b644-a215fb844213
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:20Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:20Z"
  message: Created ConfigMap/oauth-metadata-7 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:20Z"
    name: kube-apiserver-operator.179e348190f117de
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29443"
    uid: 23b27ad8-6c03-4acc-98e0-3603fc68a987
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:21Z"
  message: |-
    Updated ConfigMap/sa-token-signing-certs -n openshift-kube-apiserver:
    cause by changes in data.service-account-002.pub
  metadata:
    creationTimestamp: "2023-12-06T09:37:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:21Z"
    name: kube-apiserver-operator.179e3481d86a5c3d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29473"
    uid: 896bec10-64ec-4809-bcd4-d3a7dc9c4862
  reason: ConfigMapUpdated
  reportingComponent: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:21Z"
  message: Created ConfigMap/cloud-config-7 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:21Z"
    name: kube-apiserver-operator.179e3481e459b1c7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29477"
    uid: efb8b9b9-de66-4714-9a26-2f92136fbb82
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:22Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-7 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:22Z"
    name: kube-apiserver-operator.179e34822be0c691
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29495"
    uid: ee2cc86e-fb32-4b52-92d9-8d74b0fab736
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:24Z"
  message: Created ConfigMap/etcd-serving-ca-7 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:24Z"
    name: kube-apiserver-operator.179e3482737ac602
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29522"
    uid: 36d178ac-850b-4e3b-868c-bfdc2ac62a10
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:25Z"
  message: Created ConfigMap/kube-apiserver-server-ca-7 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:25Z"
    name: kube-apiserver-operator.179e3482bb072b05
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29533"
    uid: caa6641f-7668-49c2-aec2-e2459058cad6
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:26Z"
  message: Created ConfigMap/kubelet-serving-ca-7 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:26Z"
    name: kube-apiserver-operator.179e348302bac38c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29549"
    uid: c3dfb04f-f4d5-44ad-85d4-36546bd11a05
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:27Z"
  message: Created ConfigMap/sa-token-signing-certs-7 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:27Z"
    name: kube-apiserver-operator.179e34834ae7c764
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29568"
    uid: 08815e8e-8ad9-4438-996f-a4f55498f482
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:28Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:28Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-7 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:28Z"
    name: kube-apiserver-operator.179e348391c75358
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29584"
    uid: 7bf86063-7c31-4f40-8d14-e349b8860c9b
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:30Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:30Z"
  message: Created Secret/etcd-client-7 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:30Z"
    name: kube-apiserver-operator.179e3483d991c90f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29600"
    uid: 6b6e9b1e-df76-48b5-b983-c5e2117b0701
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:32Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:32Z"
  message: Created Secret/localhost-recovery-serving-certkey-7 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:32Z"
    name: kube-apiserver-operator.179e34845c53c5d8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29629"
    uid: 1de63c4e-6296-4ec9-9cc4-187cdf3d718e
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:33Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:33Z"
  message: Created Secret/localhost-recovery-client-token-7 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:33Z"
    name: kube-apiserver-operator.179e34848c35e8c7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29643"
    uid: d7347b19-66d5-4b61-90be-322e7a5d5421
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:34Z"
  message: Created Secret/webhook-authenticator-7 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:34Z"
    name: kube-apiserver-operator.179e3484c7933afd
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29665"
    uid: f2f8d608-f2f7-4bbe-a87d-f5d3c9fd29e6
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:34Z"
  message: Revision 7 created because required secret/localhost-recovery-client-token
    has changed
  metadata:
    creationTimestamp: "2023-12-06T09:37:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:34Z"
    name: kube-apiserver-operator.179e3484c858e324
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29667"
    uid: 33c88164-8609-406f-bcc4-ff56b3c1f6a7
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:34Z"
  message: new revision 7 triggered by "required secret/localhost-recovery-client-token
    has changed,required configmap/sa-token-signing-certs has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:37:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:34Z"
    name: kube-apiserver-operator.179e3484c8b82e2c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29668"
    uid: c2dd96a1-c325-44e6-9792-d1ec02dfe0e0
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:35Z"
  message: |-
    Updated ConfigMap/revision-status-7 -n openshift-kube-apiserver:
    cause by changes in data.reason
  metadata:
    creationTimestamp: "2023-12-06T09:37:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:35Z"
    name: kube-apiserver-operator.179e34850f114da0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29677"
    uid: 94365df2-71e7-44c7-9510-e45c627609c8
  reason: ConfigMapUpdated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:37Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded:
    All master nodes are ready\nRevisionControllerDegraded: conflicting latestAvailableRevision
    7"'
  metadata:
    creationTimestamp: "2023-12-06T09:37:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:37Z"
    name: kube-apiserver-operator.179e34857bf78573
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29709"
    uid: bd32ed13-cfa0-42a1-8297-0ce394ad4371
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:37Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 7" to "NodeControllerDegraded: All master
    nodes are ready"'
  metadata:
    creationTimestamp: "2023-12-06T09:37:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:37Z"
    name: kube-apiserver-operator.179e34857d5249b8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29711"
    uid: dde474e7-0c41-4e98-a538-1bafaf79fa8c
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:40Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 3 nodes are at revision 5; 0 nodes have
    achieved new revision 6" to "NodeInstallerProgressing: 3 nodes are at revision
    5; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable:
    3 nodes are active; 3 nodes are at revision 5; 0 nodes have achieved new revision
    6" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 5; 0 nodes
    have achieved new revision 7"'
  metadata:
    creationTimestamp: "2023-12-06T09:37:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:40Z"
    name: kube-apiserver-operator.179e348652172a28
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29750"
    uid: 7385a76c-837c-4f56-9a59-0e754912f2fc
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:37:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:37:46Z"
  message: Created Pod/installer-7-ip-10-0-106-212.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:37:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:37:46Z"
    name: kube-apiserver-operator.179e3487c2c02113
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "29841"
    uid: a57ee646-418a-46d3-8794-a1e5735f5662
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:27Z"
  message: Internal registry hostname changed to "image-registry.openshift-image-registry.svc:5000"
  metadata:
    creationTimestamp: "2023-12-06T09:38:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:27Z"
    name: kube-apiserver-operator.179e34913da89a81
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "30699"
    uid: 31180c42-35df-4af0-8aa1-11a1e5cfcf0c
  reason: ObserveInternalRegistryHostnameChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:27Z"
  message: "Writing updated observed config: map[string]any{\n\t... // 3 identical
    entries\n\t\"corsAllowedOrigins\":          []any{string(`//127\\.0\\.0\\.1(:|$)`),
    string(\"//localhost(:|$)\")},\n\t\"gracefulTerminationDuration\": string(\"194\"),\n+\t\"imagePolicyConfig\":
    map[string]any{\n+\t\t\"internalRegistryHostname\": string(\"image-registry.openshift-image-registry.svc:5000\"),\n+\t},\n\t\"servicesSubnet\":
    string(\"172.30.0.0/16\"),\n\t\"servingInfo\":    map[string]any{\"bindAddress\":
    string(\"0.0.0.0:6443\"), \"bindNetwork\": string(\"tcp4\"), \"cipherSuites\":
    []any{string(\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\"), string(\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\"),
    string(\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"), string(\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\"),
    ...}, \"minTLSVersion\": string(\"VersionTLS12\"), ...},\n}\n"
  metadata:
    creationTimestamp: "2023-12-06T09:38:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:27Z"
    name: kube-apiserver-operator.179e34914d7a82b7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "30708"
    uid: abfef342-1f32-4a6e-a0d3-fe4216caaa7f
  reason: ObservedConfigChanged
  reportingComponent: kube-apiserver-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:39:00Z"
  message: new revision 8 triggered by "required configmap/config has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:38:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:39:00Z"
    name: kube-apiserver-operator.179e3493b2466572
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31472"
    uid: f807c56a-2719-4ecf-9561-98f2dfec0bfb
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:39Z"
  message: Created ConfigMap/revision-status-8 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:39Z"
    name: kube-apiserver-operator.179e3493f967e624
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31252"
    uid: 59fcb053-8a94-4b3b-931c-96ed0034b677
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:40Z"
  message: Created ConfigMap/kube-apiserver-pod-8 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:40Z"
    name: kube-apiserver-operator.179e34944d0580d9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31266"
    uid: c95aee08-520d-471e-9a30-f50b97914509
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:42Z"
  message: Created ConfigMap/config-8 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:42Z"
    name: kube-apiserver-operator.179e3494a050d496
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31284"
    uid: f816d149-5c82-4ba0-a3ae-5b53bbc20614
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:43Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-8 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:43Z"
    name: kube-apiserver-operator.179e3494ff966412
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31303"
    uid: 081fbe24-5bb4-4a57-8d0b-2c6a7cbaf581
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:44Z"
  message: Created ConfigMap/oauth-metadata-8 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:44Z"
    name: kube-apiserver-operator.179e34954700c368
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31315"
    uid: 309227fe-ba0c-4fba-9961-91b22a992237
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:46Z"
  message: Created ConfigMap/cloud-config-8 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:46Z"
    name: kube-apiserver-operator.179e34958e852c88
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31341"
    uid: a76aa5a4-f72a-4852-ac4c-8fb4ec945438
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:48Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-8 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:48Z"
    name: kube-apiserver-operator.179e349605c605bb
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31356"
    uid: 29263227-01a5-4c77-acfe-64189a5cea88
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:49Z"
  message: Created ConfigMap/etcd-serving-ca-8 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:49Z"
    name: kube-apiserver-operator.179e3496650895fe
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31377"
    uid: d37c11e9-9c5a-4084-8668-687f04f9f600
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:51Z"
  message: Created ConfigMap/kube-apiserver-server-ca-8 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:51Z"
    name: kube-apiserver-operator.179e3496c484d795
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31391"
    uid: fd534b00-0a95-40f5-8a58-dea737073164
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:52Z"
  message: Created ConfigMap/kubelet-serving-ca-8 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:52Z"
    name: kube-apiserver-operator.179e34970c0f8213
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31395"
    uid: af84f9e2-7fa4-4ec5-8c03-a86df5fc8982
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:53Z"
  message: Created ConfigMap/sa-token-signing-certs-8 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:53Z"
    name: kube-apiserver-operator.179e3497537c442e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31405"
    uid: 00447a7c-08ad-4e9c-b6a5-9231476d5cd9
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:54Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-8 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:54Z"
    name: kube-apiserver-operator.179e34979b3ec92c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31416"
    uid: cea439ec-732e-4d0b-9205-af724ac2cff5
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:56Z"
  message: Created Secret/etcd-client-8 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:56Z"
    name: kube-apiserver-operator.179e3497e28d70ba
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31425"
    uid: 863014d8-720d-4300-8237-81c4f57b74c6
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:58Z"
  message: Created Secret/localhost-recovery-serving-certkey-8 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:58Z"
    name: kube-apiserver-operator.179e34986633c9ba
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31439"
    uid: 8b27074e-f8ea-4390-bb55-3c33f9159c6b
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:38:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:38:59Z"
  message: Created Secret/localhost-recovery-client-token-8 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:38:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:38:59Z"
    name: kube-apiserver-operator.179e3498ad8ed4e1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31456"
    uid: 854efdf6-9b47-4948-81c0-1266b3ddf302
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:39:00Z"
  message: Created Secret/webhook-authenticator-8 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:39:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:39:00Z"
    name: kube-apiserver-operator.179e3498dd299f59
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31469"
    uid: 8301f5ab-e768-4685-8b8e-54fe7ab8d52d
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:39:00Z"
  message: Revision 8 created because required configmap/config has changed
  metadata:
    creationTimestamp: "2023-12-06T09:39:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:39:00Z"
    name: kube-apiserver-operator.179e3498de34cd7b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31471"
    uid: 28d007a4-376e-440f-95df-a82a9657761f
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:39:01Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded:
    All master nodes are ready\nRevisionControllerDegraded: conflicting latestAvailableRevision
    8"'
  metadata:
    creationTimestamp: "2023-12-06T09:39:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:39:01Z"
    name: kube-apiserver-operator.179e3499328abf8c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31558"
    uid: 37799535-aad9-4e29-9e9e-48b2e4a1fd12
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:39:01Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 8" to "NodeControllerDegraded: All master
    nodes are ready"'
  metadata:
    creationTimestamp: "2023-12-06T09:39:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:39:01Z"
    name: kube-apiserver-operator.179e349934171f65
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "31560"
    uid: fda82b93-7be4-4d3a-adc3-539612fb745f
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:39:18Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 3 nodes are at revision 5; 0 nodes have
    achieved new revision 7" to "NodeInstallerProgressing: 3 nodes are at revision
    5; 0 nodes have achieved new revision 8",Available message changed from "StaticPodsAvailable:
    3 nodes are active; 3 nodes are at revision 5; 0 nodes have achieved new revision
    7" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 5; 0 nodes
    have achieved new revision 8"'
  metadata:
    creationTimestamp: "2023-12-06T09:39:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:39:18Z"
    name: kube-apiserver-operator.179e349d11a86229
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "33136"
    uid: bd9e8613-5e4a-4b12-a385-2ecf74b76ae3
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:39:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:39:22Z"
  message: Created Pod/installer-8-ip-10-0-106-212.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:39:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:39:22Z"
    name: kube-apiserver-operator.179e349e2288b3aa
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "33270"
    uid: 5d070fd7-785d-4baf-a8d0-ddf1638a7f90
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:01Z"
  message: new revision 9 triggered by "required secret/localhost-recovery-client-token
    has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:41:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:01Z"
    name: kube-apiserver-operator.179e34be9fca146e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36760"
    uid: 82ab3692-7d94-4117-9aa1-e2e1b8ffc373
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:43Z"
  message: Created ConfigMap/revision-status-9 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:43Z"
    name: kube-apiserver-operator.179e34becbb9a18a
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36425"
    uid: 17bd2522-11a3-49f4-8ab6-f8898eb03932
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:44Z"
  message: Created ConfigMap/kube-apiserver-pod-9 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:44Z"
    name: kube-apiserver-operator.179e34befb73bfd4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36490"
    uid: 150a45bd-e6f5-4301-a2bb-89cbfeaece64
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:45Z"
  message: Created ConfigMap/config-9 -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:45Z"
    name: kube-apiserver-operator.179e34bf42e0a18b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36509"
    uid: 92cb8f54-61ad-41f5-9187-d67599005aef
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:46Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-9 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:46Z"
    name: kube-apiserver-operator.179e34bf8a3680d0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36530"
    uid: 3cde01a1-a198-4f55-90b5-fd4197311184
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:47Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:47Z"
  message: Created ConfigMap/oauth-metadata-9 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:47Z"
    name: kube-apiserver-operator.179e34bfd1f3b99e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36539"
    uid: 4b4d8a6a-7e06-4261-89d8-c245a7bf498a
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:48Z"
  message: Created ConfigMap/cloud-config-9 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:48Z"
    name: kube-apiserver-operator.179e34c0194a4bdf
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36554"
    uid: 7a6356eb-9756-46a8-82a6-4e6427953b0d
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:50Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-9 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:50Z"
    name: kube-apiserver-operator.179e34c060ecbf64
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36579"
    uid: e9c2bb80-5af5-40b2-ad19-dbe65afe8be8
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:51Z"
  message: Created ConfigMap/etcd-serving-ca-9 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:51Z"
    name: kube-apiserver-operator.179e34c0a85f7bf9
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36611"
    uid: c71c180d-784e-4eec-9573-e983c1c1f8a6
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:52Z"
  message: Created ConfigMap/kube-apiserver-server-ca-9 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:52Z"
    name: kube-apiserver-operator.179e34c0efd5ab27
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36617"
    uid: f975d069-6a8c-4e65-9786-6d62e930ca77
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:53Z"
  message: Created ConfigMap/kubelet-serving-ca-9 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:53Z"
    name: kube-apiserver-operator.179e34c13778954e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36631"
    uid: 5f2a8b64-c60b-4ddc-9411-c091119dbc39
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:54Z"
  message: Created ConfigMap/sa-token-signing-certs-9 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:54Z"
    name: kube-apiserver-operator.179e34c17f0f599e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36649"
    uid: a3cb8838-3f72-481f-9ff8-09455c124606
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:56Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-9 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:56Z"
    name: kube-apiserver-operator.179e34c1c740f3be
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36676"
    uid: e84b7321-ca86-40fa-b265-ecfbf7581048
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:57Z"
  message: Created Secret/etcd-client-9 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:57Z"
    name: kube-apiserver-operator.179e34c20de9dd8f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36686"
    uid: 52cf0187-03ba-42b7-9525-3496de5b5064
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:41:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:41:59Z"
  message: Created Secret/localhost-recovery-serving-certkey-9 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:41:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:41:59Z"
    name: kube-apiserver-operator.179e34c29d4313d0
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36725"
    uid: 347aa583-ed26-4aad-aebf-8deebb98caa7
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:00Z"
  message: Created Secret/localhost-recovery-client-token-9 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:42:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:00Z"
    name: kube-apiserver-operator.179e34c2cccbd507
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36731"
    uid: 82668400-7047-429d-a57b-760d98d55b38
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:01Z"
  message: Created Secret/webhook-authenticator-9 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:42:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:01Z"
    name: kube-apiserver-operator.179e34c308450078
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36755"
    uid: c04feabb-8589-4986-9574-3d384158f281
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:01Z"
  message: Revision 9 created because required secret/localhost-recovery-client-token
    has changed
  metadata:
    creationTimestamp: "2023-12-06T09:42:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:01Z"
    name: kube-apiserver-operator.179e34c3099cafc1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36758"
    uid: 0d00cc1c-6f33-4bc3-b17a-585d884fb700
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:02Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded:
    All master nodes are ready\nRevisionControllerDegraded: conflicting latestAvailableRevision
    9"'
  metadata:
    creationTimestamp: "2023-12-06T09:42:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:02Z"
    name: kube-apiserver-operator.179e34c3459b099e
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36767"
    uid: 68a5b6dd-c880-45f8-a50d-9a133e4c8105
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:02Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 9" to "NodeControllerDegraded: All master
    nodes are ready"'
  metadata:
    creationTimestamp: "2023-12-06T09:42:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:02Z"
    name: kube-apiserver-operator.179e34c347b39588
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36770"
    uid: 5d9cfb73-bb14-459c-b295-a3b116710b04
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:07Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 3 nodes are at revision 5; 0 nodes have
    achieved new revision 8" to "NodeInstallerProgressing: 3 nodes are at revision
    5; 0 nodes have achieved new revision 9",Available message changed from "StaticPodsAvailable:
    3 nodes are active; 3 nodes are at revision 5; 0 nodes have achieved new revision
    8" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 5; 0 nodes
    have achieved new revision 9"'
  metadata:
    creationTimestamp: "2023-12-06T09:42:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:07Z"
    name: kube-apiserver-operator.179e34c458a93323
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36818"
    uid: cb33b23e-f70f-41f6-b58e-6a55f80f459a
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:42:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:42:12Z"
  message: Created Pod/installer-9-ip-10-0-106-212.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:42:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:42:12Z"
    name: kube-apiserver-operator.179e34c5a424feb7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "36907"
    uid: bd88e904-9992-41e1-a890-eef2b533f4ed
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:45:58Z"
  message: Updated node "ip-10-0-106-212.us-west-1.compute.internal" from revision
    5 to 9 because static pod is ready
  metadata:
    creationTimestamp: "2023-12-06T09:45:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:45:58Z"
    name: kube-apiserver-operator.179e34fa332659df
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "39639"
    uid: fb0c16c1-fe46-46df-9c6b-67b8823a19da
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:45:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:45:58Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 3 nodes are at revision 5; 0 nodes have
    achieved new revision 9" to "NodeInstallerProgressing: 2 nodes are at revision
    5; 1 nodes are at revision 9",Available message changed from "StaticPodsAvailable:
    3 nodes are active; 3 nodes are at revision 5; 0 nodes have achieved new revision
    9" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 nodes
    are at revision 9"'
  metadata:
    creationTimestamp: "2023-12-06T09:45:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:45:58Z"
    name: kube-apiserver-operator.179e34fa359d0789
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "39645"
    uid: e2bc9507-1e84-4572-bce8-e0004de8d3bb
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:46:05Z"
  message: Updating node "ip-10-0-21-63.us-west-1.compute.internal" from revision
    5 to 9 because node ip-10-0-21-63.us-west-1.compute.internal with revision 5 is
    the oldest
  metadata:
    creationTimestamp: "2023-12-06T09:46:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:46:05Z"
    name: kube-apiserver-operator.179e34fbd354ce70
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "39732"
    uid: ea2c6436-c5fb-44e5-8b30-acaf93e2eac7
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:46:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:46:10Z"
  message: Created Pod/installer-9-ip-10-0-21-63.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:46:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:46:10Z"
    name: kube-apiserver-operator.179e34fcf15c855f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "39780"
    uid: 48391ce7-075e-47c9-89a3-8726dd5c1e7e
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:49:54Z"
  message: Updated node "ip-10-0-21-63.us-west-1.compute.internal" from revision 5
    to 9 because static pod is ready
  metadata:
    creationTimestamp: "2023-12-06T09:49:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:49:54Z"
    name: kube-apiserver-operator.179e353115b8cf49
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "41947"
    uid: fc37f54e-5df4-4e0d-af13-7cef32fbd468
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:49:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:49:54Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing message
    changed from "NodeInstallerProgressing: 2 nodes are at revision 5; 1 nodes are
    at revision 9" to "NodeInstallerProgressing: 1 nodes are at revision 5; 2 nodes
    are at revision 9",Available message changed from "StaticPodsAvailable: 3 nodes
    are active; 2 nodes are at revision 5; 1 nodes are at revision 9" to "StaticPodsAvailable:
    3 nodes are active; 1 nodes are at revision 5; 2 nodes are at revision 9"'
  metadata:
    creationTimestamp: "2023-12-06T09:49:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:49:54Z"
    name: kube-apiserver-operator.179e3531173bd7ac
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "41948"
    uid: 77096e8d-ea30-48f3-8c78-bf687f22fa99
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:50:00Z"
  message: Updating node "ip-10-0-94-160.us-west-1.compute.internal" from revision
    5 to 9 because node ip-10-0-94-160.us-west-1.compute.internal with revision 5
    is the oldest
  metadata:
    creationTimestamp: "2023-12-06T09:50:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:50:00Z"
    name: kube-apiserver-operator.179e3532ab362841
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "42022"
    uid: 5099137e-123a-4205-88b5-72d56960605b
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:50:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:50:05Z"
  message: Created Pod/installer-9-ip-10-0-94-160.us-west-1.compute.internal -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:50:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:50:05Z"
    name: kube-apiserver-operator.179e3533c873c9d8
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "42074"
    uid: 5c91799b-81b9-4d2f-a4eb-6df637da61b3
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:53:57Z"
  message: Updated node "ip-10-0-94-160.us-west-1.compute.internal" from revision
    5 to 9 because static pod is ready
  metadata:
    creationTimestamp: "2023-12-06T09:53:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:53:57Z"
    name: kube-apiserver-operator.179e3569ce451633
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "44474"
    uid: 9e69a81d-5ecc-4f27-99fa-1045fc37b876
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:53:57Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing changed
    from True to False ("NodeInstallerProgressing: 3 nodes are at revision 9"),Available
    message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at
    revision 5; 2 nodes are at revision 9" to "StaticPodsAvailable: 3 nodes are active;
    3 nodes are at revision 9"'
  metadata:
    creationTimestamp: "2023-12-06T09:53:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:53:57Z"
    name: kube-apiserver-operator.179e3569cf3be9e4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "44476"
    uid: f9ea767b-74ff-42af-9ce0-7d853cc12c9a
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:53:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:53:59Z"
  message: Created Pod/revision-pruner-9-ip-10-0-106-212.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:53:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:53:59Z"
    name: kube-apiserver-operator.179e356a453565a7
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "44493"
    uid: 8040a7df-bc6a-4975-bb75-1d0f5a37d9af
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:54:02Z"
  message: Created Pod/revision-pruner-9-ip-10-0-21-63.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:54:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:54:02Z"
    name: kube-apiserver-operator.179e356b039f3cc4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "44554"
    uid: fbab6cc6-e72e-43de-b1f5-0163d63ae644
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:54:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:54:05Z"
  message: Created Pod/revision-pruner-9-ip-10-0-94-160.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:54:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:54:05Z"
    name: kube-apiserver-operator.179e356baa73524f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "44606"
    uid: 72c2616f-645c-44c4-9c33-bd7960aaf111
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:46Z"
  message: new revision 10 triggered by "required secret/localhost-recovery-client-token
    has changed"
  metadata:
    creationTimestamp: "2023-12-06T09:57:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:46Z"
    name: kube-apiserver-operator.179e359a6903a311
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47636"
    uid: 4130d2b1-1ff1-4443-a1b1-01867e7c0b8f
  reason: RevisionTriggered
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:27Z"
  message: Created ConfigMap/revision-status-10 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:27Z"
    name: kube-apiserver-operator.179e359aa077d60d
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47305"
    uid: 14fd7421-c19a-45d7-ab3d-35a729d1dd22
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:28Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:28Z"
  message: Created ConfigMap/kube-apiserver-pod-10 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:28Z"
    name: kube-apiserver-operator.179e359adafec2aa
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47336"
    uid: 99625a6f-f25d-4d93-a8c3-336074e4c8ec
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:29Z"
  message: Created ConfigMap/config-10 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:29Z"
    name: kube-apiserver-operator.179e359b2214ca18
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47370"
    uid: 9adee9a4-6d17-474d-8797-8a45ead8eba6
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:30Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:30Z"
  message: Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-10 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:30Z"
    name: kube-apiserver-operator.179e359b6989d57f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47412"
    uid: 8cec5f88-05d9-4431-9443-87da3f821d35
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:32Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:32Z"
  message: Created ConfigMap/oauth-metadata-10 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:32Z"
    name: kube-apiserver-operator.179e359bbd00d4e1
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47427"
    uid: dbed1b2c-48fd-4ab3-ad3a-a2943a7310b6
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:33Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:33Z"
  message: Created ConfigMap/cloud-config-10 -n openshift-kube-apiserver because it
    was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:33Z"
    name: kube-apiserver-operator.179e359c04807f68
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47457"
    uid: c7c7a172-294b-497d-a473-71cc22d93a37
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:34Z"
  message: Created ConfigMap/bound-sa-token-signing-certs-10 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:34Z"
    name: kube-apiserver-operator.179e359c4c1396d4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47472"
    uid: 691a2075-ed7a-4673-a400-136d530a9cfa
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:35Z"
  message: Created ConfigMap/etcd-serving-ca-10 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:35Z"
    name: kube-apiserver-operator.179e359c93a6d5e6
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47486"
    uid: 9a505e32-9aca-48ab-ae6f-268f38ea99f5
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:37Z"
  message: Created ConfigMap/kube-apiserver-server-ca-10 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:37Z"
    name: kube-apiserver-operator.179e359cde9f0ae4
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47503"
    uid: 452566cf-1b96-44f8-8836-4c810ccacdcc
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:38Z"
  message: Created ConfigMap/kubelet-serving-ca-10 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:38Z"
    name: kube-apiserver-operator.179e359d22b4b048
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47532"
    uid: 39d97751-0333-44be-a5eb-b1c345b16a39
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:39Z"
  message: Created ConfigMap/sa-token-signing-certs-10 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:39Z"
    name: kube-apiserver-operator.179e359d6a30ba91
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47547"
    uid: 37813b36-d65c-43ce-b07a-d3b34d12adac
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:41Z"
  message: Created ConfigMap/kube-apiserver-audit-policies-10 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:41Z"
    name: kube-apiserver-operator.179e359dc9ac3b4b
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47563"
    uid: 547e5081-8b6f-4abc-bce1-5d1483aafb56
  reason: ConfigMapCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:42Z"
  message: Created Secret/etcd-client-10 -n openshift-kube-apiserver because it was
    missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:42Z"
    name: kube-apiserver-operator.179e359e28f17488
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47584"
    uid: 50a66c6a-8874-454b-854e-6e439424fe4a
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:45Z"
  message: Created Secret/localhost-recovery-serving-certkey-10 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:45Z"
    name: kube-apiserver-operator.179e359eb7f64998
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47609"
    uid: 179d953d-8799-492e-ab21-ca38f16571ef
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:45Z"
  message: Created Secret/localhost-recovery-client-token-10 -n openshift-kube-apiserver
    because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:45Z"
    name: kube-apiserver-operator.179e359ee7cc9ebe
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47616"
    uid: a0986c45-f7cb-4b65-a1dc-48873be90ddd
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:46Z"
  message: Created Secret/webhook-authenticator-10 -n openshift-kube-apiserver because
    it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:46Z"
    name: kube-apiserver-operator.179e359f234399b2
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47632"
    uid: aaa00d6d-2352-45f7-b871-6df553e9eb70
  reason: SecretCreated
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:46Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:46Z"
  message: Revision 10 created because required secret/localhost-recovery-client-token
    has changed
  metadata:
    creationTimestamp: "2023-12-06T09:57:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:46Z"
    name: kube-apiserver-operator.179e359f242a3e3f
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47635"
    uid: 7cfe9368-5804-4b9e-a674-27e39c2c4669
  reason: RevisionCreate
  reportingComponent: kube-apiserver-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:48Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded:
    All master nodes are ready\nRevisionControllerDegraded: conflicting latestAvailableRevision
    10"'
  metadata:
    creationTimestamp: "2023-12-06T09:57:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:48Z"
    name: kube-apiserver-operator.179e359f8743c786
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47667"
    uid: 33d13dac-bec4-432a-b059-9a0a8c5b72b5
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:48Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Degraded message changed
    from "NodeControllerDegraded: All master nodes are ready\nRevisionControllerDegraded:
    conflicting latestAvailableRevision 10" to "NodeControllerDegraded: All master
    nodes are ready"'
  metadata:
    creationTimestamp: "2023-12-06T09:57:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:48Z"
    name: kube-apiserver-operator.179e359f887e2f77
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47669"
    uid: 5e2ff494-c530-445b-92bc-b3503aa41a0d
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:50Z"
  message: Created Pod/revision-pruner-10-ip-10-0-106-212.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:50Z"
    name: kube-apiserver-operator.179e35a0062f5d94
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47687"
    uid: dac1db96-18d7-4e86-991d-4e916a93b8f8
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:54Z"
  message: Created Pod/revision-pruner-10-ip-10-0-21-63.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:54Z"
    name: kube-apiserver-operator.179e35a0d07221cc
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47725"
    uid: db0aca59-8321-48b3-b7f5-9a25266d6c0a
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:57:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:57:57Z"
  message: Created Pod/revision-pruner-10-ip-10-0-94-160.us-west-1.compute.internal
    -n openshift-kube-apiserver because it was missing
  metadata:
    creationTimestamp: "2023-12-06T09:57:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:57:57Z"
    name: kube-apiserver-operator.179e35a18f60a432
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47752"
    uid: e568a58e-3409-422d-bb98-5980dc22ced9
  reason: PodCreated
  reportingComponent: kube-apiserver-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:58:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:58:01Z"
  message: Updating node "ip-10-0-106-212.us-west-1.compute.internal" from revision
    9 to 10 because node ip-10-0-106-212.us-west-1.compute.internal with revision
    9 is the oldest
  metadata:
    creationTimestamp: "2023-12-06T09:58:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:58:01Z"
    name: kube-apiserver-operator.179e35a28a48f64c
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47807"
    uid: f0aaa94e-5c04-43cc-9894-172071d70c6c
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-apiserver-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2023-12-06T09:58:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-apiserver-operator
    namespace: openshift-kube-apiserver-operator
    uid: 5fb90846-c5c3-45bf-9e15-0b159b32b6e3
  kind: Event
  lastTimestamp: "2023-12-06T09:58:01Z"
  message: 'Status for clusteroperator/kube-apiserver changed: Progressing changed
    from False to True ("NodeInstallerProgressing: 3 nodes are at revision 9; 0 nodes
    have achieved new revision 10"),Available message changed from "StaticPodsAvailable:
    3 nodes are active; 3 nodes are at revision 9" to "StaticPodsAvailable: 3 nodes
    are active; 3 nodes are at revision 9; 0 nodes have achieved new revision 10"'
  metadata:
    creationTimestamp: "2023-12-06T09:58:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2023-12-06T09:58:01Z"
    name: kube-apiserver-operator.179e35a28b575650
    namespace: openshift-kube-apiserver-operator
    resourceVersion: "47809"
    uid: 5836b154-bc95-43fc-9066-e93ea8d0d685
  reason: OperatorStatusChanged
  reportingComponent: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  reportingInstance: ""
  source:
    component: kube-apiserver-operator-status-controller-statussyncer_kube-apiserver
  type: Normal
kind: EventList
metadata:
  resourceVersion: "47809"
